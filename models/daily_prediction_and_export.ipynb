{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P1BXqsllgueC"
      },
      "source": [
        "#Boston 311 Tutorial\n",
        "\n",
        "This notebook will run you through the basic usage of this package to train 3 models on the Boston 311 data and use them to predict the outcome of cases from the last 30 days"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u54v241Vh-gN"
      },
      "source": [
        "##Install the package from github using pip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "HF8wNhboPQ1z"
      },
      "outputs": [],
      "source": [
        "#This library is only needed for the Cox Regression Model, which is not included in this tutorial\n",
        "#! pip install lifelines"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "#pwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rlLnbD24LDtG",
        "outputId": "6520c1c5-4219-49a4-ba28-7d06451fdfee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Processing /home/briarmoss/Documents/Boston_311\n",
            "  Installing build dependencies ... \u001b[?25ldone\n",
            "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
            "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25hRequirement already satisfied: numpy in /home/briarmoss/.local/lib/python3.10/site-packages (from boston311==0.1.0) (1.23.5)\n",
            "Requirement already satisfied: pandas in /home/briarmoss/.local/lib/python3.10/site-packages (from boston311==0.1.0) (2.0.1)\n",
            "Requirement already satisfied: tensorflow in /home/briarmoss/.local/lib/python3.10/site-packages (from boston311==0.1.0) (2.12.0)\n",
            "Requirement already satisfied: scikit-learn in /home/briarmoss/.local/lib/python3.10/site-packages (from boston311==0.1.0) (1.2.2)\n",
            "Requirement already satisfied: matplotlib in /home/briarmoss/.local/lib/python3.10/site-packages (from boston311==0.1.0) (3.7.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /home/briarmoss/.local/lib/python3.10/site-packages (from matplotlib->boston311==0.1.0) (23.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /home/briarmoss/.local/lib/python3.10/site-packages (from matplotlib->boston311==0.1.0) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /home/briarmoss/.local/lib/python3.10/site-packages (from matplotlib->boston311==0.1.0) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /home/briarmoss/.local/lib/python3.10/site-packages (from matplotlib->boston311==0.1.0) (4.39.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /home/briarmoss/.local/lib/python3.10/site-packages (from matplotlib->boston311==0.1.0) (1.0.7)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/lib/python3/dist-packages (from matplotlib->boston311==0.1.0) (9.0.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /home/briarmoss/.local/lib/python3.10/site-packages (from matplotlib->boston311==0.1.0) (1.4.4)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/lib/python3/dist-packages (from matplotlib->boston311==0.1.0) (2.4.7)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas->boston311==0.1.0) (2022.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /home/briarmoss/.local/lib/python3.10/site-packages (from pandas->boston311==0.1.0) (2023.3)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/briarmoss/.local/lib/python3.10/site-packages (from scikit-learn->boston311==0.1.0) (3.1.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /home/briarmoss/.local/lib/python3.10/site-packages (from scikit-learn->boston311==0.1.0) (1.2.0)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /home/briarmoss/.local/lib/python3.10/site-packages (from scikit-learn->boston311==0.1.0) (1.10.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /home/briarmoss/.local/lib/python3.10/site-packages (from tensorflow->boston311==0.1.0) (3.3.0)\n",
            "Requirement already satisfied: tensorboard<2.13,>=2.12 in /home/briarmoss/.local/lib/python3.10/site-packages (from tensorflow->boston311==0.1.0) (2.12.3)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/briarmoss/.local/lib/python3.10/site-packages (from tensorflow->boston311==0.1.0) (0.32.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /home/briarmoss/.local/lib/python3.10/site-packages (from tensorflow->boston311==0.1.0) (2.3.0)\n",
            "Requirement already satisfied: jax>=0.3.15 in /home/briarmoss/.local/lib/python3.10/site-packages (from tensorflow->boston311==0.1.0) (0.4.10)\n",
            "Requirement already satisfied: keras<2.13,>=2.12.0 in /home/briarmoss/.local/lib/python3.10/site-packages (from tensorflow->boston311==0.1.0) (2.12.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /home/briarmoss/.local/lib/python3.10/site-packages (from tensorflow->boston311==0.1.0) (16.0.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /home/briarmoss/.local/lib/python3.10/site-packages (from tensorflow->boston311==0.1.0) (3.20.3)\n",
            "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /home/briarmoss/.local/lib/python3.10/site-packages (from tensorflow->boston311==0.1.0) (2.12.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /home/briarmoss/.local/lib/python3.10/site-packages (from tensorflow->boston311==0.1.0) (3.8.0)\n",
            "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from tensorflow->boston311==0.1.0) (59.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /home/briarmoss/.local/lib/python3.10/site-packages (from tensorflow->boston311==0.1.0) (0.2.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /home/briarmoss/.local/lib/python3.10/site-packages (from tensorflow->boston311==0.1.0) (23.5.9)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /home/briarmoss/.local/lib/python3.10/site-packages (from tensorflow->boston311==0.1.0) (1.14.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /home/briarmoss/.local/lib/python3.10/site-packages (from tensorflow->boston311==0.1.0) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /home/briarmoss/.local/lib/python3.10/site-packages (from tensorflow->boston311==0.1.0) (1.6.3)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /home/briarmoss/.local/lib/python3.10/site-packages (from tensorflow->boston311==0.1.0) (0.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /home/briarmoss/.local/lib/python3.10/site-packages (from tensorflow->boston311==0.1.0) (4.5.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/lib/python3/dist-packages (from tensorflow->boston311==0.1.0) (1.16.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/briarmoss/.local/lib/python3.10/site-packages (from tensorflow->boston311==0.1.0) (1.54.2)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/lib/python3/dist-packages (from astunparse>=1.6.0->tensorflow->boston311==0.1.0) (0.37.1)\n",
            "Requirement already satisfied: ml-dtypes>=0.1.0 in /home/briarmoss/.local/lib/python3.10/site-packages (from jax>=0.3.15->tensorflow->boston311==0.1.0) (0.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/lib/python3/dist-packages (from tensorboard<2.13,>=2.12->tensorflow->boston311==0.1.0) (2.25.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /home/briarmoss/.local/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow->boston311==0.1.0) (1.0.0)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /home/briarmoss/.local/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow->boston311==0.1.0) (2.3.4)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/briarmoss/.local/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow->boston311==0.1.0) (2.18.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/briarmoss/.local/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow->boston311==0.1.0) (0.7.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /home/briarmoss/.local/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow->boston311==0.1.0) (3.4.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/briarmoss/.local/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow->boston311==0.1.0) (0.3.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/briarmoss/.local/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow->boston311==0.1.0) (5.3.0)\n",
            "Requirement already satisfied: urllib3<2.0 in /usr/lib/python3/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow->boston311==0.1.0) (1.26.5)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /home/briarmoss/.local/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow->boston311==0.1.0) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/briarmoss/.local/lib/python3.10/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow->boston311==0.1.0) (1.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/briarmoss/.local/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow->boston311==0.1.0) (2.1.2)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /home/briarmoss/.local/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow->boston311==0.1.0) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/lib/python3/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow->boston311==0.1.0) (3.2.0)\n",
            "Building wheels for collected packages: boston311\n",
            "  Building wheel for boston311 (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for boston311: filename=boston311-0.1.0-py3-none-any.whl size=20043 sha256=0b0b050beee6707f1dc4c376f0fc1aa439b79bf768309c3f53dae8c5830d7e44\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-q37q1ygc/wheels/3d/69/ee/0a6ac96b9c09c948fc0e74f2724a9703aa39749a41fa757c9e\n",
            "Successfully built boston311\n",
            "Installing collected packages: boston311\n",
            "  Attempting uninstall: boston311\n",
            "    Found existing installation: boston311 0.1.0\n",
            "    Uninstalling boston311-0.1.0:\n",
            "      Successfully uninstalled boston311-0.1.0\n",
            "Successfully installed boston311-0.1.0\n"
          ]
        }
      ],
      "source": [
        "! pip install ../"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XP7Hzen_iEAl"
      },
      "source": [
        "##Import the Boston311Model class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name: boston311\n",
            "Version: 0.1.0\n",
            "Summary: A package for training machine learning models on Boston 311 data\n",
            "Home-page: https://github.com/mindfulcoder49/Boston_311\n",
            "Author: Alex Alcivar\n",
            "Author-email: alex.g.alcivar49@gmail.com\n",
            "License: UNKNOWN\n",
            "Location: /home/briarmoss/.local/lib/python3.10/site-packages\n",
            "Requires: matplotlib, numpy, pandas, scikit-learn, tensorflow\n",
            "Required-by: \n"
          ]
        }
      ],
      "source": [
        "! pip show boston311"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "LdhJESm7eWaY"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-13 10:50:12.253282: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2023-09-13 10:50:12.616594: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2023-09-13 10:50:12.619236: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-09-13 10:50:17.723533: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        }
      ],
      "source": [
        "from boston311 import Boston311LogReg, Boston311EventDecTree, Boston311SurvDecTree"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oq06XnVjPxvg"
      },
      "source": [
        "#Get latest file URLS and Current Date Ranges"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-09-11_19-11-02_311_cases.csv\t 2023-09-12_17-01-30_manifest.txt\n",
            "2023-09-11_19-11-02_311_ml_models.csv\t daily_models\n",
            "2023-09-11_19-11-02_311_predictions.csv  daily_prediction_and_export.ipynb\n",
            "2023-09-11_19-11-02_manifest.txt\t daily.py\n",
            "2023-09-12_17-01-30_311_cases.csv\t __pycache__\n",
            "2023-09-12_17-01-30_311_ml_models.csv\t save_models_and_predictions.ipynb\n",
            "2023-09-12_17-01-30_311_predictions.csv  train_and_save_models.ipynb\n"
          ]
        }
      ],
      "source": [
        "! ls ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "_2FYkUb2P1LR"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'20230911_185132_Boston311LogReg': <boston311.Boston311LogReg.Boston311LogReg at 0x7fbd866fb040>,\n",
              " '20230911_185132_Boston311EventDecTree': <boston311.Boston311EventDecTree.Boston311EventDecTree at 0x7fbd866fb100>,\n",
              " '20230911_185132_Boston311SurvDecTree': <boston311.Boston311SurvDecTree.Boston311SurvDecTree at 0x7fbd866fb070>}"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "#define daily model folder constant\n",
        "DAILY_MODEL_FOLDER = './daily_models'\n",
        "\n",
        "\n",
        "# The helper function load_model_from_file is adjusted to load a model \n",
        "# based on its type and the provided timestamp.\n",
        "# The main loop iterates through each folder in DAILY_MODEL_FOLDER.\n",
        "# For each folder, it checks for model files (.pkl or .h5).\n",
        "# If a model file is found, it extracts the timestamp and model type \n",
        "# from the filename and uses the helper function to load the model.\n",
        "# The loaded model is added to the daily_model_dict with the key being \n",
        "# the model's filename without the extension.\n",
        "\n",
        "\n",
        "def load_model_from_file(model_type, folder_path, timestamp):\n",
        "    \"\"\"Load a model based on its type from a given folder.\"\"\"\n",
        "    if model_type == 'Boston311EventDecTree':\n",
        "        model_instance = Boston311EventDecTree()\n",
        "        model_file = f'{timestamp}_{model_type}.pkl'\n",
        "    elif model_type == 'Boston311LogReg':\n",
        "        model_instance = Boston311LogReg()\n",
        "        model_file = f'{timestamp}_{model_type}.h5'\n",
        "    elif model_type == 'Boston311SurvDecTree':\n",
        "        model_instance = Boston311SurvDecTree()\n",
        "        model_file = f'{timestamp}_{model_type}.pkl'\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown model type: {model_type}\")\n",
        "\n",
        "    properties_file = f'{timestamp}_{model_type}.json'\n",
        "    model_instance.load(os.path.join(folder_path, properties_file), os.path.join(folder_path, model_file))\n",
        "    \n",
        "    return model_instance\n",
        "\n",
        "daily_model_dict = {}\n",
        "\n",
        "for folder in os.listdir(DAILY_MODEL_FOLDER):\n",
        "    folder_path = os.path.join(DAILY_MODEL_FOLDER, folder)\n",
        "    if os.path.isdir(folder_path):\n",
        "        for file in os.listdir(folder_path):\n",
        "            if file.count('_') == 2 and any(ext in file for ext in ['.pkl', '.h5']):\n",
        "                parts = file.rsplit('.', 1)[0].split('_')\n",
        "                timestamp = f\"{parts[0]}_{parts[1]}\"\n",
        "                model_type = parts[2]\n",
        "                try:\n",
        "                    daily_model_dict[f'{timestamp}_{model_type}'] = load_model_from_file(model_type, folder_path, timestamp)\n",
        "                except ValueError:\n",
        "                    # Skip files with unknown model types\n",
        "                    continue\n",
        "\n",
        "daily_model_dict\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "from datetime import datetime, timedelta\n",
        "now = datetime.now()\n",
        "today_datestring = now.strftime(\"%Y-%m-%d\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ml_model_name</th>\n",
              "      <th>ml_model_type</th>\n",
              "      <th>ml_model_date</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [ml_model_name, ml_model_type, ml_model_date]\n",
              "Index: []"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "#define an empt pandas dataframe ml_model_df\n",
        "ml_model_df = pd.DataFrame(columns=['ml_model_name', 'ml_model_type', 'ml_model_date'])\n",
        "all_model_cases = pd.DataFrame()\n",
        "all_model_predictions = pd.DataFrame()\n",
        "\n",
        "\n",
        "ml_model_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uUMCPAELR9h7",
        "outputId": "05fcba64-1b74-4fb7-a52c-d3f8a499bcc6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing model: 20230911_185132_Boston311LogReg\n",
            "Empty DataFrame\n",
            "Columns: [ml_model_name, ml_model_type, ml_model_date]\n",
            "Index: []\n",
            "                     ml_model_name    ml_model_type ml_model_date\n",
            "0  20230911_185132_Boston311LogReg  Boston311LogReg    2023-09-11\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/briarmoss/.local/lib/python3.10/site-packages/boston311/Boston311Model.py:255: DtypeWarning: Columns (13) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(file)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files with different number of columns from File 0:  []\n",
            "Files with same number of columns as File 0:  [0]\n",
            "Files with different column order from File 0:  []\n",
            "Files with same column order as File 0:  [0]\n",
            "1081/1081 [==============================] - 2s 2ms/step\n",
            "Processing model: 20230911_185132_Boston311EventDecTree\n",
            "                     ml_model_name    ml_model_type ml_model_date\n",
            "0  20230911_185132_Boston311LogReg  Boston311LogReg    2023-09-11\n",
            "                           ml_model_name          ml_model_type ml_model_date\n",
            "0        20230911_185132_Boston311LogReg        Boston311LogReg    2023-09-11\n",
            "1  20230911_185132_Boston311EventDecTree  Boston311EventDecTree    2023-09-11\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/briarmoss/.local/lib/python3.10/site-packages/boston311/Boston311Model.py:255: DtypeWarning: Columns (13) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(file)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files with different number of columns from File 0:  []\n",
            "Files with same number of columns as File 0:  [0]\n",
            "Files with different column order from File 0:  []\n",
            "Files with same column order as File 0:  [0]\n",
            "Processing model: 20230911_185132_Boston311SurvDecTree\n",
            "                           ml_model_name          ml_model_type ml_model_date\n",
            "0        20230911_185132_Boston311LogReg        Boston311LogReg    2023-09-11\n",
            "1  20230911_185132_Boston311EventDecTree  Boston311EventDecTree    2023-09-11\n",
            "                           ml_model_name          ml_model_type ml_model_date\n",
            "0        20230911_185132_Boston311LogReg        Boston311LogReg    2023-09-11\n",
            "1  20230911_185132_Boston311EventDecTree  Boston311EventDecTree    2023-09-11\n",
            "2   20230911_185132_Boston311SurvDecTree   Boston311SurvDecTree    2023-09-11\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/briarmoss/.local/lib/python3.10/site-packages/boston311/Boston311Model.py:255: DtypeWarning: Columns (13) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(file)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files with different number of columns from File 0:  []\n",
            "Files with same number of columns as File 0:  [0]\n",
            "Files with different column order from File 0:  []\n",
            "Files with same column order as File 0:  [0]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "\n",
        "#foreach model in the daily_model_dict set the predict_dat_range to the last 30 days and then call the predict method and save the results to a csv file\n",
        "for model_name, model in daily_model_dict.items():\n",
        "\n",
        "    print(f\"Processing model: {model_name}\")\n",
        "\n",
        "    print(ml_model_df)\n",
        "    model.predict_date_range = {'start': '2023-08-09', 'end': today_datestring}\n",
        "\n",
        "\n",
        "\n",
        "    #get file creation date for the .json file in the folder with the model_name\n",
        "    #use os.path.getctime to get the creation time of the .json file in the folder with the model_name\n",
        "    #convert the creation time to a datetime object\n",
        "    #convert the datetime object to a string in the format of %Y-%m-%d\n",
        "    #add to ml_model_df dataframe with  columns, ml_model_name, ml_model_type,ml_model_id, ml_model_date\n",
        "    ml_model_datetime = os.path.getctime(os.path.join(DAILY_MODEL_FOLDER, model.__class__.__name__, model_name + '.json'))\n",
        "    ml_model_date = datetime.fromtimestamp(ml_model_datetime).strftime('%Y-%m-%d')\n",
        "    \n",
        "\n",
        "    ml_model_df = pd.concat([ml_model_df, pd.DataFrame([{'ml_model_name': model_name, \n",
        "                                    'ml_model_type': model.__class__.__name__,\n",
        "                                    'ml_model_date': ml_model_date}])], ignore_index=True)\n",
        "    \n",
        "    print(ml_model_df)\n",
        "\n",
        "    model_prediction = model.predict()\n",
        "\n",
        "    #check if the model_prediction dataframe contains an event_prediction column\n",
        "    if 'event_prediction' in model_prediction.columns:\n",
        "    #get new dataframe with just the event_prediction column from the model_prediction dataframe\n",
        "        model_prediction_event = model_prediction[['event_prediction','case_enquiry_id']].copy()\n",
        "        model_prediction_event.rename(columns={'event_prediction': 'prediction'}, inplace=True)\n",
        "        #remove model_prediction event_prediction column\n",
        "        model_cases = model_prediction.drop('event_prediction', axis=1).copy()\n",
        "    elif 'survival_prediction' in model_prediction.columns:\n",
        "        model_prediction_event = model_prediction[['survival_prediction','case_enquiry_id']].copy()\n",
        "        model_prediction_event.rename(columns={'survival_prediction': 'prediction'}, inplace=True)\n",
        "        #remove model_prediction survival_prediction column\n",
        "        model_cases = model_prediction.drop('survival_prediction', axis=1).copy()\n",
        "\n",
        "    model_prediction_event['ml_model_name'] = model_name\n",
        "    #add today's date to the dataframe\n",
        "    model_prediction_event['prediction_date'] = today_datestring\n",
        "    #rename the event_prediction column to prediction\n",
        "    \n",
        "    #remove geom column in model_cases\n",
        "    model_cases = model_cases.drop(['geom_4326','event','survival_time_hours', 'survival_time'], axis=1).copy()\n",
        "\n",
        "    # Add the model_cases dataframe to the all_model_cases dataframe\n",
        "    all_model_cases = pd.concat([all_model_cases, model_cases], ignore_index=True).drop_duplicates().reset_index(drop=True)\n",
        "\n",
        "    # Add the model_prediction_event dataframe to the all_model_predictions dataframe\n",
        "    all_model_predictions = pd.concat([all_model_predictions, model_prediction_event], ignore_index=True)\n",
        "\n",
        "    \n",
        "\n",
        "    \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of rows in all_model_predictions: 103716\n"
          ]
        }
      ],
      "source": [
        "#count rows in prediction dataframe\n",
        "print(f\"Number of rows in all_model_predictions: {len(all_model_predictions)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Assuming the dataframe with all case data is named all_cases\n",
        "closed_case_ids = all_model_cases[all_model_cases['case_status'] == 'Closed']['case_enquiry_id'].unique()\n",
        "\n",
        "# Drop rows from all_model_predictions where case_enquiry_id matches those in closed_case_ids\n",
        "all_model_predictions = all_model_predictions[~all_model_predictions['case_enquiry_id'].isin(closed_case_ids)]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of rows in all_model_predictions: 20997\n"
          ]
        }
      ],
      "source": [
        "#count rows in prediction dataframe\n",
        "print(f\"Number of rows in all_model_predictions: {len(all_model_predictions)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I4dxuwJdgrZr"
      },
      "source": [
        "## Save the prediction data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'2023-09-13_10-51-36'"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#get current datetime in Boston timezone as string\n",
        "from datetime import datetime\n",
        "from pytz import timezone\n",
        "import pytz\n",
        "boston = timezone('US/Eastern')\n",
        "now = datetime.now(boston)\n",
        "today_datestring = now.strftime(\"%Y-%m-%d\")\n",
        "#get time in Boston timezone as string for a filename\n",
        "now = datetime.now(boston)\n",
        "time_string = now.strftime(\"%H-%M-%S\")\n",
        "#define datetime string\n",
        "my_datetime = today_datestring + '_' + time_string \n",
        "\n",
        "my_datetime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "       case_enquiry_id             open_dt        sla_target_dt   \n",
            "0         101004975722 2023-08-09 00:37:00  2023-08-10 04:30:00  \\\n",
            "1         101004975723 2023-08-09 00:47:40  2023-08-10 04:30:00   \n",
            "2         101004975724 2023-08-09 00:48:58  2023-08-10 04:30:00   \n",
            "3         101004975726 2023-08-09 01:18:47  2023-08-11 04:30:00   \n",
            "4         101004975727 2023-08-09 01:19:54  2023-08-10 04:30:00   \n",
            "...                ...                 ...                  ...   \n",
            "34567     101005050187 2023-09-12 19:48:23  2023-09-14 04:30:00   \n",
            "34568     101005050188 2023-09-12 19:49:22  2023-09-14 04:30:00   \n",
            "34569     101005050189 2023-09-12 19:49:55  2023-09-14 04:30:00   \n",
            "34570     101005050190 2023-09-12 19:50:09  2023-09-14 04:30:00   \n",
            "34571     101005050191 2023-09-12 19:56:33  2023-09-14 04:30:00   \n",
            "\n",
            "                closed_dt on_time case_status   \n",
            "0     2023-08-09 01:29:44  ONTIME      Closed  \\\n",
            "1     2023-08-09 01:43:02  ONTIME      Closed   \n",
            "2     2023-08-09 08:53:28  ONTIME      Closed   \n",
            "3     2023-08-09 11:54:12  ONTIME      Closed   \n",
            "4     2023-08-09 02:02:12  ONTIME      Closed   \n",
            "...                   ...     ...         ...   \n",
            "34567                 NaT  ONTIME        Open   \n",
            "34568                 NaT  ONTIME        Open   \n",
            "34569                 NaT  ONTIME        Open   \n",
            "34570                 NaT  ONTIME        Open   \n",
            "34571                 NaT  ONTIME        Open   \n",
            "\n",
            "                                          closure_reason   \n",
            "0      Case Closed. Closed date : Wed Aug 09 05:29:44...  \\\n",
            "1      Case Closed. Closed date : 2023-08-09 05:43:02...   \n",
            "2      Case Closed. Closed date : 2023-08-09 12:53:28...   \n",
            "3      Case Closed. Closed date : Wed Aug 09 15:54:12...   \n",
            "4      Case Closed. Closed date : 2023-08-09 06:02:12...   \n",
            "...                                                  ...   \n",
            "34567                                                      \n",
            "34568                                                      \n",
            "34569                                                      \n",
            "34570                                                      \n",
            "34571                                                      \n",
            "\n",
            "                                case_title                            subject   \n",
            "0             Requests for Street Cleaning            Public Works Department  \\\n",
            "1                      Parking Enforcement  Transportation - Traffic Division   \n",
            "2                      Parking Enforcement  Transportation - Traffic Division   \n",
            "3      Improper Storage of Trash (Barrels)            Public Works Department   \n",
            "4                      Parking Enforcement  Transportation - Traffic Division   \n",
            "...                                    ...                                ...   \n",
            "34567                  Parking Enforcement  Transportation - Traffic Division   \n",
            "34568                  Parking Enforcement  Transportation - Traffic Division   \n",
            "34569                  Parking Enforcement  Transportation - Traffic Division   \n",
            "34570                  Parking Enforcement  Transportation - Traffic Division   \n",
            "34571                  Parking Enforcement  Transportation - Traffic Division   \n",
            "\n",
            "                                 reason  ... neighborhood_services_district   \n",
            "0                       Street Cleaning  ...                              8  \\\n",
            "1      Enforcement & Abandoned Vehicles  ...                              7   \n",
            "2      Enforcement & Abandoned Vehicles  ...                             12   \n",
            "3                      Code Enforcement  ...                              4   \n",
            "4      Enforcement & Abandoned Vehicles  ...                              5   \n",
            "...                                 ...  ...                            ...   \n",
            "34567  Enforcement & Abandoned Vehicles  ...                              1   \n",
            "34568  Enforcement & Abandoned Vehicles  ...                              1   \n",
            "34569  Enforcement & Abandoned Vehicles  ...                              5   \n",
            "34570  Enforcement & Abandoned Vehicles  ...                              1   \n",
            "34571  Enforcement & Abandoned Vehicles  ...                             15   \n",
            "\n",
            "          ward precinct                  location_street_name   \n",
            "0      Ward 15     1508                         30 Dickens St  \\\n",
            "1      Ward 13     1310                         14 Midland St   \n",
            "2      Ward 20     2016                        2261 Centre St   \n",
            "3       Ward 3     0307                         3-5 Hanson St   \n",
            "4           07     0703                              84R G St   \n",
            "...        ...      ...                                   ...   \n",
            "34567   Ward 1     0108                         1 Monmouth Sq   \n",
            "34568       01     0108                          73 Falcon St   \n",
            "34569        6     0603           INTERSECTION Gold St & E St   \n",
            "34570        1     0108  INTERSECTION Monmouth St & Brooks St   \n",
            "34571  Ward 21     2108                       1 Woodstock Ave   \n",
            "\n",
            "      location_zipcode   latitude  longitude                source   \n",
            "0               2122.0  42.301060 -71.057691      Constituent Call  \\\n",
            "1               2125.0  42.311420 -71.054401  Citizens Connect App   \n",
            "2               2132.0  42.273020 -71.161111  Citizens Connect App   \n",
            "3               2118.0  42.343580 -71.069761  Citizens Connect App   \n",
            "4               2127.0  42.333090 -71.043747  Citizens Connect App   \n",
            "...                ...        ...        ...                   ...   \n",
            "34567           2128.0  42.380404 -71.036991  Citizens Connect App   \n",
            "34568           2128.0  42.381866 -71.036648  Citizens Connect App   \n",
            "34569              NaN  42.336792 -71.050479  Citizens Connect App   \n",
            "34570              NaN  42.380512 -71.036105  Citizens Connect App   \n",
            "34571           2135.0  42.344780 -71.138541  Citizens Connect App   \n",
            "\n",
            "      ward_number                          checksum  \n",
            "0              15  ddda47f693be48318576966d9e5b2eb4  \n",
            "1              13  84bd30e3a620c74da1a6de4227735dd2  \n",
            "2              20  7f3ed3479b4b218667499526d3a8f451  \n",
            "3               3  4fcbee403fbb58b7da2c1c9c97ac4161  \n",
            "4               7  4655c660360219fbb9031386a5029356  \n",
            "...           ...                               ...  \n",
            "34567           1  e8382f9fd1bd6ad1d70377c69276f7ff  \n",
            "34568           1  2d9d468544df32693d2e96219f5b2c84  \n",
            "34569           6  a62f96ba4e46c7584d248d190b6e5060  \n",
            "34570           1  6f6bad88050c94ffd6c63d4ae7c857bd  \n",
            "34571          21  d4321a13efc5244d5d410aa77f615380  \n",
            "\n",
            "[34572 rows x 31 columns]\n"
          ]
        }
      ],
      "source": [
        "import hashlib\n",
        "\n",
        "# Function to compute the checksum for a row\n",
        "def compute_checksum(row):\n",
        "    # Convert row to string and encode\n",
        "    row_str = ''.join(map(str, row.values)).encode('utf-8')\n",
        "    \n",
        "    # Compute MD5 hash (or any other hash of your choice)\n",
        "    result = hashlib.md5(row_str).hexdigest()\n",
        "    return result\n",
        "\n",
        "# Apply the function to each row and assign the result to a new column\n",
        "all_model_cases['checksum'] = all_model_cases.apply(compute_checksum, axis=1)\n",
        "\n",
        "print(all_model_cases)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "aI0HHI6YjMoQ"
      },
      "outputs": [],
      "source": [
        "all_model_cases.to_csv(my_datetime+'_311_cases.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "all_model_predictions.to_csv(my_datetime+'_311_predictions.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "ml_model_df.to_csv(my_datetime+'_311_ml_models.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "#create datetime _manifest.txt file with one filename per line\n",
        "with open(my_datetime+'_manifest.txt', 'w') as f:\n",
        "    f.write(my_datetime+'_311_cases.csv\\n')\n",
        "    f.write(my_datetime+'_311_predictions.csv\\n')\n",
        "    f.write(my_datetime+'_311_ml_models.csv\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "#create an export folder\n",
        "EXPORT_FOLDER = '~/Documents/BODC-DEI-site/database/seeders'\n",
        "#copy the csv files to the export folder\n",
        "!cp {my_datetime}_311_cases.csv {EXPORT_FOLDER}\n",
        "!cp {my_datetime}_311_predictions.csv {EXPORT_FOLDER}\n",
        "!cp {my_datetime}_311_ml_models.csv {EXPORT_FOLDER}\n",
        "!cp {my_datetime}_manifest.txt {EXPORT_FOLDER}\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "** Copy the files to the production server **"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Executing: scp -P 65002 2023-09-13_10-51-36_311_cases.csv u353344964@195.179.236.61:/home/u353344964/domains/bodc-dei.org/laravel/database/seeders\n",
            "Executing: scp -P 65002 2023-09-13_10-51-36_311_cases.csv u353344964@195.179.236.61:/home/u353344964/domains/bodc-dei.org/stagelaravel/database/seeders\n",
            "Executing: scp -P 65002 2023-09-13_10-51-36_311_predictions.csv u353344964@195.179.236.61:/home/u353344964/domains/bodc-dei.org/laravel/database/seeders\n",
            "Executing: scp -P 65002 2023-09-13_10-51-36_311_predictions.csv u353344964@195.179.236.61:/home/u353344964/domains/bodc-dei.org/stagelaravel/database/seeders\n",
            "Executing: scp -P 65002 2023-09-13_10-51-36_311_ml_models.csv u353344964@195.179.236.61:/home/u353344964/domains/bodc-dei.org/laravel/database/seeders\n",
            "Executing: scp -P 65002 2023-09-13_10-51-36_311_ml_models.csv u353344964@195.179.236.61:/home/u353344964/domains/bodc-dei.org/stagelaravel/database/seeders\n",
            "Executing: scp -P 65002 2023-09-13_10-51-36_manifest.txt u353344964@195.179.236.61:/home/u353344964/domains/bodc-dei.org/laravel/database/seeders\n",
            "Executing: scp -P 65002 2023-09-13_10-51-36_manifest.txt u353344964@195.179.236.61:/home/u353344964/domains/bodc-dei.org/stagelaravel/database/seeders\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# Define constants for servers\n",
        "PROD_USER = 'u353344964'\n",
        "PROD_HOSTNAME = '195.179.236.61'\n",
        "PORT_NUMBER = 65002\n",
        "PROD_EXPORT_FOLDER = '/home/u353344964/domains/bodc-dei.org/laravel/database/seeders'\n",
        "STAGE_EXPORT_FOLDER = '/home/u353344964/domains/bodc-dei.org/stagelaravel/database/seeders'\n",
        "\n",
        "def scp_to_server(filename, user=PROD_USER, hostname=PROD_HOSTNAME, port=PORT_NUMBER, export_folder=PROD_EXPORT_FOLDER):\n",
        "    \"\"\"Copy a file to the server using scp.\"\"\"\n",
        "    command = f\"scp -P {port} {filename} {user}@{hostname}:{export_folder}\"\n",
        "    print(f\"Executing: {command}\")\n",
        "    os.system(command)\n",
        "\n",
        "# Use the function to scp files\n",
        "files_to_copy = [\n",
        "    f\"{my_datetime}_311_cases.csv\",\n",
        "    f\"{my_datetime}_311_predictions.csv\",\n",
        "    f\"{my_datetime}_311_ml_models.csv\",\n",
        "    f\"{my_datetime}_manifest.txt\"\n",
        "]\n",
        "\n",
        "# Control where to copy\n",
        "copy_to_prod = True\n",
        "copy_to_stage = True\n",
        "\n",
        "for file in files_to_copy:\n",
        "    if copy_to_prod:\n",
        "        scp_to_server(file, export_folder=PROD_EXPORT_FOLDER)\n",
        "    if copy_to_stage:\n",
        "        scp_to_server(file, export_folder=STAGE_EXPORT_FOLDER)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
