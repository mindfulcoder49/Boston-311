{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P1BXqsllgueC"
      },
      "source": [
        "#Boston 311 Tutorial\n",
        "\n",
        "This notebook will run you through the basic usage of this package to train 3 models on the Boston 311 data and use them to predict the outcome of cases from the last 30 days"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u54v241Vh-gN"
      },
      "source": [
        "##Install the package from github using pip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "HF8wNhboPQ1z"
      },
      "outputs": [],
      "source": [
        "#This library is only needed for the Cox Regression Model, which is not included in this tutorial\n",
        "#! pip install lifelines"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "#pwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rlLnbD24LDtG",
        "outputId": "6520c1c5-4219-49a4-ba28-7d06451fdfee"
      },
      "outputs": [],
      "source": [
        "#! pip install ../"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XP7Hzen_iEAl"
      },
      "source": [
        "##Import the Boston311Model class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name: boston311\n",
            "Version: 0.1.0\n",
            "Summary: A package for training machine learning models on Boston 311 data\n",
            "Home-page: https://github.com/mindfulcoder49/Boston_311\n",
            "Author: Alex Alcivar\n",
            "Author-email: alex.g.alcivar49@gmail.com\n",
            "License: UNKNOWN\n",
            "Location: /home/briarmoss/.local/lib/python3.10/site-packages\n",
            "Requires: matplotlib, numpy, pandas, scikit-learn, tensorflow\n",
            "Required-by: \n"
          ]
        }
      ],
      "source": [
        "! pip show boston311"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "LdhJESm7eWaY"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-08 20:11:55.359441: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2023-09-08 20:11:55.973234: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2023-09-08 20:11:55.976288: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-09-08 20:11:59.334672: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        }
      ],
      "source": [
        "from boston311 import Boston311LogReg, Boston311EventDecTree, Boston311SurvDecTree"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oq06XnVjPxvg"
      },
      "source": [
        "#Get latest file URLS and Current Date Ranges"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "_2FYkUb2P1LR"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'logtree': <boston311.Boston311EventDecTree.Boston311EventDecTree at 0x7f1f794a2920>,\n",
              " 'logreg': <boston311.Boston311LogReg.Boston311LogReg at 0x7f1ffbab5720>}"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "#define daily model folder constant\n",
        "DAILY_MODEL_FOLDER = './daily_models'\n",
        "\n",
        "#define a dict for each type of 311 model, then scan all the folders in the daily model folder and load the correct model based on the folder name if it contains logtree or logreg and add it to the dict with the key being the folder name\n",
        "daily_model_dict = {}\n",
        "for folder in os.listdir(DAILY_MODEL_FOLDER):\n",
        "    if 'logtree' in folder:\n",
        "        daily_model_dict[folder] = Boston311EventDecTree()\n",
        "        daily_model_dict[folder].load(os.path.join(DAILY_MODEL_FOLDER, folder, 'logtreeproperties.json'), os.path.join(DAILY_MODEL_FOLDER, folder, 'logtree.pkl'))\n",
        "    elif 'logreg' in folder:\n",
        "        daily_model_dict[folder] = Boston311LogReg()\n",
        "        daily_model_dict[folder].load(os.path.join(DAILY_MODEL_FOLDER, folder, 'logregproperties.json'), os.path.join(DAILY_MODEL_FOLDER, folder, 'logreg.h5'))\n",
        "\n",
        "daily_model_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "from datetime import datetime, timedelta\n",
        "now = datetime.now()\n",
        "today_datestring = now.strftime(\"%Y-%m-%d\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ml_model_name</th>\n",
              "      <th>ml_model_type</th>\n",
              "      <th>id</th>\n",
              "      <th>ml_model_date</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [ml_model_name, ml_model_type, id, ml_model_date]\n",
              "Index: []"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "#define an empt pandas dataframe ml_model_df\n",
        "ml_model_df = pd.DataFrame(columns=['ml_model_name', 'ml_model_type', 'id', 'ml_model_date'])\n",
        "all_model_cases = pd.DataFrame()\n",
        "all_model_predictions = pd.DataFrame()\n",
        "\n",
        "\n",
        "ml_model_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uUMCPAELR9h7",
        "outputId": "05fcba64-1b74-4fb7-a52c-d3f8a499bcc6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing model: logtree\n",
            "Empty DataFrame\n",
            "Columns: [ml_model_name, ml_model_type, id, ml_model_date]\n",
            "Index: []\n",
            "  ml_model_name          ml_model_type       id ml_model_date\n",
            "0       logtree  Boston311EventDecTree  logtree    2023-09-08\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/briarmoss/.local/lib/python3.10/site-packages/boston311/Boston311Model.py:251: DtypeWarning: Columns (13) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(file)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files with different number of columns from File 0:  []\n",
            "Files with same number of columns as File 0:  [0]\n",
            "Files with different column order from File 0:  []\n",
            "Files with same column order as File 0:  [0]\n",
            "Processing model: logreg\n",
            "  ml_model_name          ml_model_type       id ml_model_date\n",
            "0       logtree  Boston311EventDecTree  logtree    2023-09-08\n",
            "  ml_model_name          ml_model_type       id ml_model_date\n",
            "0       logtree  Boston311EventDecTree  logtree    2023-09-08\n",
            "1        logreg        Boston311LogReg   logreg    2023-09-08\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/briarmoss/.local/lib/python3.10/site-packages/boston311/Boston311Model.py:251: DtypeWarning: Columns (13) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(file)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files with different number of columns from File 0:  []\n",
            "Files with same number of columns as File 0:  [0]\n",
            "Files with different column order from File 0:  []\n",
            "Files with same column order as File 0:  [0]\n",
            "929/929 [==============================] - 6s 6ms/step\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "\n",
        "#foreach model in the daily_model_dict set the predict_dat_range to the last 30 days and then call the predict method and save the results to a csv file\n",
        "for model_name, model in daily_model_dict.items():\n",
        "\n",
        "    print(f\"Processing model: {model_name}\")\n",
        "\n",
        "    print(ml_model_df)\n",
        "    model.predict_date_range = {'start': '2023-08-09', 'end': today_datestring}\n",
        "\n",
        "\n",
        "\n",
        "    #get file creation date for the .json file in the folder with the model_name\n",
        "    #use os.path.getctime to get the creation time of the .json file in the folder with the model_name\n",
        "    #convert the creation time to a datetime object\n",
        "    #convert the datetime object to a string in the format of %Y-%m-%d\n",
        "    #add to ml_model_df dataframe with  columns, ml_model_name, ml_model_type,ml_model_id, ml_model_date\n",
        "    ml_model_datetime = os.path.getctime(os.path.join(DAILY_MODEL_FOLDER, model_name, model_name + 'properties.json'))\n",
        "    ml_model_date = datetime.fromtimestamp(ml_model_datetime).strftime('%Y-%m-%d')\n",
        "    \n",
        "\n",
        "    ml_model_df = pd.concat([ml_model_df, pd.DataFrame([{'ml_model_name': model_name, \n",
        "                                    'ml_model_type': model.__class__.__name__,\n",
        "                                    'id': model_name,\n",
        "                                    'ml_model_date': ml_model_date}])], ignore_index=True)\n",
        "    \n",
        "    print(ml_model_df)\n",
        "\n",
        "    model_prediction = model.predict()\n",
        "    #get new dataframe with just the event_prediction column from the model_prediction dataframe\n",
        "    model_prediction_event = model_prediction[['event_prediction','case_enquiry_id']].copy()\n",
        "    model_prediction_event['ml_model_id'] = model_name\n",
        "    #add today's date to the dataframe\n",
        "    model_prediction_event['prediction_date'] = today_datestring\n",
        "    #rename the event_prediction column to prediction\n",
        "    model_prediction_event.rename(columns={'event_prediction': 'prediction'}, inplace=True)\n",
        "\n",
        "    #remove model_prediction event_prediction column\n",
        "    model_cases = model_prediction.drop('event_prediction', axis=1).copy()\n",
        "\n",
        "    #remove geom column in model_cases\n",
        "    model_cases = model_cases.drop('geom_4326', axis=1).copy()\n",
        "\n",
        "    # Add the model_cases dataframe to the all_model_cases dataframe\n",
        "    all_model_cases = pd.concat([all_model_cases, model_cases], ignore_index=True).drop_duplicates().reset_index(drop=True)\n",
        "\n",
        "    # Add the model_prediction_event dataframe to the all_model_predictions dataframe\n",
        "    all_model_predictions = pd.concat([all_model_predictions, model_prediction_event], ignore_index=True)\n",
        "\n",
        "    \n",
        "\n",
        "    \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I4dxuwJdgrZr"
      },
      "source": [
        "##Save the prediction data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "aI0HHI6YjMoQ"
      },
      "outputs": [],
      "source": [
        "all_model_cases.to_csv(today_datestring+'_311_cases.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "all_model_predictions.to_csv(today_datestring+'_311_predictions.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "ml_model_df.to_csv(today_datestring+'_311_ml_models.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "#create an export folder\n",
        "EXPORT_FOLDER = '~/Documents/BODC-DEI-site/database/seeders'\n",
        "#copy the csv files to the export folder\n",
        "!cp {today_datestring}_311_cases.csv {EXPORT_FOLDER}\n",
        "!cp {today_datestring}_311_predictions.csv {EXPORT_FOLDER}\n",
        "!cp {today_datestring}_311_ml_models.csv {EXPORT_FOLDER}\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
