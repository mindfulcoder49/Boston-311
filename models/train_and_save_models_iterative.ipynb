{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P1BXqsllgueC"
      },
      "source": [
        "#Boston 311 Tutorial\n",
        "\n",
        "This notebook will run you through the basic usage of this package to train 3 models on the Boston 311 data and use them to predict the outcome of cases from the last 30 days"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Processing /home/briarmoss/Documents/Boston_311\n",
            "  Installing build dependencies ... \u001b[?25ldone\n",
            "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
            "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25hRequirement already satisfied: scikit-learn in /home/briarmoss/.local/lib/python3.10/site-packages (from boston311==0.1.0) (1.2.2)\n",
            "Requirement already satisfied: numpy in /home/briarmoss/.local/lib/python3.10/site-packages (from boston311==0.1.0) (1.23.5)\n",
            "Requirement already satisfied: tensorflow in /home/briarmoss/.local/lib/python3.10/site-packages (from boston311==0.1.0) (2.12.0)\n",
            "Requirement already satisfied: matplotlib in /usr/lib/python3/dist-packages (from boston311==0.1.0) (3.5.1)\n",
            "Requirement already satisfied: pandas in /home/briarmoss/.local/lib/python3.10/site-packages (from boston311==0.1.0) (2.0.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /home/briarmoss/.local/lib/python3.10/site-packages (from pandas->boston311==0.1.0) (2023.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /home/briarmoss/.local/lib/python3.10/site-packages (from pandas->boston311==0.1.0) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas->boston311==0.1.0) (2022.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /home/briarmoss/.local/lib/python3.10/site-packages (from scikit-learn->boston311==0.1.0) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/briarmoss/.local/lib/python3.10/site-packages (from scikit-learn->boston311==0.1.0) (3.1.0)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /home/briarmoss/.local/lib/python3.10/site-packages (from scikit-learn->boston311==0.1.0) (1.10.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/briarmoss/.local/lib/python3.10/site-packages (from tensorflow->boston311==0.1.0) (0.32.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/lib/python3/dist-packages (from tensorflow->boston311==0.1.0) (1.16.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /home/briarmoss/.local/lib/python3.10/site-packages (from tensorflow->boston311==0.1.0) (0.2.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /home/briarmoss/.local/lib/python3.10/site-packages (from tensorflow->boston311==0.1.0) (1.14.1)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /home/briarmoss/.local/lib/python3.10/site-packages (from tensorflow->boston311==0.1.0) (3.8.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /home/briarmoss/.local/lib/python3.10/site-packages (from tensorflow->boston311==0.1.0) (2.3.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /home/briarmoss/.local/lib/python3.10/site-packages (from tensorflow->boston311==0.1.0) (3.3.0)\n",
            "Requirement already satisfied: packaging in /home/briarmoss/.local/lib/python3.10/site-packages (from tensorflow->boston311==0.1.0) (23.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /home/briarmoss/.local/lib/python3.10/site-packages (from tensorflow->boston311==0.1.0) (1.4.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /home/briarmoss/.local/lib/python3.10/site-packages (from tensorflow->boston311==0.1.0) (4.23.3)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/briarmoss/.local/lib/python3.10/site-packages (from tensorflow->boston311==0.1.0) (1.54.2)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /home/briarmoss/.local/lib/python3.10/site-packages (from tensorflow->boston311==0.1.0) (23.5.26)\n",
            "Requirement already satisfied: jax>=0.3.15 in /home/briarmoss/.local/lib/python3.10/site-packages (from tensorflow->boston311==0.1.0) (0.4.12)\n",
            "Requirement already satisfied: keras<2.13,>=2.12.0 in /home/briarmoss/.local/lib/python3.10/site-packages (from tensorflow->boston311==0.1.0) (2.12.0)\n",
            "Requirement already satisfied: tensorboard<2.13,>=2.12 in /home/briarmoss/.local/lib/python3.10/site-packages (from tensorflow->boston311==0.1.0) (2.12.3)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /home/briarmoss/.local/lib/python3.10/site-packages (from tensorflow->boston311==0.1.0) (1.6.3)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /home/briarmoss/.local/lib/python3.10/site-packages (from tensorflow->boston311==0.1.0) (0.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from tensorflow->boston311==0.1.0) (59.6.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /home/briarmoss/.local/lib/python3.10/site-packages (from tensorflow->boston311==0.1.0) (2.12.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /home/briarmoss/.local/lib/python3.10/site-packages (from tensorflow->boston311==0.1.0) (4.6.3)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /home/briarmoss/.local/lib/python3.10/site-packages (from tensorflow->boston311==0.1.0) (16.0.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/lib/python3/dist-packages (from astunparse>=1.6.0->tensorflow->boston311==0.1.0) (0.37.1)\n",
            "Requirement already satisfied: ml-dtypes>=0.1.0 in /home/briarmoss/.local/lib/python3.10/site-packages (from jax>=0.3.15->tensorflow->boston311==0.1.0) (0.2.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /home/briarmoss/.local/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow->boston311==0.1.0) (1.0.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/briarmoss/.local/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow->boston311==0.1.0) (0.7.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /home/briarmoss/.local/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow->boston311==0.1.0) (2.3.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /home/briarmoss/.local/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow->boston311==0.1.0) (3.4.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/lib/python3/dist-packages (from tensorboard<2.13,>=2.12->tensorflow->boston311==0.1.0) (2.25.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/briarmoss/.local/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow->boston311==0.1.0) (2.20.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/briarmoss/.local/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow->boston311==0.1.0) (5.3.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /home/briarmoss/.local/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow->boston311==0.1.0) (4.9)\n",
            "Requirement already satisfied: urllib3<2.0 in /usr/lib/python3/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow->boston311==0.1.0) (1.26.5)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/briarmoss/.local/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow->boston311==0.1.0) (0.3.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/briarmoss/.local/lib/python3.10/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow->boston311==0.1.0) (1.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/briarmoss/.local/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow->boston311==0.1.0) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /home/briarmoss/.local/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow->boston311==0.1.0) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/lib/python3/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow->boston311==0.1.0) (3.2.0)\n",
            "Building wheels for collected packages: boston311\n",
            "  Building wheel for boston311 (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for boston311: filename=boston311-0.1.0-py3-none-any.whl size=16081 sha256=c4cea62fb5aad2b62def42bee1d54b6f25068a88bb2c98df406a26eef41d7204\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-uugfpdrq/wheels/3d/69/ee/0a6ac96b9c09c948fc0e74f2724a9703aa39749a41fa757c9e\n",
            "Successfully built boston311\n",
            "Installing collected packages: boston311\n",
            "  Attempting uninstall: boston311\n",
            "    Found existing installation: boston311 0.1.0\n",
            "    Uninstalling boston311-0.1.0:\n",
            "      Successfully uninstalled boston311-0.1.0\n",
            "Successfully installed boston311-0.1.0\n"
          ]
        }
      ],
      "source": [
        "! pip install ../"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XP7Hzen_iEAl"
      },
      "source": [
        "##Import the Boston311Model class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "LdhJESm7eWaY"
      },
      "outputs": [],
      "source": [
        "from boston311 import Boston311LogReg, Boston311EventDecTree, Boston311SurvDecTree\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oq06XnVjPxvg"
      },
      "source": [
        "## Get latest file URLS and Current Date Ranges"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "_2FYkUb2P1LR"
      },
      "outputs": [],
      "source": [
        "latest_URLS = Boston311LogReg.get311URLs()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mpg9Czm3QDpu",
        "outputId": "5e2b399b-0999-45d4-f9f9-d80ec19941ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'2023': 'https://data.boston.gov/dataset/8048697b-ad64-4bfc-b090-ee00169f2323/resource/e6013a93-1321-4f2a-bf91-8d8a02f1e62f/download/tmp4i_c_2hr.csv', '2022': 'https://data.boston.gov/dataset/8048697b-ad64-4bfc-b090-ee00169f2323/resource/81a7b022-f8fc-4da5-80e4-b160058ca207/download/tmpfm8veglw.csv', '2021': 'https://data.boston.gov/dataset/8048697b-ad64-4bfc-b090-ee00169f2323/resource/f53ebccd-bc61-49f9-83db-625f209c95f5/download/tmp88p9g82n.csv', '2020': 'https://data.boston.gov/dataset/8048697b-ad64-4bfc-b090-ee00169f2323/resource/6ff6a6fd-3141-4440-a880-6f60a37fe789/download/tmpcv_10m2s.csv', '2019': 'https://data.boston.gov/dataset/8048697b-ad64-4bfc-b090-ee00169f2323/resource/ea2e4696-4a2d-429c-9807-d02eb92e0222/download/tmpcje3ep_w.csv', '2018': 'https://data.boston.gov/dataset/8048697b-ad64-4bfc-b090-ee00169f2323/resource/2be28d90-3a90-4af1-a3f6-f28c1e25880a/download/tmp7602cia8.csv', '2017': 'https://data.boston.gov/dataset/8048697b-ad64-4bfc-b090-ee00169f2323/resource/30022137-709d-465e-baae-ca155b51927d/download/tmpzccn8u4q.csv', '2016': 'https://data.boston.gov/dataset/8048697b-ad64-4bfc-b090-ee00169f2323/resource/b7ea6b1b-3ca4-4c5b-9713-6dc1db52379a/download/tmpzxzxeqfb.csv', '2015': 'https://data.boston.gov/dataset/8048697b-ad64-4bfc-b090-ee00169f2323/resource/c9509ab4-6f6d-4b97-979a-0cf2a10c922b/download/tmphrybkxuh.csv', '2014': 'https://data.boston.gov/dataset/8048697b-ad64-4bfc-b090-ee00169f2323/resource/bdae89c8-d4ce-40e9-a6e1-a5203953a2e0/download/tmp8afxvko_.csv', '2013': 'https://data.boston.gov/dataset/8048697b-ad64-4bfc-b090-ee00169f2323/resource/407c5cd0-f764-4a41-adf8-054ff535049e/download/tmpyzk_wmya.csv', '2012': 'https://data.boston.gov/dataset/8048697b-ad64-4bfc-b090-ee00169f2323/resource/382e10d9-1864-40ba-bef6-4eea3c75463c/download/tmpeyvgdt5u.csv', '2011': 'https://data.boston.gov/dataset/8048697b-ad64-4bfc-b090-ee00169f2323/resource/94b499d9-712a-4d2a-b790-7ceec5c9c4b1/download/tmp_9ogynu0.csv'}\n"
          ]
        }
      ],
      "source": [
        "print(latest_URLS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uUMCPAELR9h7",
        "outputId": "05fcba64-1b74-4fb7-a52c-d3f8a499bcc6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-09-19 2023-08-20 2023-09-20\n"
          ]
        }
      ],
      "source": [
        "from datetime import datetime, timedelta\n",
        "now = datetime.now()\n",
        "thirty_days = timedelta(days=30)\n",
        "thirty_days_ago = now - thirty_days\n",
        "today_datestring = now.strftime(\"%Y-%m-%d\")\n",
        "thirty_days_ago_datestring = thirty_days_ago.strftime(\"%Y-%m-%d\")\n",
        "tomorrow_datestring = (datetime.today() + timedelta(days=1)).strftime('%Y-%m-%d')\n",
        "\n",
        "print(today_datestring, thirty_days_ago_datestring, tomorrow_datestring)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "#set model folder constant\n",
        "MODEL_FOLDER = './daily_models'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NN_UiAIvb9MT"
      },
      "source": [
        "##Define several models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'dropColumnValues': {'source': ['City Worker App', 'Employee Generated']}, 'survivalTimeMin': 0, 'survivalTimeFill': '2023-09-20'}\n",
            "\n",
            "\n",
            "{'dropColumnValues': {'source': ['City Worker App', 'Employee Generated']}, 'survivalTimeMin': 0, 'survivalTimeFill': '2023-09-20'}\n",
            "\n",
            "\n",
            "{'dropColumnValues': {'source': ['City Worker App', 'Employee Generated']}, 'survivalTimeMin': 0, 'survivalTimeFill': '2023-09-20'}\n",
            "\n",
            "\n",
            "{'dropColumnValues': {'source': ['City Worker App', 'Employee Generated']}, 'survivalTimeMin': 0, 'survivalTimeFill': '2023-09-20'}\n",
            "\n",
            "\n",
            "{'dropColumnValues': {'source': ['City Worker App', 'Employee Generated']}, 'survivalTimeMin': 0, 'survivalTimeFill': '2023-09-20'}\n",
            "\n",
            "\n",
            "{'dropColumnValues': {'source': ['City Worker App', 'Employee Generated']}, 'survivalTimeMin': 0, 'survivalTimeFill': '2023-09-20'}\n",
            "\n",
            "\n",
            "{'dropColumnValues': {'source': ['City Worker App', 'Employee Generated']}, 'survivalTimeMin': 0, 'survivalTimeFill': '2023-09-20'}\n",
            "\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from typing import List, Dict, Any\n",
        "from itertools import combinations\n",
        "\n",
        "# Function to define an iteration scenario\n",
        "def define_iteration_scenario(feature_columns: List[str], time_spans: List[Dict[str, str]]) -> Dict[str, Any]:\n",
        "    scenario = {\n",
        "        'feature_columns': feature_columns,\n",
        "        'time_spans': time_spans\n",
        "    }\n",
        "    return scenario\n",
        "\n",
        "# Function to produce all the models based on an iteration scenario\n",
        "def generate_models(scenario: Dict[str, Any], latest_urls: Dict[str, str], model_class, combination_size=1):\n",
        "    generated_models = {}\n",
        "\n",
        "    scenario_dict = {'dropColumnValues': {'source': ['City Worker App', 'Employee Generated']}, 'survivalTimeMin': 0}\n",
        "    if model_class == Boston311SurvDecTree:\n",
        "        scenario_dict['survivalTimeFill'] = tomorrow_datestring\n",
        "    \n",
        "    # Iterate through all paired combinations of feature columns\n",
        "    for feature_pair in combinations(scenario['feature_columns'], combination_size):\n",
        "        \n",
        "        # Iterate through all time spans\n",
        "        for time_span in scenario['time_spans']:\n",
        "            train_start = time_span['start']\n",
        "            train_end = time_span['end']\n",
        "            \n",
        "            # Create a model\n",
        "            model = model_class(\n",
        "                train_date_range={'start': train_start, 'end': train_end},\n",
        "                predict_date_range={'start': thirty_days_ago_datestring, 'end': tomorrow_datestring},  # Adjust as needed\n",
        "                feature_columns=list(feature_pair),\n",
        "                scenario=scenario_dict, \n",
        "                files_dict=latest_urls\n",
        "            )\n",
        "            \n",
        "            #create variable to hold model name and add the model_class.__name__\n",
        "            model_name = model_class.__name__\n",
        "            #append the feature pair by iterating over it\n",
        "            for feature in feature_pair:\n",
        "                model_name += f'_{feature}'\n",
        "\n",
        "            #store model with key as class name and feature pair\n",
        "            generated_models[model_name] = model\n",
        "            \n",
        "    return generated_models\n",
        "\n",
        "# Example usage\n",
        "feature_columns_to_use = ['type', 'queue', 'source', 'subject', 'reason', 'department', 'ward_number']  # Replace with your actual feature columns\n",
        "\n",
        "#feature_columns_to_use = ['queue', 'ward_number'] \n",
        "\n",
        "time_spans_to_use = [\n",
        "    {'start': '2022-01-01', 'end': thirty_days_ago_datestring},\n",
        "]  # Replace with your actual time spans\n",
        "\n",
        "# Define the iteration scenario\n",
        "iteration_scenario = define_iteration_scenario(feature_columns_to_use, time_spans_to_use)\n",
        "\n",
        "# Generate the models (replace `Boston311LogReg` with the model class you want to use)\n",
        "# latest_URLS would be the actual URLs you have\n",
        "#generated_models = generate_models(iteration_scenario, latest_urls=latest_URLS, model_class=Boston311LogReg, combination_size=1)\n",
        "#Add the other models\n",
        "#generated_models.update(generate_models(iteration_scenario, latest_urls=latest_URLS, model_class=Boston311EventDecTree, combination_size=1))\n",
        "#generated_models.update(generate_models(iteration_scenario, latest_urls=latest_URLS, model_class=Boston311SurvDecTree, combination_size=1))\n",
        "#run the same but with combination_size = 2\n",
        "#generated_models.update(generate_models(iteration_scenario, latest_urls=latest_URLS, model_class=Boston311LogReg, combination_size=2))\n",
        "#generated_models.update(generate_models(iteration_scenario, latest_urls=latest_URLS, model_class=Boston311EventDecTree, combination_size=2))\n",
        "#generated_models.update(generate_models(iteration_scenario, latest_urls=latest_URLS, model_class=Boston311SurvDecTree, combination_size=2))\n",
        "# Now, `generated_models` contains all the models based on the defined iteration scenario\n",
        "generated_models = (generate_models(iteration_scenario, latest_urls=latest_URLS, model_class=Boston311SurvDecTree, combination_size=6))\n",
        "#print model keys\n",
        "#print(generated_models.keys())\n",
        "\n",
        "#for each model in generated_models print the scenario\n",
        "for model in generated_models:\n",
        "    print(generated_models[model].scenario)\n",
        "    #print newline\n",
        "    print('\\n')\n",
        "\n",
        "len(generated_models) \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "#get current datetime in Boston timezone as string\n",
        "from datetime import datetime\n",
        "from pytz import timezone\n",
        "import pytz\n",
        "boston = timezone('US/Eastern')\n",
        "now = datetime.now(boston)\n",
        "today_datestring = now.strftime(\"%Y-%m-%d\")\n",
        "#get time in Boston timezone as string for a filename\n",
        "now = datetime.now(boston)\n",
        "time_string = now.strftime(\"%H-%M-%S\")\n",
        "#define datetime string\n",
        "my_datetime = today_datestring + '_' + time_string "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sSSkyth-2K3A"
      },
      "source": [
        "## Train all the models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/briarmoss/.local/lib/python3.10/site-packages/boston311/Boston311Model.py:255: DtypeWarning: Columns (13) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(file)\n",
            "/home/briarmoss/.local/lib/python3.10/site-packages/boston311/Boston311Model.py:255: DtypeWarning: Columns (13) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(file)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files with different number of columns from File 0:  []\n",
            "Files with same number of columns as File 0:  [0, 1]\n",
            "Files with different column order from File 0:  []\n",
            "Files with same column order as File 0:  [0, 1]\n",
            "training model: Boston311SurvDecTree_type_queue_source_subject_reason_department\n",
            "Starting Training at 2023-09-19 23:07:32.143879\n",
            "Testing accuracy: 0.6945399828030955\n",
            "Ending Training at 2023-09-19 23:07:38.592320\n",
            "Training took 0:00:06.448441\n",
            "Done training model: Boston311SurvDecTree_type_queue_source_subject_reason_department accuracy: 0.6945399828030955\n",
            "training model: Boston311SurvDecTree_type_queue_source_subject_reason_ward_number\n",
            "Starting Training at 2023-09-19 23:07:41.775942\n",
            "Testing accuracy: 0.7000214961306965\n",
            "Ending Training at 2023-09-19 23:07:50.498504\n",
            "Training took 0:00:08.722562\n",
            "Done training model: Boston311SurvDecTree_type_queue_source_subject_reason_ward_number accuracy: 0.7000214961306965\n",
            "training model: Boston311SurvDecTree_type_queue_source_subject_department_ward_number\n",
            "Starting Training at 2023-09-19 23:07:53.715689\n",
            "Testing accuracy: 0.7000214961306965\n",
            "Ending Training at 2023-09-19 23:08:00.623972\n",
            "Training took 0:00:06.908283\n",
            "Done training model: Boston311SurvDecTree_type_queue_source_subject_department_ward_number accuracy: 0.7000214961306965\n",
            "training model: Boston311SurvDecTree_type_queue_source_reason_department_ward_number\n",
            "Starting Training at 2023-09-19 23:08:03.816690\n",
            "Testing accuracy: 0.6998304194133945\n",
            "Ending Training at 2023-09-19 23:08:11.293229\n",
            "Training took 0:00:07.476539\n",
            "Done training model: Boston311SurvDecTree_type_queue_source_reason_department_ward_number accuracy: 0.6998304194133945\n",
            "training model: Boston311SurvDecTree_type_queue_subject_reason_department_ward_number\n",
            "Starting Training at 2023-09-19 23:08:14.505710\n",
            "Testing accuracy: 0.7008932836533869\n",
            "Ending Training at 2023-09-19 23:08:22.037528\n",
            "Training took 0:00:07.531818\n",
            "Done training model: Boston311SurvDecTree_type_queue_subject_reason_department_ward_number accuracy: 0.7008932836533869\n",
            "training model: Boston311SurvDecTree_type_source_subject_reason_department_ward_number\n",
            "Starting Training at 2023-09-19 23:08:24.853855\n",
            "Testing accuracy: 0.6822991306009363\n",
            "Ending Training at 2023-09-19 23:08:29.282302\n",
            "Training took 0:00:04.428447\n",
            "Done training model: Boston311SurvDecTree_type_source_subject_reason_department_ward_number accuracy: 0.6822991306009363\n",
            "training model: Boston311SurvDecTree_queue_source_subject_reason_department_ward_number\n",
            "Starting Training at 2023-09-19 23:08:32.258058\n",
            "Testing accuracy: 0.6965940575140919\n",
            "Ending Training at 2023-09-19 23:08:37.424356\n",
            "Training took 0:00:05.166298\n",
            "Done training model: Boston311SurvDecTree_queue_source_subject_reason_department_ward_number accuracy: 0.6965940575140919\n"
          ]
        }
      ],
      "source": [
        "#define accuracy dict\n",
        "model_accuracy = {}\n",
        "#get the first model and save the results of the load_data method to a dataframe\n",
        "model = list(generated_models.values())[0]\n",
        "df = model.load_data()\n",
        "\n",
        "for name, model in generated_models.items():\n",
        "    #print the model we are training\n",
        "    print(\"training model: \" + name)\n",
        "    test_acc = model.run_pipeline(df)\n",
        "    #add model name and accuracy to dict\n",
        "    model_accuracy[name] = test_acc\n",
        "    #print Done training model\n",
        "    print(\"Done training model: \" + name + \" accuracy: \" + str(test_acc))\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model_name, accuracy\n",
            "Boston311SurvDecTree_type_queue_subject_reason_department_ward_number  :  0.7008932836533869\n",
            "Boston311SurvDecTree_type_queue_source_subject_reason_ward_number  :  0.7000214961306965\n",
            "Boston311SurvDecTree_type_queue_source_subject_department_ward_number  :  0.7000214961306965\n",
            "Boston311SurvDecTree_type_queue_source_reason_department_ward_number  :  0.6998304194133945\n",
            "Boston311SurvDecTree_queue_source_subject_reason_department_ward_number  :  0.6965940575140919\n",
            "Boston311SurvDecTree_type_queue_source_subject_reason_department  :  0.6945399828030955\n",
            "Boston311SurvDecTree_type_source_subject_reason_department_ward_number  :  0.6822991306009363\n"
          ]
        }
      ],
      "source": [
        "#sort the model accuracy dict by value\n",
        "model_accuracy = dict(sorted(model_accuracy.items(), key=lambda item: item[1], reverse=True))\n",
        "\n",
        "#print header for data\n",
        "print(\"model_name, accuracy\")\n",
        "\n",
        "#print model accuracy dict nicely\n",
        "for key, value in model_accuracy.items():\n",
        "    print(key, ' : ', str(value))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "#save the model accuracy dict to a csv\n",
        "import csv\n",
        "with open(f'{MODEL_FOLDER}/model_accuracy_{my_datetime}.csv', 'w') as f:\n",
        "    for key in model_accuracy.keys():\n",
        "        f.write(\"%s,%s\\n\"%(key,model_accuracy[key]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "28"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import gc\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [],
      "source": [
        "#run the predict method on each model\n",
        "\n",
        "#for name, model in generated_models.items():\n",
        "   #print the model we are predicting\n",
        "#    print(\"predicting model: \" + name)\n",
        "#    model.predict()\n",
        "    #print Dont predicting model\n",
        "#    print(\"Done predicting model: \" + name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "import datetime\n",
        "\n",
        "def save_model_to_dir(model, folder_name):\n",
        "    dir_path = os.path.join(MODEL_FOLDER, folder_name)\n",
        "    \n",
        "    if not os.path.exists(dir_path):\n",
        "        os.mkdir(dir_path)\n",
        "    \n",
        "    timestamp = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "    model_name = timestamp + \"_\" + model.model_type\n",
        "    properties_name = model_name\n",
        "    \n",
        "    model.save(dir_path, model_name, properties_name)\n",
        "\n",
        "\n",
        "# Iterate over models and save\n",
        "for model_name, model in generated_models.items():\n",
        "    save_model_to_dir(model, model_name)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
