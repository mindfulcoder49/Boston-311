{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P1BXqsllgueC"
      },
      "source": [
        "#Boston 311 Tutorial\n",
        "\n",
        "This notebook will run you through the basic usage of this package to train 3 models on the Boston 311 mydata and use them to predict the outcome of cases from the last 30 days"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "\u001b[33mWARNING: Ignoring invalid distribution -ensorflow (/home/briarmoss/.local/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ensorflow (/home/briarmoss/.local/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: keras-tuner in /home/briarmoss/.local/lib/python3.10/site-packages (1.4.3)\n",
            "Requirement already satisfied: packaging in /home/briarmoss/.local/lib/python3.10/site-packages (from keras-tuner) (23.1)\n",
            "Requirement already satisfied: requests in /usr/lib/python3/dist-packages (from keras-tuner) (2.25.1)\n",
            "Requirement already satisfied: keras-core in /home/briarmoss/.local/lib/python3.10/site-packages (from keras-tuner) (0.1.7)\n",
            "Requirement already satisfied: kt-legacy in /home/briarmoss/.local/lib/python3.10/site-packages (from keras-tuner) (1.0.5)\n",
            "Requirement already satisfied: h5py in /home/briarmoss/.local/lib/python3.10/site-packages (from keras-core->keras-tuner) (3.8.0)\n",
            "Requirement already satisfied: namex in /home/briarmoss/.local/lib/python3.10/site-packages (from keras-core->keras-tuner) (0.0.7)\n",
            "Requirement already satisfied: absl-py in /home/briarmoss/.local/lib/python3.10/site-packages (from keras-core->keras-tuner) (1.4.0)\n",
            "Requirement already satisfied: rich in /home/briarmoss/.local/lib/python3.10/site-packages (from keras-core->keras-tuner) (13.5.3)\n",
            "Requirement already satisfied: dm-tree in /home/briarmoss/.local/lib/python3.10/site-packages (from keras-core->keras-tuner) (0.1.8)\n",
            "Requirement already satisfied: numpy in /home/briarmoss/.local/lib/python3.10/site-packages (from keras-core->keras-tuner) (1.23.5)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/briarmoss/.local/lib/python3.10/site-packages (from rich->keras-core->keras-tuner) (2.15.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/briarmoss/.local/lib/python3.10/site-packages (from rich->keras-core->keras-tuner) (3.0.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /home/briarmoss/.local/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras-core->keras-tuner) (0.1.2)\n",
            "\u001b[33mWARNING: Ignoring invalid distribution -ensorflow (/home/briarmoss/.local/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "! pip install keras-tuner"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "\u001b[33mWARNING: Ignoring invalid distribution -ensorflow (/home/briarmoss/.local/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ensorflow (/home/briarmoss/.local/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mProcessing /home/briarmoss/Documents/Boston_311\n",
            "  Installing build dependencies ... \u001b[?25ldone\n",
            "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
            "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25hRequirement already satisfied: numpy in /home/briarmoss/.local/lib/python3.10/site-packages (from boston311==0.1.0) (1.23.5)\n",
            "Requirement already satisfied: tensorflow in /home/briarmoss/.local/lib/python3.10/site-packages (from boston311==0.1.0) (2.13.0)\n",
            "Requirement already satisfied: pandas in /home/briarmoss/.local/lib/python3.10/site-packages (from boston311==0.1.0) (2.0.1)\n",
            "Requirement already satisfied: scikit-learn in /home/briarmoss/.local/lib/python3.10/site-packages (from boston311==0.1.0) (1.2.2)\n",
            "Requirement already satisfied: matplotlib in /home/briarmoss/.local/lib/python3.10/site-packages (from boston311==0.1.0) (3.7.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /home/briarmoss/.local/lib/python3.10/site-packages (from matplotlib->boston311==0.1.0) (1.4.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /home/briarmoss/.local/lib/python3.10/site-packages (from matplotlib->boston311==0.1.0) (1.0.7)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /home/briarmoss/.local/lib/python3.10/site-packages (from matplotlib->boston311==0.1.0) (2.8.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/lib/python3/dist-packages (from matplotlib->boston311==0.1.0) (2.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /home/briarmoss/.local/lib/python3.10/site-packages (from matplotlib->boston311==0.1.0) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/lib/python3/dist-packages (from matplotlib->boston311==0.1.0) (9.0.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /home/briarmoss/.local/lib/python3.10/site-packages (from matplotlib->boston311==0.1.0) (4.39.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /home/briarmoss/.local/lib/python3.10/site-packages (from matplotlib->boston311==0.1.0) (0.11.0)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /home/briarmoss/.local/lib/python3.10/site-packages (from pandas->boston311==0.1.0) (2023.3)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas->boston311==0.1.0) (2022.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /home/briarmoss/.local/lib/python3.10/site-packages (from scikit-learn->boston311==0.1.0) (1.2.0)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /home/briarmoss/.local/lib/python3.10/site-packages (from scikit-learn->boston311==0.1.0) (1.10.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/briarmoss/.local/lib/python3.10/site-packages (from scikit-learn->boston311==0.1.0) (3.1.0)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /home/briarmoss/.local/lib/python3.10/site-packages (from tensorflow->boston311==0.1.0) (0.4.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /home/briarmoss/.local/lib/python3.10/site-packages (from tensorflow->boston311==0.1.0) (3.3.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /home/briarmoss/.local/lib/python3.10/site-packages (from tensorflow->boston311==0.1.0) (1.14.1)\n",
            "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in /home/briarmoss/.local/lib/python3.10/site-packages (from tensorflow->boston311==0.1.0) (4.5.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/briarmoss/.local/lib/python3.10/site-packages (from tensorflow->boston311==0.1.0) (0.32.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /home/briarmoss/.local/lib/python3.10/site-packages (from tensorflow->boston311==0.1.0) (3.8.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /home/briarmoss/.local/lib/python3.10/site-packages (from tensorflow->boston311==0.1.0) (3.20.3)\n",
            "Requirement already satisfied: keras<2.14,>=2.13.1 in /home/briarmoss/.local/lib/python3.10/site-packages (from tensorflow->boston311==0.1.0) (2.13.1)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/lib/python3/dist-packages (from tensorflow->boston311==0.1.0) (1.16.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /home/briarmoss/.local/lib/python3.10/site-packages (from tensorflow->boston311==0.1.0) (0.2.0)\n",
            "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from tensorflow->boston311==0.1.0) (59.6.0)\n",
            "Requirement already satisfied: tensorboard<2.14,>=2.13 in /home/briarmoss/.local/lib/python3.10/site-packages (from tensorflow->boston311==0.1.0) (2.13.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /home/briarmoss/.local/lib/python3.10/site-packages (from tensorflow->boston311==0.1.0) (1.4.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/briarmoss/.local/lib/python3.10/site-packages (from tensorflow->boston311==0.1.0) (1.54.2)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /home/briarmoss/.local/lib/python3.10/site-packages (from tensorflow->boston311==0.1.0) (16.0.0)\n",
            "Requirement already satisfied: flatbuffers>=23.1.21 in /home/briarmoss/.local/lib/python3.10/site-packages (from tensorflow->boston311==0.1.0) (23.5.9)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /home/briarmoss/.local/lib/python3.10/site-packages (from tensorflow->boston311==0.1.0) (1.6.3)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /home/briarmoss/.local/lib/python3.10/site-packages (from tensorflow->boston311==0.1.0) (2.3.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in /home/briarmoss/.local/lib/python3.10/site-packages (from tensorflow->boston311==0.1.0) (2.13.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/lib/python3/dist-packages (from astunparse>=1.6.0->tensorflow->boston311==0.1.0) (0.37.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /home/briarmoss/.local/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow->boston311==0.1.0) (2.3.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/lib/python3/dist-packages (from tensorboard<2.14,>=2.13->tensorflow->boston311==0.1.0) (2.25.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/briarmoss/.local/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow->boston311==0.1.0) (2.18.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /home/briarmoss/.local/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow->boston311==0.1.0) (3.4.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /home/briarmoss/.local/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow->boston311==0.1.0) (1.0.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/briarmoss/.local/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow->boston311==0.1.0) (0.7.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/briarmoss/.local/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow->boston311==0.1.0) (5.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/briarmoss/.local/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow->boston311==0.1.0) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /home/briarmoss/.local/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow->boston311==0.1.0) (4.9)\n",
            "Requirement already satisfied: urllib3<2.0 in /usr/lib/python3/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow->boston311==0.1.0) (1.26.5)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/briarmoss/.local/lib/python3.10/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow->boston311==0.1.0) (1.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/briarmoss/.local/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow->boston311==0.1.0) (2.1.2)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /home/briarmoss/.local/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow->boston311==0.1.0) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/lib/python3/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow->boston311==0.1.0) (3.2.0)\n",
            "Building wheels for collected packages: boston311\n",
            "  Building wheel for boston311 (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for boston311: filename=boston311-0.1.0-py3-none-any.whl size=22809 sha256=3e82cd8a45963de83ce526dc5ad34944a595704043cd18875862c88c968067d2\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-dn6hso54/wheels/3d/69/ee/0a6ac96b9c09c948fc0e74f2724a9703aa39749a41fa757c9e\n",
            "Successfully built boston311\n",
            "\u001b[33mWARNING: Ignoring invalid distribution -ensorflow (/home/briarmoss/.local/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mInstalling collected packages: boston311\n",
            "  Attempting uninstall: boston311\n",
            "\u001b[33m    WARNING: Ignoring invalid distribution -ensorflow (/home/briarmoss/.local/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m    Found existing installation: boston311 0.1.0\n",
            "    Uninstalling boston311-0.1.0:\n",
            "      Successfully uninstalled boston311-0.1.0\n",
            "\u001b[33mWARNING: Ignoring invalid distribution -ensorflow (/home/briarmoss/.local/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mSuccessfully installed boston311-0.1.0\n"
          ]
        }
      ],
      "source": [
        "! pip install ../"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XP7Hzen_iEAl"
      },
      "source": [
        "##Import the Boston311Model class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "import re\n",
        "import sys\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "LdhJESm7eWaY"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-29 19:44:55.501583: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2023-09-29 19:44:57.853353: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2023-09-29 19:44:57.873720: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-09-29 19:45:05.160563: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend\n"
          ]
        }
      ],
      "source": [
        "from boston311 import Boston311LogReg, Boston311EventDecTree, Boston311SurvDecTree, Boston311KerasNLP\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load extra features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "#get current datetime in Boston timezone as string\n",
        "from datetime import datetime\n",
        "from pytz import timezone\n",
        "import pytz\n",
        "boston = timezone('US/Eastern')\n",
        "now = datetime.now(boston)\n",
        "today_datestring = now.strftime(\"%Y-%m-%d\")\n",
        "#get time in Boston timezone as string for a filename\n",
        "now = datetime.now(boston)\n",
        "time_string = now.strftime(\"%H-%M-%S\")\n",
        "#define datetime string\n",
        "my_datetime = today_datestring + '_' + time_string \n",
        "\n",
        "#format tomorrows date as yyyy-mm-dd\n",
        "tomorrows_date =  now + pd.DateOffset(days=1)\n",
        "tomorrows_datestring = tomorrows_date.strftime(\"%Y-%m-%d\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "#set path to mydata\n",
        "EXTRA_mydata_FILE = './cls_and_pooled_embeddings_with_service_id.csv'\n",
        "json_file = './daily_models/Boston311KerasNLP/20230925_143704_Boston311KerasNLP.json'\n",
        "model_file = './daily_models/Boston311KerasNLP/20230925_143704_Boston311KerasNLP.h5'\n",
        "kerasNLP_model = Boston311KerasNLP()\n",
        "kerasNLP_model.load( json_file, model_file)\n",
        "kerasNLP_model.predict_date_rang = {'start':'2023-08-27', 'end':tomorrows_datestring}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/briarmoss/.local/lib/python3.10/site-packages/boston311/Boston311Model.py:259: DtypeWarning: Columns (13) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(file)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files with different number of columns from File 0:  []\n",
            "Files with same number of columns as File 0:  [0]\n",
            "Files with different column order from File 0:  []\n",
            "Files with same column order as File 0:  [0]\n"
          ]
        }
      ],
      "source": [
        "data = kerasNLP_model.load_data( 'predict' )\n",
        "data = kerasNLP_model.enhance_data( data, 'predict')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "clean_data = kerasNLP_model.clean_data_for_prediction( data )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>case_enquiry_id</th>\n",
              "      <th>event</th>\n",
              "      <th>survival_time_hours</th>\n",
              "      <th>type_Abandoned Bicycle</th>\n",
              "      <th>type_Abandoned Building</th>\n",
              "      <th>type_Abandoned Vehicles</th>\n",
              "      <th>type_Abandoned Vehicles - Private Tow</th>\n",
              "      <th>type_Aircraft Noise Disturbance</th>\n",
              "      <th>type_Alert Boston</th>\n",
              "      <th>type_Animal Found</th>\n",
              "      <th>...</th>\n",
              "      <th>ward_number_20</th>\n",
              "      <th>ward_number_21</th>\n",
              "      <th>ward_number_22</th>\n",
              "      <th>ward_number_3</th>\n",
              "      <th>ward_number_4</th>\n",
              "      <th>ward_number_5</th>\n",
              "      <th>ward_number_6</th>\n",
              "      <th>ward_number_7</th>\n",
              "      <th>ward_number_8</th>\n",
              "      <th>ward_number_9</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 438 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "  case_enquiry_id event survival_time_hours  type_Abandoned Bicycle   \n",
              "0             NaN   NaN                 NaN                   False  \\\n",
              "1             NaN   NaN                 NaN                   False   \n",
              "2             NaN   NaN                 NaN                   False   \n",
              "3             NaN   NaN                 NaN                   False   \n",
              "4             NaN   NaN                 NaN                   False   \n",
              "\n",
              "   type_Abandoned Building  type_Abandoned Vehicles   \n",
              "0                    False                    False  \\\n",
              "1                    False                    False   \n",
              "2                    False                    False   \n",
              "3                    False                    False   \n",
              "4                    False                    False   \n",
              "\n",
              "   type_Abandoned Vehicles - Private Tow  type_Aircraft Noise Disturbance   \n",
              "0                                  False                            False  \\\n",
              "1                                  False                            False   \n",
              "2                                  False                            False   \n",
              "3                                  False                            False   \n",
              "4                                  False                            False   \n",
              "\n",
              "   type_Alert Boston  type_Animal Found  ...  ward_number_20  ward_number_21   \n",
              "0              False              False  ...           False           False  \\\n",
              "1              False              False  ...           False           False   \n",
              "2              False              False  ...           False           False   \n",
              "3              False              False  ...           False           False   \n",
              "4              False              False  ...           False           False   \n",
              "\n",
              "   ward_number_22  ward_number_3  ward_number_4  ward_number_5  ward_number_6   \n",
              "0            True          False          False          False          False  \\\n",
              "1            True          False          False          False          False   \n",
              "2            True          False          False          False          False   \n",
              "3           False          False          False          False          False   \n",
              "4            True          False          False          False          False   \n",
              "\n",
              "   ward_number_7  ward_number_8  ward_number_9  \n",
              "0          False          False          False  \n",
              "1          False          False          False  \n",
              "2          False          False          False  \n",
              "3          False          False          False  \n",
              "4          False          False          False  \n",
              "\n",
              "[5 rows x 438 columns]"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "clean_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mydata = None\n",
        "case_data_file = 'case_data.pkl'\n",
        "mydata = None\n",
        "\n",
        "X = None\n",
        "\n",
        "if os.path.exists(case_data_file):\n",
        "    mydata = pickle.load(open(case_data_file, \"rb\"))\n",
        "else:\n",
        "    mydata = kerasNLP_model.load_data()\n",
        "\n",
        "    pickle.dump(mydata, open(case_data_file, \"wb\"))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mydata['case_enquiry_id']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mydata = kerasNLP_model.enhance_data(mydata)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mydata = kerasNLP_model.apply_scenario(mydata)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "mydata = kerasNLP_model.clean_data(mydata)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(mydata['case_enquiry_id'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from ast import literal_eval\n",
        "import pickle\n",
        "\n",
        "pickle_file = 'dataframe.pkl'\n",
        "\n",
        "X = None\n",
        "\n",
        "if os.path.exists(pickle_file):\n",
        "    X = pickle.load(open(pickle_file, \"rb\"))\n",
        "else:\n",
        "    X = pd.read_csv(EXTRA_mydata_FILE)\n",
        "\n",
        "    #rename service_request_id to case_enquiry_id\n",
        "    X.rename(columns={'service_request_id':'case_enquiry_id'}, inplace=True)\n",
        "    #remove all rows where case_enquiry_id is non-numeric\n",
        "    #X = X[X['case_enquiry_id'].str.isnumeric()]\n",
        "    #convert case_enquiry_id to int64\n",
        "    #X['case_enquiry_id'] = X['case_enquiry_id'].astype('int64')\n",
        "\n",
        "    # Convert stringified arrays back to NumPy arrays\n",
        "    X['cls_embedding'] = X['cls_embedding'].apply(literal_eval).apply(np.array)\n",
        "    X['pooled_embedding'] = X['pooled_embedding'].apply(literal_eval).apply(np.array)\n",
        "\n",
        "    pickle.dump(X, open(pickle_file, \"wb\"))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#load second file form pickle or from csv\n",
        "pickle_file2022 = 'dataframe2.pkl'\n",
        "EXTRA_mydata_FILE_2022 = './cls_and_pooled_embeddings_with_service_id_2022.csv'\n",
        "\n",
        "X2022 = None\n",
        "\n",
        "if os.path.exists(pickle_file2022):\n",
        "    X2022 = pickle.load(open(pickle_file2022, \"rb\"))\n",
        "else:\n",
        "    X2022 = pd.read_csv(EXTRA_mydata_FILE_2022)\n",
        "\n",
        "    #rename service_request_id to case_enquiry_id\n",
        "    X2022.rename(columns={'service_request_id':'case_enquiry_id'}, inplace=True)\n",
        "    #remove all rows where case_enquiry_id is non-numeric\n",
        "    #X2022 = X2022[X2022['case_enquiry_id'].str.isnumeric()]\n",
        "    #convert case_enquiry_id to int64\n",
        "    #X2022['case_enquiry_id'] = X2022['case_enquiry_id'].astype('int64')\n",
        "\n",
        "    # Convert stringified arrays back to NumPy arrays\n",
        "    X2022['cls_embedding'] = X2022['cls_embedding'].apply(literal_eval).apply(np.array)\n",
        "    X2022['pooled_embedding'] = X2022['pooled_embedding'].apply(literal_eval).apply(np.array)\n",
        "\n",
        "    pickle.dump(X2022, open(pickle_file2022, \"wb\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#print information about X2022\n",
        "print(X.info())\n",
        "print(X2022.info())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#concatenate the two dataframes and reindex\n",
        "df = pd.concat([X, X2022], ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Assuming df is your DataFrame and it has columns 'cls_embedding' and 'pooled_embedding'\n",
        "cls_embedding_flattened = np.stack(df['cls_embedding'].to_numpy())\n",
        "pooled_embedding_flattened = np.stack(df['pooled_embedding'].to_numpy())\n",
        "\n",
        "# Remove the old columns\n",
        "df.drop(['cls_embedding', 'pooled_embedding'], axis=1, inplace=True)\n",
        "\n",
        "# Add the new flattened columns\n",
        "df_cls = pd.DataFrame(cls_embedding_flattened, columns=[f'cls_{i}' for i in range(cls_embedding_flattened.shape[1])])\n",
        "df_pooled = pd.DataFrame(pooled_embedding_flattened, columns=[f'pooled_{i}' for i in range(pooled_embedding_flattened.shape[1])])\n",
        "\n",
        "df = pd.concat([df, df_cls, df_pooled], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df['case_enquiry_id'] = df['case_enquiry_id'].astype(str)\n",
        "is_numeric = df['case_enquiry_id'].str.isnumeric()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = df[is_numeric]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df['case_enquiry_id'] = df['case_enquiry_id'].astype('int64')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mydata.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#join them so we are left only with records that have mydata in both files\n",
        "new_mydata = mydata.merge(df, on='case_enquiry_id', how='inner')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "new_mydata.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "df, y = kerasNLP_model.split_data(new_mydata)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#cast all columns that are type bool to float\n",
        "for col in df.columns:\n",
        "    if df[col].dtype == 'bool':\n",
        "        df[col] = df[col].astype('float64')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#list the number of rows in X and y\n",
        "print(df.shape)\n",
        "print(y.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#free all unused dataframes\n",
        "df_to_delete = [cls_embedding_flattened, pooled_embedding_flattened, df_cls, df_pooled, X, X2022, new_mydata, is_numeric, mydata]\n",
        "\n",
        "for data_frame in df_to_delete:\n",
        "    del data_frame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "#parse CLS embedding column as array\n",
        "test_acc = kerasNLP_model.predict(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "data = kerasNLP_model.load_data( 'predict' )\n",
        "data = kerasNLP_model.enhance_data( data, 'predict')\n",
        "clean_data = kerasNLP_model.clean_data_for_prediction( data )\n",
        "\n",
        "X_predict, y_predict = kerasNLP_model.split_data( clean_data )\n",
        "y_predict = kerasNLP_model.model.predict(X_predict)\n",
        "data['survival_prediction'] = y_predict\n",
        "return data\n",
        "\"\"\"\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
