{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P1BXqsllgueC"
      },
      "source": [
        "#Boston 311 Tutorial\n",
        "\n",
        "This notebook will run you through the basic usage of this package to train 3 models on the Boston 311 mydata and use them to predict the outcome of cases from the last 30 days"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "\u001b[33mWARNING: Ignoring invalid distribution -ensorflow (/home/briarmoss/.local/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ensorflow (/home/briarmoss/.local/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: keras-tuner in /home/briarmoss/.local/lib/python3.10/site-packages (1.4.3)\n",
            "Requirement already satisfied: requests in /usr/lib/python3/dist-packages (from keras-tuner) (2.25.1)\n",
            "Requirement already satisfied: kt-legacy in /home/briarmoss/.local/lib/python3.10/site-packages (from keras-tuner) (1.0.5)\n",
            "Requirement already satisfied: keras-core in /home/briarmoss/.local/lib/python3.10/site-packages (from keras-tuner) (0.1.7)\n",
            "Requirement already satisfied: packaging in /home/briarmoss/.local/lib/python3.10/site-packages (from keras-tuner) (23.1)\n",
            "Requirement already satisfied: namex in /home/briarmoss/.local/lib/python3.10/site-packages (from keras-core->keras-tuner) (0.0.7)\n",
            "Requirement already satisfied: numpy in /home/briarmoss/.local/lib/python3.10/site-packages (from keras-core->keras-tuner) (1.23.5)\n",
            "Requirement already satisfied: dm-tree in /home/briarmoss/.local/lib/python3.10/site-packages (from keras-core->keras-tuner) (0.1.8)\n",
            "Requirement already satisfied: h5py in /home/briarmoss/.local/lib/python3.10/site-packages (from keras-core->keras-tuner) (3.8.0)\n",
            "Requirement already satisfied: rich in /home/briarmoss/.local/lib/python3.10/site-packages (from keras-core->keras-tuner) (13.5.3)\n",
            "Requirement already satisfied: absl-py in /home/briarmoss/.local/lib/python3.10/site-packages (from keras-core->keras-tuner) (1.4.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/briarmoss/.local/lib/python3.10/site-packages (from rich->keras-core->keras-tuner) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/briarmoss/.local/lib/python3.10/site-packages (from rich->keras-core->keras-tuner) (2.15.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /home/briarmoss/.local/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras-core->keras-tuner) (0.1.2)\n",
            "\u001b[33mWARNING: Ignoring invalid distribution -ensorflow (/home/briarmoss/.local/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "! pip install keras-tuner"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "\u001b[33mWARNING: Ignoring invalid distribution -ensorflow (/home/briarmoss/.local/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ensorflow (/home/briarmoss/.local/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mProcessing /home/briarmoss/Documents/Boston_311\n",
            "  Installing build dependencies ... \u001b[?25ldone\n",
            "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
            "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25hRequirement already satisfied: scikit-learn in /home/briarmoss/.local/lib/python3.10/site-packages (from boston311==0.1.0) (1.2.2)\n",
            "Requirement already satisfied: numpy in /home/briarmoss/.local/lib/python3.10/site-packages (from boston311==0.1.0) (1.23.5)\n",
            "Requirement already satisfied: tensorflow in /home/briarmoss/.local/lib/python3.10/site-packages (from boston311==0.1.0) (2.13.0)\n",
            "Requirement already satisfied: pandas in /home/briarmoss/.local/lib/python3.10/site-packages (from boston311==0.1.0) (2.0.1)\n",
            "Requirement already satisfied: matplotlib in /home/briarmoss/.local/lib/python3.10/site-packages (from boston311==0.1.0) (3.7.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/lib/python3/dist-packages (from matplotlib->boston311==0.1.0) (9.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /home/briarmoss/.local/lib/python3.10/site-packages (from matplotlib->boston311==0.1.0) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /home/briarmoss/.local/lib/python3.10/site-packages (from matplotlib->boston311==0.1.0) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /home/briarmoss/.local/lib/python3.10/site-packages (from matplotlib->boston311==0.1.0) (23.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/lib/python3/dist-packages (from matplotlib->boston311==0.1.0) (2.4.7)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /home/briarmoss/.local/lib/python3.10/site-packages (from matplotlib->boston311==0.1.0) (4.39.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /home/briarmoss/.local/lib/python3.10/site-packages (from matplotlib->boston311==0.1.0) (0.11.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /home/briarmoss/.local/lib/python3.10/site-packages (from matplotlib->boston311==0.1.0) (1.0.7)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas->boston311==0.1.0) (2022.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /home/briarmoss/.local/lib/python3.10/site-packages (from pandas->boston311==0.1.0) (2023.3)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/briarmoss/.local/lib/python3.10/site-packages (from scikit-learn->boston311==0.1.0) (3.1.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /home/briarmoss/.local/lib/python3.10/site-packages (from scikit-learn->boston311==0.1.0) (1.2.0)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /home/briarmoss/.local/lib/python3.10/site-packages (from scikit-learn->boston311==0.1.0) (1.10.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/briarmoss/.local/lib/python3.10/site-packages (from tensorflow->boston311==0.1.0) (1.54.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /home/briarmoss/.local/lib/python3.10/site-packages (from tensorflow->boston311==0.1.0) (3.20.3)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /home/briarmoss/.local/lib/python3.10/site-packages (from tensorflow->boston311==0.1.0) (3.3.0)\n",
            "Requirement already satisfied: flatbuffers>=23.1.21 in /home/briarmoss/.local/lib/python3.10/site-packages (from tensorflow->boston311==0.1.0) (23.5.9)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /home/briarmoss/.local/lib/python3.10/site-packages (from tensorflow->boston311==0.1.0) (1.6.3)\n",
            "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in /home/briarmoss/.local/lib/python3.10/site-packages (from tensorflow->boston311==0.1.0) (2.13.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /home/briarmoss/.local/lib/python3.10/site-packages (from tensorflow->boston311==0.1.0) (0.2.0)\n",
            "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from tensorflow->boston311==0.1.0) (59.6.0)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /home/briarmoss/.local/lib/python3.10/site-packages (from tensorflow->boston311==0.1.0) (0.4.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/lib/python3/dist-packages (from tensorflow->boston311==0.1.0) (1.16.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/briarmoss/.local/lib/python3.10/site-packages (from tensorflow->boston311==0.1.0) (0.32.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /home/briarmoss/.local/lib/python3.10/site-packages (from tensorflow->boston311==0.1.0) (1.4.0)\n",
            "Requirement already satisfied: tensorboard<2.14,>=2.13 in /home/briarmoss/.local/lib/python3.10/site-packages (from tensorflow->boston311==0.1.0) (2.13.0)\n",
            "Requirement already satisfied: keras<2.14,>=2.13.1 in /home/briarmoss/.local/lib/python3.10/site-packages (from tensorflow->boston311==0.1.0) (2.13.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /home/briarmoss/.local/lib/python3.10/site-packages (from tensorflow->boston311==0.1.0) (16.0.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /home/briarmoss/.local/lib/python3.10/site-packages (from tensorflow->boston311==0.1.0) (3.8.0)\n",
            "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in /home/briarmoss/.local/lib/python3.10/site-packages (from tensorflow->boston311==0.1.0) (4.5.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /home/briarmoss/.local/lib/python3.10/site-packages (from tensorflow->boston311==0.1.0) (2.3.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /home/briarmoss/.local/lib/python3.10/site-packages (from tensorflow->boston311==0.1.0) (1.14.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/lib/python3/dist-packages (from astunparse>=1.6.0->tensorflow->boston311==0.1.0) (0.37.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /home/briarmoss/.local/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow->boston311==0.1.0) (1.0.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/lib/python3/dist-packages (from tensorboard<2.14,>=2.13->tensorflow->boston311==0.1.0) (2.25.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/briarmoss/.local/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow->boston311==0.1.0) (0.7.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /home/briarmoss/.local/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow->boston311==0.1.0) (3.4.3)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/briarmoss/.local/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow->boston311==0.1.0) (2.18.0)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /home/briarmoss/.local/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow->boston311==0.1.0) (2.3.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /home/briarmoss/.local/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow->boston311==0.1.0) (4.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/briarmoss/.local/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow->boston311==0.1.0) (0.3.0)\n",
            "Requirement already satisfied: urllib3<2.0 in /usr/lib/python3/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow->boston311==0.1.0) (1.26.5)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/briarmoss/.local/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow->boston311==0.1.0) (5.3.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/briarmoss/.local/lib/python3.10/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow->boston311==0.1.0) (1.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/briarmoss/.local/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow->boston311==0.1.0) (2.1.2)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /home/briarmoss/.local/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow->boston311==0.1.0) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/lib/python3/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow->boston311==0.1.0) (3.2.0)\n",
            "Building wheels for collected packages: boston311\n",
            "  Building wheel for boston311 (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for boston311: filename=boston311-0.1.0-py3-none-any.whl size=22841 sha256=e1a35273c6a4dc40d302f42f3cdab1a5663afd43718a943bcd63ba32c7e74359\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-_12ewgrx/wheels/3d/69/ee/0a6ac96b9c09c948fc0e74f2724a9703aa39749a41fa757c9e\n",
            "Successfully built boston311\n",
            "\u001b[33mWARNING: Ignoring invalid distribution -ensorflow (/home/briarmoss/.local/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mInstalling collected packages: boston311\n",
            "  Attempting uninstall: boston311\n",
            "\u001b[33m    WARNING: Ignoring invalid distribution -ensorflow (/home/briarmoss/.local/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m    Found existing installation: boston311 0.1.0\n",
            "    Uninstalling boston311-0.1.0:\n",
            "      Successfully uninstalled boston311-0.1.0\n",
            "\u001b[33mWARNING: Ignoring invalid distribution -ensorflow (/home/briarmoss/.local/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mSuccessfully installed boston311-0.1.0\n"
          ]
        }
      ],
      "source": [
        "! pip install ../"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XP7Hzen_iEAl"
      },
      "source": [
        "##Import the Boston311Model class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "import re\n",
        "import sys\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "LdhJESm7eWaY"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-10-03 01:33:05.657213: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2023-10-03 01:33:06.344631: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2023-10-03 01:33:06.350197: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-10-03 01:33:09.420928: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend\n"
          ]
        }
      ],
      "source": [
        "from boston311 import Boston311LogReg, Boston311EventDecTree, Boston311SurvDecTree, Boston311KerasNLP\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load extra features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "#get current datetime in Boston timezone as string\n",
        "from datetime import datetime\n",
        "from pytz import timezone\n",
        "import pytz\n",
        "boston = timezone('US/Eastern')\n",
        "now = datetime.now(boston)\n",
        "today_datestring = now.strftime(\"%Y-%m-%d\")\n",
        "#get time in Boston timezone as string for a filename\n",
        "now = datetime.now(boston)\n",
        "time_string = now.strftime(\"%H-%M-%S\")\n",
        "#define datetime string\n",
        "my_datetime = today_datestring + '_' + time_string \n",
        "\n",
        "#format tomorrows date as yyyy-mm-dd\n",
        "tomorrows_date =  now + pd.DateOffset(days=1)\n",
        "tomorrows_datestring = tomorrows_date.strftime(\"%Y-%m-%d\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "#set path to mydata\n",
        "EXTRA_mydata_FILE = './cls_and_pooled_embeddings_with_service_id.csv'\n",
        "json_file = './daily_models/Boston311KerasNLP/20230925_143704_Boston311KerasNLP.json'\n",
        "model_file = './daily_models/Boston311KerasNLP/20230925_143704_Boston311KerasNLP.h5'\n",
        "kerasNLP_model = Boston311KerasNLP()\n",
        "kerasNLP_model.load( json_file, model_file)\n",
        "kerasNLP_model.predict_date_rang = {'start':'2023-08-27', 'end':tomorrows_datestring}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/briarmoss/.local/lib/python3.10/site-packages/boston311/Boston311Model.py:262: DtypeWarning: Columns (13) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(file)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files with different number of columns from File 0:  []\n",
            "Files with same number of columns as File 0:  [0]\n",
            "Files with different column order from File 0:  []\n",
            "Files with same column order as File 0:  [0]\n"
          ]
        }
      ],
      "source": [
        "data = kerasNLP_model.load_data( 'predict' )\n",
        "data = kerasNLP_model.enhance_data( data, 'predict')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "clean_data = kerasNLP_model.clean_data_for_prediction( data )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>case_enquiry_id</th>\n",
              "      <th>type_Abandoned Bicycle</th>\n",
              "      <th>type_Abandoned Building</th>\n",
              "      <th>type_Abandoned Vehicles</th>\n",
              "      <th>type_Abandoned Vehicles - Private Tow</th>\n",
              "      <th>type_Aircraft Noise Disturbance</th>\n",
              "      <th>type_Alert Boston</th>\n",
              "      <th>type_Animal Found</th>\n",
              "      <th>type_Animal Generic Request</th>\n",
              "      <th>type_Animal Lost</th>\n",
              "      <th>...</th>\n",
              "      <th>ward_number_20</th>\n",
              "      <th>ward_number_21</th>\n",
              "      <th>ward_number_22</th>\n",
              "      <th>ward_number_3</th>\n",
              "      <th>ward_number_4</th>\n",
              "      <th>ward_number_5</th>\n",
              "      <th>ward_number_6</th>\n",
              "      <th>ward_number_7</th>\n",
              "      <th>ward_number_8</th>\n",
              "      <th>ward_number_9</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>101005013792</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>101005013793</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>101005013794</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>101005013795</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>101005013796</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 436 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "  case_enquiry_id  type_Abandoned Bicycle  type_Abandoned Building   \n",
              "0    101005013792                   False                    False  \\\n",
              "1    101005013793                   False                    False   \n",
              "2    101005013794                   False                    False   \n",
              "3    101005013795                   False                    False   \n",
              "4    101005013796                   False                    False   \n",
              "\n",
              "   type_Abandoned Vehicles  type_Abandoned Vehicles - Private Tow   \n",
              "0                    False                                  False  \\\n",
              "1                    False                                  False   \n",
              "2                    False                                  False   \n",
              "3                    False                                  False   \n",
              "4                    False                                  False   \n",
              "\n",
              "   type_Aircraft Noise Disturbance  type_Alert Boston  type_Animal Found   \n",
              "0                            False              False              False  \\\n",
              "1                            False              False              False   \n",
              "2                            False              False              False   \n",
              "3                            False              False              False   \n",
              "4                            False              False              False   \n",
              "\n",
              "   type_Animal Generic Request  type_Animal Lost  ...  ward_number_20   \n",
              "0                        False             False  ...           False  \\\n",
              "1                        False             False  ...           False   \n",
              "2                        False             False  ...           False   \n",
              "3                        False             False  ...           False   \n",
              "4                        False             False  ...           False   \n",
              "\n",
              "   ward_number_21  ward_number_22  ward_number_3  ward_number_4   \n",
              "0           False            True          False          False  \\\n",
              "1           False            True          False          False   \n",
              "2           False            True          False          False   \n",
              "3           False           False          False          False   \n",
              "4           False            True          False          False   \n",
              "\n",
              "   ward_number_5  ward_number_6  ward_number_7  ward_number_8  ward_number_9  \n",
              "0          False          False          False          False          False  \n",
              "1          False          False          False          False          False  \n",
              "2          False          False          False          False          False  \n",
              "3          False          False          False          False          False  \n",
              "4          False          False          False          False          False  \n",
              "\n",
              "[5 rows x 436 columns]"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "clean_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "mydata = clean_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0        101005013792\n",
              "1        101005013793\n",
              "2        101005013794\n",
              "3        101005013795\n",
              "4        101005013796\n",
              "             ...     \n",
              "29776    101005079312\n",
              "29777    101005079313\n",
              "29778    101005079315\n",
              "29779    101005079316\n",
              "29780    101005079318\n",
              "Name: case_enquiry_id, Length: 29781, dtype: object"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mydata['case_enquiry_id']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from ast import literal_eval\n",
        "import pickle\n",
        "\n",
        "pickle_file = 'dataframe.pkl'\n",
        "\n",
        "X = None\n",
        "\n",
        "if os.path.exists(pickle_file):\n",
        "    X = pickle.load(open(pickle_file, \"rb\"))\n",
        "else:\n",
        "    X = pd.read_csv(EXTRA_mydata_FILE)\n",
        "\n",
        "    #rename service_request_id to case_enquiry_id\n",
        "    X.rename(columns={'service_request_id':'case_enquiry_id'}, inplace=True)\n",
        "    #remove all rows where case_enquiry_id is non-numeric\n",
        "    #X = X[X['case_enquiry_id'].str.isnumeric()]\n",
        "    #convert case_enquiry_id to int64\n",
        "    #X['case_enquiry_id'] = X['case_enquiry_id'].astype('int64')\n",
        "\n",
        "    # Convert stringified arrays back to NumPy arrays\n",
        "    X['cls_embedding'] = X['cls_embedding'].apply(literal_eval).apply(np.array)\n",
        "    X['pooled_embedding'] = X['pooled_embedding'].apply(literal_eval).apply(np.array)\n",
        "\n",
        "    pickle.dump(X, open(pickle_file, \"wb\"))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "#concatenate the two dataframes and reindex\n",
        "df = X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(28265, 3)"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Assuming df is your DataFrame and it has columns 'cls_embedding' and 'pooled_embedding'\n",
        "cls_embedding_flattened = np.stack(df['cls_embedding'].to_numpy())\n",
        "pooled_embedding_flattened = np.stack(df['pooled_embedding'].to_numpy())\n",
        "\n",
        "# Remove the old columns\n",
        "df.drop(['cls_embedding', 'pooled_embedding'], axis=1, inplace=True)\n",
        "\n",
        "# Add the new flattened columns\n",
        "df_cls = pd.DataFrame(cls_embedding_flattened, columns=[f'cls_{i}' for i in range(cls_embedding_flattened.shape[1])])\n",
        "df_pooled = pd.DataFrame(pooled_embedding_flattened, columns=[f'pooled_{i}' for i in range(pooled_embedding_flattened.shape[1])])\n",
        "\n",
        "df = pd.concat([df, df_cls, df_pooled], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "df['case_enquiry_id'] = df['case_enquiry_id'].astype(str)\n",
        "is_numeric = df['case_enquiry_id'].str.isnumeric()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = df[is_numeric]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "df['case_enquiry_id'] = df['case_enquiry_id'].astype('int64')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(28265, 257)"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(29781, 436)"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mydata.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "#join them so we are left only with records that have mydata in both files\n",
        "new_mydata = mydata.merge(df, on='case_enquiry_id', how='inner')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(18186, 692)"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "new_mydata.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "df = new_mydata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "#cast all columns that are type bool to float\n",
        "for col in df.columns:\n",
        "    if df[col].dtype == 'bool':\n",
        "        df[col] = df[col].astype('float64')\n",
        "    if df[col].dtype == 'int64':\n",
        "        df[col] = df[col].astype('float64') "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "case_enquiry_id                           object\n",
            "type_Abandoned Bicycle                   float64\n",
            "type_Abandoned Building                  float64\n",
            "type_Abandoned Vehicles                  float64\n",
            "type_Abandoned Vehicles - Private Tow    float64\n",
            "                                          ...   \n",
            "pooled_123                               float64\n",
            "pooled_124                               float64\n",
            "pooled_125                               float64\n",
            "pooled_126                               float64\n",
            "pooled_127                               float64\n",
            "Length: 692, dtype: object\n"
          ]
        }
      ],
      "source": [
        "#list the number of rows in X and y\n",
        "print(df.dtypes)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "#free all unused dataframes\n",
        "#df_to_delete = [cls_embedding_flattened, pooled_embedding_flattened, df_cls, df_pooled, X, new_mydata, is_numeric, mydata]\n",
        "\n",
        "#for data_frame in df_to_delete:\n",
        "#    if data_frame is not None:\n",
        "#        del data_frame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "case_enquiry_id = df['case_enquiry_id']\n",
        "X_predict = df.drop(['case_enquiry_id'], axis=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-10-03 01:36:57.411079: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 100532208 exceeds 10% of free system memory.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "569/569 [==============================] - 3s 4ms/step\n"
          ]
        }
      ],
      "source": [
        "\n",
        "#parse CLS embedding column as array\n",
        "predictions = kerasNLP_model.model.predict(X_predict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['0.7559566 0.20721163 0.033212524 0.0025828772 0.0008951307 8.179453e-05 3.803741e-05 1.7574697e-05 3.7406842e-06'\n",
            " '0.7104199 0.2381293 0.046981774 0.003711577 0.00040469103 0.00014026689 0.00020275456 9.391938e-06 2.3866696e-07'\n",
            " '0.6704167 0.28465536 0.03871845 0.0035374311 0.0015684962 0.0002003041 0.00016235236 0.000731696 9.161791e-06'\n",
            " ...\n",
            " '0.15320297 0.09023995 0.06491842 0.029716609 0.0429548 0.044575464 0.45883057 0.049090143 0.06647106'\n",
            " '0.15320298 0.09023996 0.06491843 0.02971661 0.042954803 0.044575468 0.4588306 0.049090147 0.06647107'\n",
            " '0.15320298 0.09023996 0.06491843 0.02971661 0.042954803 0.044575468 0.4588306 0.049090143 0.06647107']\n"
          ]
        }
      ],
      "source": [
        "# Define a function to flatten an array into a string.\n",
        "def array_to_string(arr):\n",
        "    return ' '.join(map(str, arr))\n",
        "\n",
        "# Apply the function along axis 1 (rows).\n",
        "string_predictions = np.apply_along_axis(array_to_string, axis=1, arr=predictions)\n",
        "\n",
        "# Now string_predictions is a 1D NumPy array where each element is a string\n",
        "# that contains all the elements from the corresponding row in the original 2D array.\n",
        "print(string_predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "#combine case_enquiry_id and predictions into a dataframe\n",
        "predictions_df = pd.DataFrame({'case_enquiry_id':case_enquiry_id, 'prediction':string_predictions})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "bin_labels = [\n",
        "    \"0-12 hours\",      # Less than half a day\n",
        "    \"12-24 hours\",     # Half to one day\n",
        "    \"1-3 days\",        # One to three days\n",
        "    \"4-7 days\",        # Four to seven days\n",
        "    \"1-2 weeks\",       # One to two weeks\n",
        "    \"2-4 weeks\",       # Two to four weeks\n",
        "    \"1-2 months\",      # One to two months\n",
        "    \"2-4 months\",      # Two to four months\n",
        "    \"4+ months\"        # More than four months\n",
        "]\n",
        "\n",
        "#predictions_df['prediction'] = predictions_df['prediction'].apply(lambda x: bin_labels[x])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "18186"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(predictions_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[7.5595659e-01 2.0721163e-01 3.3212524e-02 ... 3.8037411e-05\n",
            "  1.7574697e-05 3.7406842e-06]\n",
            " [7.1041989e-01 2.3812930e-01 4.6981774e-02 ... 2.0275456e-04\n",
            "  9.3919380e-06 2.3866696e-07]\n",
            " [6.7041671e-01 2.8465536e-01 3.8718451e-02 ... 1.6235236e-04\n",
            "  7.3169603e-04 9.1617912e-06]\n",
            " ...\n",
            " [1.5320297e-01 9.0239950e-02 6.4918421e-02 ... 4.5883057e-01\n",
            "  4.9090143e-02 6.6471063e-02]\n",
            " [1.5320298e-01 9.0239957e-02 6.4918429e-02 ... 4.5883060e-01\n",
            "  4.9090147e-02 6.6471070e-02]\n",
            " [1.5320298e-01 9.0239957e-02 6.4918429e-02 ... 4.5883060e-01\n",
            "  4.9090143e-02 6.6471070e-02]]\n"
          ]
        }
      ],
      "source": [
        "print(predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Boston311KerasNLP'"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "kerasNLP_model.model_type"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "model_name = '20230925_143704_Boston311KerasNLP'\n",
        "ml_model_date = '2023-09-25'\n",
        "\n",
        "#define an empt pandas dataframe ml_model_df\n",
        "ml_model_df = pd.DataFrame(columns=['ml_model_name', 'ml_model_type', 'ml_model_date'])\n",
        "\n",
        "ml_model_df = pd.concat([ml_model_df, pd.DataFrame([{'ml_model_name': model_name, \n",
        "                                    'ml_model_type': kerasNLP_model.model_type,\n",
        "                                    'ml_model_date': ml_model_date}])], ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_cases = data.drop(['geom_4326','survival_time_hours', 'survival_time', 'event'], axis=1).copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "all_model_cases = model_cases \n",
        "all_model_predictions = predictions_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "all_model_predictions['ml_model_name'] = model_name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [],
      "source": [
        "all_model_predictions['prediction_date'] = today_datestring"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [],
      "source": [
        "# %%\n",
        "#get current datetime in Boston timezone as string\n",
        "from datetime import datetime\n",
        "from pytz import timezone\n",
        "import pytz\n",
        "boston = timezone('US/Eastern')\n",
        "now = datetime.now(boston)\n",
        "today_datestring = now.strftime(\"%Y-%m-%d\")\n",
        "#get time in Boston timezone as string for a filename\n",
        "now = datetime.now(boston)\n",
        "time_string = now.strftime(\"%H-%M-%S\")\n",
        "#define datetime string\n",
        "my_datetime = today_datestring + '_' + time_string "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# %%\n",
        "all_model_cases.to_csv(my_datetime+'_311_cases.csv', index=False)\n",
        "\n",
        "\n",
        "# %%\n",
        "\n",
        "all_model_predictions.to_csv(my_datetime+'_311_predictions.csv', index=False)\n",
        "\n",
        "# %%\n",
        "\n",
        "ml_model_df.to_csv(my_datetime+'_311_ml_models.csv', index=False)\n",
        "\n",
        "# %%\n",
        "#create datetime _manifest.txt file with one filename per line\n",
        "with open(my_datetime+'_manifest.txt', 'w') as f:\n",
        "    f.write(my_datetime+'_311_cases.csv\\n')\n",
        "    f.write(my_datetime+'_311_predictions.csv\\n')\n",
        "    f.write(my_datetime+'_311_ml_models.csv\\n')\n",
        "\n",
        "# %%\n",
        "#create an export folder\n",
        "EXPORT_FOLDER = '~/Documents/BODC-DEI-site/database/seeders'\n",
        "#copy the csv files to the export folder\n",
        "!cp {my_datetime}_311_cases.csv {EXPORT_FOLDER}\n",
        "!cp {my_datetime}_311_predictions.csv {EXPORT_FOLDER}\n",
        "!cp {my_datetime}_311_ml_models.csv {EXPORT_FOLDER}\n",
        "!cp {my_datetime}_manifest.txt {EXPORT_FOLDER}\n",
        "\n",
        "\n",
        "\n",
        "# %% [markdown]\n",
        "# ** Copy the files to the production server **\n",
        "\n",
        "# %%\n",
        "# Define constants for servers\n",
        "PROD_USER = 'u353344964'\n",
        "PROD_HOSTNAME = '195.179.236.61'\n",
        "PORT_NUMBER = 65002\n",
        "PROD_BASE_FOLDER = '/home/u353344964/domains/bodc-dei.org/laravel'\n",
        "STAGE_BASE_FOLDER = '/home/u353344964/domains/bodc-dei.org/stagelaravel'\n",
        "PROD_EXPORT_FOLDER = '/home/u353344964/domains/bodc-dei.org/laravel/database/seeders'\n",
        "STAGE_EXPORT_FOLDER = '/home/u353344964/domains/bodc-dei.org/stagelaravel/database/seeders'\n",
        "\n",
        "# %%\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "65002"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "\n",
        "def scp_to_server(filename, user=PROD_USER, hostname=PROD_HOSTNAME, port=PORT_NUMBER, export_folder=PROD_EXPORT_FOLDER):\n",
        "    \"\"\"Copy a file to the server using scp.\"\"\"\n",
        "    command = f\"scp -P {port} {filename} {user}@{hostname}:{export_folder}\"\n",
        "    print(f\"Executing: {command}\")\n",
        "    os.system(command)\n",
        "\n",
        "# Use the function to scp files\n",
        "files_to_copy = [\n",
        "    f\"{my_datetime}_311_cases.csv\",\n",
        "    f\"{my_datetime}_311_predictions.csv\",\n",
        "    f\"{my_datetime}_311_ml_models.csv\",\n",
        "    f\"{my_datetime}_manifest.txt\"\n",
        "]\n",
        "\n",
        "# Control where to copy\n",
        "copy_to_prod = False\n",
        "copy_to_stage = False\n",
        "\n",
        "for file in files_to_copy:\n",
        "    if copy_to_prod:\n",
        "        scp_to_server(file, export_folder=PROD_EXPORT_FOLDER)\n",
        "    if copy_to_stage:\n",
        "        scp_to_server(file, export_folder=STAGE_EXPORT_FOLDER)\n",
        "\n",
        "\n",
        "# %%\n",
        "PORT_NUMBER"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [],
      "source": [
        "# %%\n",
        "if copy_to_prod:\n",
        "    !ssh -p {PORT_NUMBER} {PROD_USER}@{PROD_HOSTNAME} 'cd {PROD_BASE_FOLDER}; php artisan db:seed --class=ThreeOneOneSeeder'\n",
        "\n",
        "if copy_to_stage:\n",
        "    !ssh -p {PORT_NUMBER} {PROD_USER}@{PROD_HOSTNAME} 'cd {STAGE_BASE_FOLDER}; php artisan db:seed --class=ThreeOneOneSeeder'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
