{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P1BXqsllgueC"
      },
      "source": [
        "#Boston 311 Tutorial\n",
        "\n",
        "This notebook will run you through the basic usage of this package to train 3 models on the Boston 311 mydata and use them to predict the outcome of cases from the last 30 days"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Processing /home/briarmoss/Documents/Boston_311\n",
            "  Installing build dependencies ... \u001b[?25l"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "done\n",
            "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
            "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25hBuilding wheels for collected packages: boston311\n",
            "  Building wheel for boston311 (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for boston311: filename=boston311-0.2.0-py3-none-any.whl size=24770 sha256=8ab99acf6fd882135c669bdd3c554ed7d515c9b9639466601ee07508ec99cfd5\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-ni3k3092/wheels/3d/69/ee/0a6ac96b9c09c948fc0e74f2724a9703aa39749a41fa757c9e\n",
            "Successfully built boston311\n",
            "Installing collected packages: boston311\n",
            "  Attempting uninstall: boston311\n",
            "    Found existing installation: boston311 0.2.0\n",
            "    Uninstalling boston311-0.2.0:\n",
            "      Successfully uninstalled boston311-0.2.0\n",
            "Successfully installed boston311-0.2.0\n"
          ]
        }
      ],
      "source": [
        "! pip install ../"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XP7Hzen_iEAl"
      },
      "source": [
        "##Import the Boston311Model class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "import re\n",
        "import sys\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "LdhJESm7eWaY"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-01-01 15:46:36.147052: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-01-01 15:46:36.147087: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-01-01 15:46:36.148142: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-01-01 15:46:36.153966: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-01-01 15:46:36.787906: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend\n"
          ]
        }
      ],
      "source": [
        "from boston311 import Boston311KerasNN\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load extra features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "today_datestring, tomorrow_datestring, thirty_days_ago_datestring = Boston311KerasNN().get_datestrings()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "./daily_models/Boston311KerasNN/2024-01-01_15-39-39_Boston311KerasNN.json\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-01-01 15:46:37.820207: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:274] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
          ]
        }
      ],
      "source": [
        "import glob\n",
        "import os\n",
        "\n",
        "def get_latest_model_files(model_dir=\"./daily_models/Boston311KerasNN/\"):\n",
        "    # Get all json and h5 files\n",
        "    json_files = glob.glob(os.path.join(model_dir, \"*.json\"))\n",
        "    h5_files = glob.glob(os.path.join(model_dir, \"*.h5\"))\n",
        "    #also add .keras files to h5_files\n",
        "    keras_files = glob.glob(os.path.join(model_dir, \"*.keras\"))\n",
        "    h5_files.extend(keras_files)\n",
        "\n",
        "    # Sort files by modification time\n",
        "    json_files.sort(key=os.path.getmtime, reverse=True)\n",
        "    h5_files.sort(key=os.path.getmtime, reverse=True)\n",
        "\n",
        "    if json_files and h5_files:\n",
        "        latest_json = json_files[0]\n",
        "        latest_h5 = h5_files[0]\n",
        "        return latest_json, latest_h5\n",
        "    else:\n",
        "        return None, None\n",
        "\n",
        "# Use the function\n",
        "json_file, model_file = get_latest_model_files()\n",
        "print(json_file)\n",
        "\n",
        "if json_file and model_file:\n",
        "    KerasNN_model = Boston311KerasNN()\n",
        "    KerasNN_model.load(json_file, model_file)\n",
        "    KerasNN_model.predict_date_range['end'] = tomorrow_datestring\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "case_data_file = 'case_data.pkl'\n",
        "case_data_csv = 'all_311_cases.csv'\n",
        "data = KerasNN_model.pkl_load_data(case_data_csv, case_data_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "columns in data before drop: Index(['case_enquiry_id', 'open_dt', 'sla_target_dt', 'closed_dt', 'on_time',\n",
            "       'case_status', 'closure_reason', 'case_title', 'subject', 'reason',\n",
            "       'type', 'queue', 'department', 'submitted_photo', 'closed_photo',\n",
            "       'location', 'fire_district', 'pwd_district', 'city_council_district',\n",
            "       'police_district', 'neighborhood', 'neighborhood_services_district',\n",
            "       'ward', 'precinct', 'location_street_name', 'location_zipcode',\n",
            "       'latitude', 'longitude', 'geom_4326', 'source', 'survival_time',\n",
            "       'event', 'ward_number', 'survival_time_hours'],\n",
            "      dtype='object')\n",
            "columns to drop: Index(['case_status', 'case_title', 'city_council_district', 'closed_dt',\n",
            "       'closed_photo', 'closure_reason', 'fire_district', 'geom_4326',\n",
            "       'latitude', 'location', 'location_street_name', 'location_zipcode',\n",
            "       'longitude', 'neighborhood', 'neighborhood_services_district',\n",
            "       'on_time', 'open_dt', 'police_district', 'precinct', 'pwd_district',\n",
            "       'sla_target_dt', 'source', 'submitted_photo', 'survival_time', 'type',\n",
            "       'ward', 'ward_number'],\n",
            "      dtype='object')\n",
            "columns in data before ohewfd: Index(['case_enquiry_id', 'subject', 'reason', 'queue', 'department', 'event',\n",
            "       'survival_time_hours'],\n",
            "      dtype='object')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/briarmoss/.local/lib/python3.10/site-packages/boston311/Boston311Model.py:267: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  data = pd.concat([data, fake_df], ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "588/588 [==============================] - 0s 525us/step\n"
          ]
        }
      ],
      "source": [
        "\n",
        "#parse CLS embedding column as array\n",
        "predictions, prediction_data = KerasNN_model.predict(data=data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['0.98571086 0.01112131 0.0012720719 0.0003417297 0.00013077813 0.00011743487 9.166865e-05 5.3575404e-05 2.763312e-05 3.4524404e-05 4.5948305e-05 5.9111717e-05 3.9228988e-05 3.5233887e-05 2.8057626e-05 2.4534385e-05 4.087682e-05 4.7892867e-05 3.2318778e-05 3.650561e-05 2.3478264e-05 1.3950757e-05 1.3428576e-05 8.118847e-06 1.1144418e-05 7.967572e-06 1.0177317e-05 9.87482e-06 1.128973e-05 9.5391915e-06 8.593722e-06 1.2715714e-05 5.947659e-06 8.805407e-06 9.292074e-06 6.19861e-06 9.326769e-06 7.3965116e-06 6.510644e-06 5.409634e-06 6.2378676e-06 1.5275195e-05 8.363891e-06 7.600942e-06 9.738493e-06 1.0703754e-05 4.2763495e-06 7.524434e-06 1.1431113e-05 1.13314845e-05 1.0096672e-05 8.334788e-06 8.070384e-06 4.930613e-06 1.174393e-05 8.6625205e-06 4.618142e-06 7.757868e-06 8.466696e-06 8.427464e-06 0.00033580855'\n",
            " '0.27253813 0.09703063 0.061388515 0.04948826 0.037689645 0.026524302 0.028119074 0.01824459 0.014532071 0.014634336 0.012943782 0.010535295 0.008613946 0.008687455 0.007904848 0.008840861 0.0103484355 0.011198676 0.006939668 0.0071978304 0.007490554 0.005844668 0.0052944864 0.0056801187 0.005782813 0.003836592 0.004750027 0.0054903566 0.0046019983 0.004356364 0.0035525472 0.0041929875 0.0028367143 0.0037228956 0.00438158 0.003119676 0.003160834 0.0045691407 0.0036032149 0.002324347 0.0032274406 0.0044322475 0.0027576373 0.002685898 0.003547939 0.0034030508 0.001948071 0.0035057717 0.0032014467 0.0027043913 0.0025119134 0.0037545841 0.0026730343 0.0021325857 0.00342492 0.0034892478 0.0023605132 0.0026868663 0.0041984334 0.002938013 0.1364237'\n",
            " '0.14051642 0.232723 0.18313232 0.20592485 0.09839989 0.0099653425 0.0022431253 0.0015289487 0.00074613036 0.0007976336 0.0004271539 0.0006330807 0.000739096 0.0008110433 0.0004473129 0.0026393274 0.0069565102 0.010194717 0.004526308 0.004172515 0.0051946514 0.007238857 0.0044506253 0.006647803 0.007990604 0.003552074 0.0041157138 0.006282601 0.006826997 0.0045766127 0.007291436 0.006347921 0.0033076415 0.0036333625 0.004241142 0.0007357342 0.00031218003 0.00064102514 0.0002513082 0.00021382119 0.0002937973 0.00029098932 0.00015715537 0.00020156743 0.0003076985 0.00035184738 0.0001902469 0.00030071946 0.00026441895 0.0001659165 0.00020838137 0.00033379276 0.0002158413 0.0001781964 0.00025761646 0.00020846268 0.00018142408 0.00022178254 0.00034495746 0.00018950374 0.0037587893'\n",
            " ...\n",
            " '0.6503912 0.13639423 0.09801303 0.0340479 0.013156625 0.0069329585 0.007857367 0.0065955967 0.0027778235 0.0034063554 0.0027238189 0.004056238 0.0059852335 0.0038801776 0.0017729129 0.0035114007 0.0051415674 0.0048304237 0.0021431514 0.0020128186 0.0012733191 0.00031610308 0.00021247228 0.00023027757 0.00032633886 0.00011759352 0.00013292016 0.00022643736 0.00019946983 0.00012701488 0.00013029855 0.00016770152 0.000100071185 6.848842e-05 9.437468e-05 5.1879328e-05 3.847796e-05 3.4221568e-05 2.5086269e-05 2.0837888e-05 2.3343937e-05 3.9204588e-05 2.582374e-05 1.659058e-05 2.5404985e-05 2.554765e-05 8.730474e-06 1.6641416e-05 2.326697e-05 2.2061544e-05 1.4526797e-05 1.9014231e-05 1.596009e-05 1.3708791e-05 1.3767959e-05 9.991322e-06 9.680912e-06 1.5688214e-05 1.6034235e-05 1.7299879e-05 0.00010340229'\n",
            " '0.6503912 0.13639423 0.09801303 0.0340479 0.013156625 0.0069329585 0.007857367 0.0065955967 0.0027778235 0.0034063554 0.0027238189 0.004056238 0.0059852335 0.0038801776 0.0017729129 0.0035114007 0.0051415674 0.0048304237 0.0021431514 0.0020128186 0.0012733191 0.00031610308 0.00021247228 0.00023027757 0.00032633886 0.00011759352 0.00013292016 0.00022643736 0.00019946983 0.00012701488 0.00013029855 0.00016770152 0.000100071185 6.848842e-05 9.437468e-05 5.1879328e-05 3.847796e-05 3.4221568e-05 2.5086269e-05 2.0837888e-05 2.3343937e-05 3.9204588e-05 2.582374e-05 1.659058e-05 2.5404985e-05 2.554765e-05 8.730474e-06 1.6641416e-05 2.326697e-05 2.2061544e-05 1.4526797e-05 1.9014231e-05 1.596009e-05 1.3708791e-05 1.3767959e-05 9.991322e-06 9.680912e-06 1.5688214e-05 1.6034235e-05 1.7299879e-05 0.00010340229'\n",
            " '0.9911011 0.006459922 0.00076955603 0.00021558552 9.491776e-05 9.746083e-05 9.51182e-05 5.747201e-05 3.0164183e-05 3.7016624e-05 4.6906884e-05 5.9604456e-05 4.3576536e-05 4.2021125e-05 3.0660478e-05 2.4625699e-05 3.8313465e-05 4.2685708e-05 3.18272e-05 3.527707e-05 2.230691e-05 1.11042145e-05 1.1111206e-05 6.346564e-06 8.930574e-06 6.0849034e-06 7.898495e-06 7.453502e-06 8.660895e-06 7.086663e-06 6.226601e-06 9.840388e-06 4.8355937e-06 6.5557742e-06 7.351339e-06 5.5998194e-06 9.312525e-06 6.5799013e-06 6.643244e-06 5.506686e-06 5.8221244e-06 1.5312084e-05 9.128738e-06 7.6358765e-06 9.461739e-06 9.960865e-06 3.9601564e-06 7.068406e-06 1.10653755e-05 1.2015395e-05 1.0117369e-05 7.7113555e-06 8.063586e-06 4.9738233e-06 1.128404e-05 8.400867e-06 4.51469e-06 7.781128e-06 7.974796e-06 8.766256e-06 0.00030992634']\n"
          ]
        }
      ],
      "source": [
        "# Define a function to flatten an array into a string.\n",
        "def array_to_string(arr):\n",
        "    return ' '.join(map(str, arr))\n",
        "\n",
        "# Apply the function along axis 1 (rows).\n",
        "string_predictions = np.apply_along_axis(array_to_string, axis=1, arr=predictions)\n",
        "\n",
        "# Now string_predictions is a 1D NumPy array where each element is a string\n",
        "# that contains all the elements from the corresponding row in the original 2D array.\n",
        "print(string_predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "case_enquiry_id = prediction_data['case_enquiry_id']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "#combine case_enquiry_id and predictions into a dataframe\n",
        "predictions_df = pd.DataFrame({'case_enquiry_id':case_enquiry_id, 'prediction':string_predictions})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                          ml_model_name     ml_model_type ml_model_date  \\\n",
            "0  2024-01-01_15-39-39_Boston311KerasNN  Boston311KerasNN    2024-01-01   \n",
            "\n",
            "                                       ml_model_json  \n",
            "0  {\"feature_columns\": [\"queue\", \"subject\", \"reas...  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "#get model_name from json_file name and ml_model_date from json_file name first 8 characters which are YYYY-MM-DD and keep it to YYYY-MM-DD\n",
        "model_name = json_file.split('/')[-1].split('.')[0]\n",
        "ml_model_date = json_file.split('/')[-1].split('.')[0][:10]\n",
        "\n",
        "#define an empt pandas dataframe ml_model_df\n",
        "ml_model_df = pd.DataFrame(columns=['ml_model_name', 'ml_model_type', 'ml_model_date'])\n",
        "\n",
        "#read contents of json_file into ml_model_json\n",
        "with open(json_file, 'r') as f:\n",
        "    ml_model_json = f.read()\n",
        "\n",
        "ml_model_df = pd.concat([ml_model_df, pd.DataFrame([{'ml_model_name': model_name, \n",
        "                                    'ml_model_type': KerasNN_model.model_type,\n",
        "                                    'ml_model_date': ml_model_date}])], ignore_index=True)\n",
        "\n",
        "print(ml_model_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "all_model_cases = prediction_data.drop(['geom_4326','survival_time_hours', 'survival_time', 'event'], axis=1).copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "all_model_predictions = predictions_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "all_model_predictions['ml_model_name'] = model_name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "# %%\n",
        "#get current datetime in Boston timezone as string\n",
        "from datetime import datetime\n",
        "from pytz import timezone\n",
        "import pytz\n",
        "boston = timezone('US/Eastern')\n",
        "now = datetime.now(boston)\n",
        "today_datestring = now.strftime(\"%Y-%m-%d\")\n",
        "#get time in Boston timezone as string for a filename\n",
        "now = datetime.now(boston)\n",
        "time_string = now.strftime(\"%H-%M-%S\")\n",
        "#define datetime string\n",
        "my_datetime = today_datestring + '_' + time_string "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "all_model_predictions['prediction_date'] = today_datestring"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2024-01-01_15-46-43_311_cases.csv               0%    0     0.0KB/s   --:-- ETA"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2024-01-01_15-46-43_311_cases.csv             100% 9367KB   2.7MB/s   00:03    \n",
            "2024-01-01_15-46-43_311_predictions.csv       100%   15MB   2.4MB/s   00:06    \n",
            "2024-01-01_15-46-43_311_ml_models.csv         100% 9675     1.7MB/s   00:00    \n",
            "2024-01-01_15-46-43_manifest.txt              100%  112    13.2KB/s   00:00    \n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# %%\n",
        "all_model_cases.to_csv(my_datetime+'_311_cases.csv', index=False)\n",
        "\n",
        "\n",
        "# %%\n",
        "\n",
        "all_model_predictions.to_csv(my_datetime+'_311_predictions.csv', index=False)\n",
        "\n",
        "# %%\n",
        "\n",
        "ml_model_df.to_csv(my_datetime+'_311_ml_models.csv', index=False)\n",
        "\n",
        "# %%\n",
        "#create datetime _manifest.txt file with one filename per line\n",
        "with open(my_datetime+'_manifest.txt', 'w') as f:\n",
        "    f.write(my_datetime+'_311_cases.csv\\n')\n",
        "    f.write(my_datetime+'_311_ml_models.csv\\n')\n",
        "    f.write(my_datetime+'_311_predictions.csv\\n')\n",
        "\n",
        "# %%\n",
        "#create an export folder\n",
        "\n",
        "SCP_COMMAND = \"scp -i /home/briarmoss/.ssh/id_rsa_new\" \n",
        "EXPORT_FOLDER = \"briarmoss@10.0.0.81:/home/briarmoss/Documents/BODC-DEI-site/database/seeders/\"\n",
        "\n",
        "#copy the csv files to the export folder\n",
        "! {SCP_COMMAND} {my_datetime}_311_cases.csv {EXPORT_FOLDER}\n",
        "! {SCP_COMMAND} {my_datetime}_311_predictions.csv {EXPORT_FOLDER}\n",
        "! {SCP_COMMAND} {my_datetime}_311_ml_models.csv {EXPORT_FOLDER}\n",
        "! {SCP_COMMAND} {my_datetime}_manifest.txt {EXPORT_FOLDER}\n",
        "\n",
        "\n",
        "\n",
        "# %% [markdown]\n",
        "# ** Copy the files to the production server **\n",
        "\n",
        "# %%\n",
        "# Define constants for servers\n",
        "PROD_USER = 'u353344964'\n",
        "PROD_HOSTNAME = '195.179.236.61'\n",
        "PORT_NUMBER = 65002\n",
        "PROD_BASE_FOLDER = '/home/u353344964/domains/bodc-dei.org/laravel'\n",
        "STAGE_BASE_FOLDER = '/home/u353344964/domains/bodc-dei.org/stagelaravel'\n",
        "PROD_EXPORT_FOLDER = '/home/u353344964/domains/bodc-dei.org/laravel/database/seeders'\n",
        "STAGE_EXPORT_FOLDER = '/home/u353344964/domains/bodc-dei.org/stagelaravel/database/seeders'\n",
        "\n",
        "# %%\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "65002"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "\n",
        "def scp_to_server(filename, user=PROD_USER, hostname=PROD_HOSTNAME, port=PORT_NUMBER, export_folder=PROD_EXPORT_FOLDER):\n",
        "    \"\"\"Copy a file to the server using scp.\"\"\"\n",
        "    command = f\"scp -P {port} {filename} {user}@{hostname}:{export_folder}\"\n",
        "    print(f\"Executing: {command}\")\n",
        "    os.system(command)\n",
        "\n",
        "# Use the function to scp files\n",
        "files_to_copy = [\n",
        "    f\"{my_datetime}_311_cases.csv\",\n",
        "    f\"{my_datetime}_311_ml_models.csv\",\n",
        "    f\"{my_datetime}_311_predictions.csv\",\n",
        "    f\"{my_datetime}_manifest.txt\"\n",
        "]\n",
        "\n",
        "# Control where to copy\n",
        "copy_to_prod = False\n",
        "copy_to_stage = True\n",
        "\n",
        "for file in files_to_copy:\n",
        "    if copy_to_prod:\n",
        "        scp_to_server(file, export_folder=PROD_EXPORT_FOLDER)\n",
        "    if copy_to_stage:\n",
        "        scp_to_server(file, export_folder=STAGE_EXPORT_FOLDER)\n",
        "\n",
        "\n",
        "# %%\n",
        "PORT_NUMBER"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "if copy_to_prod:\n",
        "    ! ssh -p {PORT_NUMBER} {PROD_USER}@{PROD_HOSTNAME} 'cd {PROD_BASE_FOLDER}; php artisan db:seed --class=ThreeOneOneSeeder'\n",
        "\n",
        "if copy_to_stage:\n",
        "    ! ssh -p {PORT_NUMBER} {PROD_USER}@{PROD_HOSTNAME} 'cd {STAGE_BASE_FOLDER}; php artisan db:seed --class=ThreeOneOneSeeder'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
