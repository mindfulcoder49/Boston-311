{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Processing /home/briarmoss/Documents/Boston_311\n",
            "  Installing build dependencies ... \u001b[?25ldone\n",
            "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
            "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25hBuilding wheels for collected packages: boston311\n",
            "  Building wheel for boston311 (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for boston311: filename=boston311-0.2.0-py3-none-any.whl size=24525 sha256=b7588b953aa7dd609eee8bf109283558e55bcc9af01a97a19ba9c1d7f1a7b52f\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-htirotq3/wheels/3d/69/ee/0a6ac96b9c09c948fc0e74f2724a9703aa39749a41fa757c9e\n",
            "Successfully built boston311\n",
            "Installing collected packages: boston311\n",
            "  Attempting uninstall: boston311\n",
            "    Found existing installation: boston311 0.2.0\n",
            "    Uninstalling boston311-0.2.0:\n",
            "      Successfully uninstalled boston311-0.2.0\n",
            "Successfully installed boston311-0.2.0\n"
          ]
        }
      ],
      "source": [
        "! pip install  ../"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-11-01 23:02:04.114950: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2023-11-01 23:02:04.161403: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2023-11-01 23:02:04.162116: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-11-01 23:02:04.833968: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "/tmp/ipykernel_548799/3798184988.py:7: DeprecationWarning: `import kerastuner` is deprecated, please use `import keras_tuner`.\n",
            "  from kerastuner import HyperParameters\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "from ast import literal_eval\n",
        "from datetime import datetime, timedelta\n",
        "from kerastuner import HyperParameters\n",
        "from boston311 import Boston311LogReg, Boston311KerasNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uUMCPAELR9h7",
        "outputId": "05fcba64-1b74-4fb7-a52c-d3f8a499bcc6"
      },
      "outputs": [],
      "source": [
        "today_datestring, tomorrow_datestring, thirty_days_ago_datestring = Boston311LogReg().get_datestrings()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "KerasNN_model = Boston311KerasNN()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "KerasNN_model.train_date_range={'start':'2020-01-01','end':thirty_days_ago_datestring}\n",
        "\n",
        "KerasNN_model.predict_date_range={'start':thirty_days_ago_datestring,'end':today_datestring}\n",
        "\n",
        "KerasNN_model.feature_columns=['queue', 'subject', 'reason', 'department']\n",
        "\n",
        "KerasNN_model.scenario={'dropColumnValues': {'source':['City Worker App', 'Employee Generated']}, 'survivalTimeMin':300, 'survivalTimeFill':tomorrow_datestring}\n",
        "\n",
        "KerasNN_model.epochs = 20\n",
        "KerasNN_model.batch_size = 32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "hour_interval = 48\n",
        "max_days = 120\n",
        "\n",
        "#KerasNN_model.bin_edges = KerasNN_model.generate_time_bins_statistics(df, num_intervals=60)\n",
        "KerasNN_model.bin_edges = KerasNN_model.generate_time_bins_fixed_interval(hour_interval, max_days)\n",
        "\n",
        "start_nodes = 256  \n",
        "end_nodes = 128\n",
        "#l2_0 = 0.00001\n",
        "#learning_rate = 7.5842e-05\n",
        "l2_0 = 0.001\n",
        "learning_rate = 0.0001\n",
        "\n",
        "hp = HyperParameters()\n",
        "hp.Fixed('start_nodes', start_nodes)\n",
        "hp.Fixed('end_nodes', end_nodes)\n",
        "hp.Fixed('l2_0', l2_0)\n",
        "hp.Fixed('learning_rate', learning_rate)\n",
        "bin_number = len(KerasNN_model.bin_edges) - 1\n",
        "hp.Fixed('final_layer', bin_number)\n",
        "hp.Fixed('final_activation', 'softmax')\n",
        "KerasNN_model.best_hyperparameters = hp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "pickle_file = 'dataframe.pkl'\n",
        "xz_file = '../dataframe.csv.xz'\n",
        "#unpack xz file if it exists\n",
        "if os.path.exists(xz_file):\n",
        "    os.system(f'unxz {xz_file}')\n",
        "    df = pd.read_csv('dataframe.csv')\n",
        "    pickle.dump(df, open(pickle_file, \"wb\"))\n",
        "EXTRA_mydata_FILE = './cls_and_pooled_embeddings_with_three_cols.csv'\n",
        "\n",
        "df = KerasNN_model.pkl_load_data(EXTRA_mydata_FILE, pickle_file)\n",
        "\n",
        "# if df has a column service_request_id, do the following\n",
        "if 'service_request_id' in df.columns:\n",
        "    df.rename(columns={'service_request_id':'case_enquiry_id'}, inplace=True)\n",
        "\n",
        "    df['case_enquiry_id'] = df['case_enquiry_id'].astype(str)\n",
        "    is_numeric = df['case_enquiry_id'].str.isnumeric()\n",
        "    df = df[is_numeric]\n",
        "    df['case_enquiry_id'] = df['case_enquiry_id'].astype('int64')\n",
        "    for col in ['desc_cls_embedding', 'desc_pooled_embedding', 'name_cls_embedding', 'name_pooled_embedding', 'code_cls_embedding', 'code_pooled_embedding']:\n",
        "        df[col] = df[col].apply(literal_eval).apply(np.array)\n",
        "\n",
        "    pickle.dump(df, open(pickle_file, \"wb\"))\n",
        "\n",
        "# Assuming df is your DataFrame\n",
        "column_names = ['desc_cls_embedding', 'desc_pooled_embedding', 'name_cls_embedding', 'name_pooled_embedding', 'code_cls_embedding', 'code_pooled_embedding']\n",
        "df = KerasNN_model.flatten_and_replace_columns(df, column_names)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "case_data_file = 'case_data.pkl'\n",
        "case_data_csv = 'all_311_cases.csv'\n",
        "data = KerasNN_model.pkl_load_data(case_data_csv, case_data_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "#get current datetime in Boston timezone as string\n",
        "my_datetime_str = KerasNN_model.get_current_datetime_str()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "bin_labels is None\n",
            "Starting Training at 2023-11-01 23:02:37.501231\n",
            "input_dim: 1020\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 256)               261376    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 128)               32896     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 61)                7869      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 302141 (1.15 MB)\n",
            "Trainable params: 302141 (1.15 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n",
            "<class 'pandas.core.frame.DataFrame'> (168320, 61)\n",
            "<class 'pandas.core.frame.DataFrame'> (42081, 61)\n",
            "run fit\n",
            "\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-11-01 23:02:40.941474: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 1373491200 exceeds 10% of free system memory.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5247/5260 [============================>.] - ETA: 0s - loss: 1.4473 - accuracy: 0.7288 - top_k_categorical_accuracy: 0.8219"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-11-01 23:02:52.490896: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 686753760 exceeds 10% of free system memory.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5260/5260 [==============================] - 13s 2ms/step - loss: 1.4469 - accuracy: 0.7288 - top_k_categorical_accuracy: 0.8219 - val_loss: 1.6117 - val_accuracy: 0.6603 - val_top_k_categorical_accuracy: 0.7560\n",
            "Epoch 2/20\n",
            "5260/5260 [==============================] - 11s 2ms/step - loss: 1.2584 - accuracy: 0.7408 - top_k_categorical_accuracy: 0.8300 - val_loss: 1.5054 - val_accuracy: 0.6732 - val_top_k_categorical_accuracy: 0.7625\n",
            "Epoch 3/20\n",
            "5260/5260 [==============================] - 11s 2ms/step - loss: 1.1970 - accuracy: 0.7437 - top_k_categorical_accuracy: 0.8323 - val_loss: 1.4745 - val_accuracy: 0.6685 - val_top_k_categorical_accuracy: 0.7616\n",
            "Epoch 4/20\n",
            "5260/5260 [==============================] - 11s 2ms/step - loss: 1.1618 - accuracy: 0.7451 - top_k_categorical_accuracy: 0.8335 - val_loss: 1.4496 - val_accuracy: 0.6716 - val_top_k_categorical_accuracy: 0.7634\n",
            "Epoch 5/20\n",
            "5260/5260 [==============================] - 11s 2ms/step - loss: 1.1387 - accuracy: 0.7461 - top_k_categorical_accuracy: 0.8341 - val_loss: 1.4438 - val_accuracy: 0.6735 - val_top_k_categorical_accuracy: 0.7647\n",
            "Epoch 6/20\n",
            "5260/5260 [==============================] - 11s 2ms/step - loss: 1.1230 - accuracy: 0.7467 - top_k_categorical_accuracy: 0.8343 - val_loss: 1.4439 - val_accuracy: 0.6651 - val_top_k_categorical_accuracy: 0.7623\n",
            "Epoch 7/20\n",
            "5260/5260 [==============================] - 11s 2ms/step - loss: 1.1107 - accuracy: 0.7467 - top_k_categorical_accuracy: 0.8348 - val_loss: 1.4119 - val_accuracy: 0.6746 - val_top_k_categorical_accuracy: 0.7652\n",
            "Epoch 8/20\n",
            "5260/5260 [==============================] - 11s 2ms/step - loss: 1.1014 - accuracy: 0.7474 - top_k_categorical_accuracy: 0.8355 - val_loss: 1.3997 - val_accuracy: 0.6720 - val_top_k_categorical_accuracy: 0.7637\n",
            "Epoch 9/20\n",
            "5260/5260 [==============================] - 11s 2ms/step - loss: 1.0947 - accuracy: 0.7475 - top_k_categorical_accuracy: 0.8357 - val_loss: 1.3836 - val_accuracy: 0.6742 - val_top_k_categorical_accuracy: 0.7659\n",
            "Epoch 10/20\n",
            "5260/5260 [==============================] - 11s 2ms/step - loss: 1.0892 - accuracy: 0.7480 - top_k_categorical_accuracy: 0.8358 - val_loss: 1.3859 - val_accuracy: 0.6743 - val_top_k_categorical_accuracy: 0.7653\n",
            "Epoch 11/20\n",
            "5260/5260 [==============================] - 11s 2ms/step - loss: 1.0842 - accuracy: 0.7485 - top_k_categorical_accuracy: 0.8359 - val_loss: 1.3938 - val_accuracy: 0.6723 - val_top_k_categorical_accuracy: 0.7650\n",
            "Epoch 12/20\n",
            "5260/5260 [==============================] - 11s 2ms/step - loss: 1.0795 - accuracy: 0.7488 - top_k_categorical_accuracy: 0.8368 - val_loss: 1.4257 - val_accuracy: 0.6693 - val_top_k_categorical_accuracy: 0.7623\n",
            "Epoch 13/20\n",
            "5260/5260 [==============================] - 11s 2ms/step - loss: 1.0770 - accuracy: 0.7488 - top_k_categorical_accuracy: 0.8366 - val_loss: 1.3577 - val_accuracy: 0.6746 - val_top_k_categorical_accuracy: 0.7660\n",
            "Epoch 14/20\n",
            "5260/5260 [==============================] - 11s 2ms/step - loss: 1.0740 - accuracy: 0.7490 - top_k_categorical_accuracy: 0.8366 - val_loss: 1.3917 - val_accuracy: 0.6720 - val_top_k_categorical_accuracy: 0.7663\n",
            "Epoch 15/20\n",
            "5260/5260 [==============================] - 11s 2ms/step - loss: 1.0709 - accuracy: 0.7494 - top_k_categorical_accuracy: 0.8369 - val_loss: 1.3777 - val_accuracy: 0.6724 - val_top_k_categorical_accuracy: 0.7657\n",
            "Epoch 16/20\n",
            "5260/5260 [==============================] - 11s 2ms/step - loss: 1.0684 - accuracy: 0.7495 - top_k_categorical_accuracy: 0.8370 - val_loss: 1.3564 - val_accuracy: 0.6748 - val_top_k_categorical_accuracy: 0.7666\n",
            "Epoch 17/20\n",
            "5260/5260 [==============================] - 11s 2ms/step - loss: 1.0671 - accuracy: 0.7499 - top_k_categorical_accuracy: 0.8372 - val_loss: 1.3589 - val_accuracy: 0.6747 - val_top_k_categorical_accuracy: 0.7652\n",
            "Epoch 18/20\n",
            "5260/5260 [==============================] - 11s 2ms/step - loss: 1.0648 - accuracy: 0.7501 - top_k_categorical_accuracy: 0.8372 - val_loss: 1.3813 - val_accuracy: 0.6703 - val_top_k_categorical_accuracy: 0.7648\n",
            "Epoch 19/20\n",
            "5260/5260 [==============================] - 11s 2ms/step - loss: 1.0628 - accuracy: 0.7499 - top_k_categorical_accuracy: 0.8372 - val_loss: 1.3691 - val_accuracy: 0.6718 - val_top_k_categorical_accuracy: 0.7640\n",
            "Epoch 20/20\n",
            "5260/5260 [==============================] - 11s 2ms/step - loss: 1.0623 - accuracy: 0.7503 - top_k_categorical_accuracy: 0.8373 - val_loss: 1.3606 - val_accuracy: 0.6706 - val_top_k_categorical_accuracy: 0.7662\n",
            "1316/1316 [==============================] - 1s 730us/step - loss: 1.0693 - accuracy: 0.7490 - top_k_categorical_accuracy: 0.8395\n",
            "Testing accuracy: 0.7489603161811829 \n",
            "Top-2 accuracy: 0.8395237922668457 \n",
            "Test loss: 1.069309115409851\n",
            "Ending Training at 2023-11-01 23:06:29.229458\n",
            "Training took 0:03:51.728227\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.7489603161811829"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "KerasNN_model.run_pipeline(data, df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Checking files_dict\n",
            "files_dict is None\n",
            "trying to call get311URLs\n",
            "trying to get csv URLs\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found URL: https://data.boston.gov/dataset/8048697b-ad64-4bfc-b090-ee00169f2323/resource/e6013a93-1321-4f2a-bf91-8d8a02f1e62f/download/tmpt_2g32xl.csv for year 2023\n",
            "Found URL: https://data.boston.gov/dataset/8048697b-ad64-4bfc-b090-ee00169f2323/resource/81a7b022-f8fc-4da5-80e4-b160058ca207/download/tmpfm8veglw.csv for year 2022\n",
            "Found URL: https://data.boston.gov/dataset/8048697b-ad64-4bfc-b090-ee00169f2323/resource/f53ebccd-bc61-49f9-83db-625f209c95f5/download/tmp88p9g82n.csv for year 2021\n",
            "Found URL: https://data.boston.gov/dataset/8048697b-ad64-4bfc-b090-ee00169f2323/resource/6ff6a6fd-3141-4440-a880-6f60a37fe789/download/tmpcv_10m2s.csv for year 2020\n",
            "Found URL: https://data.boston.gov/dataset/8048697b-ad64-4bfc-b090-ee00169f2323/resource/ea2e4696-4a2d-429c-9807-d02eb92e0222/download/tmpcje3ep_w.csv for year 2019\n",
            "Found URL: https://data.boston.gov/dataset/8048697b-ad64-4bfc-b090-ee00169f2323/resource/2be28d90-3a90-4af1-a3f6-f28c1e25880a/download/tmp7602cia8.csv for year 2018\n",
            "Found URL: https://data.boston.gov/dataset/8048697b-ad64-4bfc-b090-ee00169f2323/resource/30022137-709d-465e-baae-ca155b51927d/download/tmpzccn8u4q.csv for year 2017\n",
            "Found URL: https://data.boston.gov/dataset/8048697b-ad64-4bfc-b090-ee00169f2323/resource/b7ea6b1b-3ca4-4c5b-9713-6dc1db52379a/download/tmpzxzxeqfb.csv for year 2016\n",
            "Found URL: https://data.boston.gov/dataset/8048697b-ad64-4bfc-b090-ee00169f2323/resource/c9509ab4-6f6d-4b97-979a-0cf2a10c922b/download/tmphrybkxuh.csv for year 2015\n",
            "Found URL: https://data.boston.gov/dataset/8048697b-ad64-4bfc-b090-ee00169f2323/resource/bdae89c8-d4ce-40e9-a6e1-a5203953a2e0/download/tmp8afxvko_.csv for year 2014\n",
            "Found URL: https://data.boston.gov/dataset/8048697b-ad64-4bfc-b090-ee00169f2323/resource/407c5cd0-f764-4a41-adf8-054ff535049e/download/tmpyzk_wmya.csv for year 2013\n",
            "Found URL: https://data.boston.gov/dataset/8048697b-ad64-4bfc-b090-ee00169f2323/resource/382e10d9-1864-40ba-bef6-4eea3c75463c/download/tmpeyvgdt5u.csv for year 2012\n",
            "Found URL: https://data.boston.gov/dataset/8048697b-ad64-4bfc-b090-ee00169f2323/resource/94b499d9-712a-4d2a-b790-7ceec5c9c4b1/download/tmp_9ogynu0.csv for year 2011\n",
            "files_dict is {'2023': 'https://data.boston.gov/dataset/8048697b-ad64-4bfc-b090-ee00169f2323/resource/e6013a93-1321-4f2a-bf91-8d8a02f1e62f/download/tmpt_2g32xl.csv', '2022': 'https://data.boston.gov/dataset/8048697b-ad64-4bfc-b090-ee00169f2323/resource/81a7b022-f8fc-4da5-80e4-b160058ca207/download/tmpfm8veglw.csv', '2021': 'https://data.boston.gov/dataset/8048697b-ad64-4bfc-b090-ee00169f2323/resource/f53ebccd-bc61-49f9-83db-625f209c95f5/download/tmp88p9g82n.csv', '2020': 'https://data.boston.gov/dataset/8048697b-ad64-4bfc-b090-ee00169f2323/resource/6ff6a6fd-3141-4440-a880-6f60a37fe789/download/tmpcv_10m2s.csv', '2019': 'https://data.boston.gov/dataset/8048697b-ad64-4bfc-b090-ee00169f2323/resource/ea2e4696-4a2d-429c-9807-d02eb92e0222/download/tmpcje3ep_w.csv', '2018': 'https://data.boston.gov/dataset/8048697b-ad64-4bfc-b090-ee00169f2323/resource/2be28d90-3a90-4af1-a3f6-f28c1e25880a/download/tmp7602cia8.csv', '2017': 'https://data.boston.gov/dataset/8048697b-ad64-4bfc-b090-ee00169f2323/resource/30022137-709d-465e-baae-ca155b51927d/download/tmpzccn8u4q.csv', '2016': 'https://data.boston.gov/dataset/8048697b-ad64-4bfc-b090-ee00169f2323/resource/b7ea6b1b-3ca4-4c5b-9713-6dc1db52379a/download/tmpzxzxeqfb.csv', '2015': 'https://data.boston.gov/dataset/8048697b-ad64-4bfc-b090-ee00169f2323/resource/c9509ab4-6f6d-4b97-979a-0cf2a10c922b/download/tmphrybkxuh.csv', '2014': 'https://data.boston.gov/dataset/8048697b-ad64-4bfc-b090-ee00169f2323/resource/bdae89c8-d4ce-40e9-a6e1-a5203953a2e0/download/tmp8afxvko_.csv', '2013': 'https://data.boston.gov/dataset/8048697b-ad64-4bfc-b090-ee00169f2323/resource/407c5cd0-f764-4a41-adf8-054ff535049e/download/tmpyzk_wmya.csv', '2012': 'https://data.boston.gov/dataset/8048697b-ad64-4bfc-b090-ee00169f2323/resource/382e10d9-1864-40ba-bef6-4eea3c75463c/download/tmpeyvgdt5u.csv', '2011': 'https://data.boston.gov/dataset/8048697b-ad64-4bfc-b090-ee00169f2323/resource/94b499d9-712a-4d2a-b790-7ceec5c9c4b1/download/tmp_9ogynu0.csv'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/briarmoss/.local/lib/python3.10/site-packages/boston311/Boston311Model.py:331: DtypeWarning: Columns (13) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(file)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "columns in data before drop: Index(['case_enquiry_id', 'open_dt', 'sla_target_dt', 'closed_dt', 'on_time',\n",
            "       'case_status', 'closure_reason', 'case_title', 'subject', 'reason',\n",
            "       'type', 'queue', 'department', 'submitted_photo', 'closed_photo',\n",
            "       'location', 'fire_district', 'pwd_district', 'city_council_district',\n",
            "       'police_district', 'neighborhood', 'neighborhood_services_district',\n",
            "       'ward', 'precinct', 'location_street_name', 'location_zipcode',\n",
            "       'latitude', 'longitude', 'geom_4326', 'source', 'survival_time',\n",
            "       'event', 'ward_number', 'survival_time_hours'],\n",
            "      dtype='object')\n",
            "columns to drop: Index(['case_status', 'case_title', 'city_council_district', 'closed_dt',\n",
            "       'closed_photo', 'closure_reason', 'fire_district', 'geom_4326',\n",
            "       'latitude', 'location', 'location_street_name', 'location_zipcode',\n",
            "       'longitude', 'neighborhood', 'neighborhood_services_district',\n",
            "       'on_time', 'open_dt', 'police_district', 'precinct', 'pwd_district',\n",
            "       'sla_target_dt', 'source', 'submitted_photo', 'survival_time', 'type',\n",
            "       'ward', 'ward_number'],\n",
            "      dtype='object')\n",
            "columns in data before ohewfd: Index(['case_enquiry_id', 'subject', 'reason', 'queue', 'department', 'event',\n",
            "       'survival_time_hours'],\n",
            "      dtype='object')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/briarmoss/.local/lib/python3.10/site-packages/boston311/Boston311Model.py:262: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  data = pd.concat([data, fake_df], ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "484/484 [==============================] - 0s 580us/step\n"
          ]
        }
      ],
      "source": [
        "predictions = KerasNN_model.predict(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[1.56276435e-01 3.10001597e-02 2.35506669e-02 ... 5.43830311e-03\n",
            "  6.58557983e-03 2.89393395e-01]\n",
            " [7.40468860e-01 1.40885875e-01 4.92025875e-02 ... 2.92857021e-05\n",
            "  5.07032746e-05 2.27548589e-04]\n",
            " [3.52099001e-01 1.69185564e-01 6.14025295e-02 ... 1.78430998e-03\n",
            "  2.51933932e-03 1.30301211e-02]\n",
            " ...\n",
            " [7.66762137e-01 1.35053545e-01 4.26015295e-02 ... 2.13420208e-05\n",
            "  3.69925765e-05 2.02469877e-04]\n",
            " [7.65175879e-01 1.40136063e-01 4.23399620e-02 ... 1.51481190e-05\n",
            "  2.79881806e-05 1.14482405e-04]\n",
            " [7.60507941e-01 1.37570754e-01 4.60410602e-02 ... 1.85126919e-05\n",
            "  3.36519442e-05 1.38173375e-04]]\n"
          ]
        }
      ],
      "source": [
        "print(predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/briarmoss/.local/lib/python3.10/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ],
      "source": [
        "#set model folder constant\n",
        "MODEL_FOLDER = './daily_models'\n",
        "\n",
        "def save_model_to_dir(model, folder_name, datetime_string=None):\n",
        "    dir_path = os.path.join(MODEL_FOLDER, folder_name)\n",
        "    \n",
        "    if not os.path.exists(dir_path):\n",
        "        os.mkdir(dir_path)\n",
        "    \n",
        "    if datetime_string is None:\n",
        "        timestamp = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "    else:\n",
        "        timestamp = datetime_string\n",
        "    \n",
        "    model_name = timestamp + \"_\" + model.model_type\n",
        "    properties_name = model_name\n",
        "    \n",
        "    model.save(dir_path, model_name, properties_name)\n",
        "\n",
        "\n",
        "save_model_to_dir(KerasNN_model, KerasNN_model.model_type, datetime_string=my_datetime_str)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
