{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P1BXqsllgueC"
      },
      "source": [
        "#Boston 311 Tutorial\n",
        "\n",
        "This notebook will run you through the basic usage of this package to train 3 models on the Boston 311 mydata and use them to predict the outcome of cases from the last 30 days"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: keras-tuner in /home/briarmoss/.local/lib/python3.10/site-packages (1.4.0)\n",
            "Requirement already satisfied: kt-legacy in /home/briarmoss/.local/lib/python3.10/site-packages (from keras-tuner) (1.0.5)\n",
            "Requirement already satisfied: keras-core in /home/briarmoss/.local/lib/python3.10/site-packages (from keras-tuner) (0.1.7)\n",
            "Requirement already satisfied: packaging in /home/briarmoss/.local/lib/python3.10/site-packages (from keras-tuner) (23.1)\n",
            "Requirement already satisfied: requests in /usr/lib/python3/dist-packages (from keras-tuner) (2.25.1)\n",
            "Requirement already satisfied: rich in /home/briarmoss/.local/lib/python3.10/site-packages (from keras-core->keras-tuner) (13.5.3)\n",
            "Requirement already satisfied: namex in /home/briarmoss/.local/lib/python3.10/site-packages (from keras-core->keras-tuner) (0.0.7)\n",
            "Requirement already satisfied: absl-py in /home/briarmoss/.local/lib/python3.10/site-packages (from keras-core->keras-tuner) (1.4.0)\n",
            "Requirement already satisfied: h5py in /home/briarmoss/.local/lib/python3.10/site-packages (from keras-core->keras-tuner) (3.8.0)\n",
            "Requirement already satisfied: numpy in /home/briarmoss/.local/lib/python3.10/site-packages (from keras-core->keras-tuner) (1.23.5)\n",
            "Requirement already satisfied: dm-tree in /home/briarmoss/.local/lib/python3.10/site-packages (from keras-core->keras-tuner) (0.1.8)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/briarmoss/.local/lib/python3.10/site-packages (from rich->keras-core->keras-tuner) (2.15.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/briarmoss/.local/lib/python3.10/site-packages (from rich->keras-core->keras-tuner) (3.0.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /home/briarmoss/.local/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras-core->keras-tuner) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install keras-tuner"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Processing /home/briarmoss/Documents/Boston_311\n",
            "  Installing build dependencies ... \u001b[?25ldone\n",
            "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
            "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25hRequirement already satisfied: pandas in /home/briarmoss/.local/lib/python3.10/site-packages (from boston311==0.1.0) (2.0.2)\n",
            "Requirement already satisfied: matplotlib in /usr/lib/python3/dist-packages (from boston311==0.1.0) (3.5.1)\n",
            "Requirement already satisfied: scikit-learn in /home/briarmoss/.local/lib/python3.10/site-packages (from boston311==0.1.0) (1.2.2)\n",
            "Requirement already satisfied: numpy in /home/briarmoss/.local/lib/python3.10/site-packages (from boston311==0.1.0) (1.23.5)\n",
            "Requirement already satisfied: tensorflow in /home/briarmoss/.local/lib/python3.10/site-packages (from boston311==0.1.0) (2.13.0)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /home/briarmoss/.local/lib/python3.10/site-packages (from pandas->boston311==0.1.0) (2023.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /home/briarmoss/.local/lib/python3.10/site-packages (from pandas->boston311==0.1.0) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas->boston311==0.1.0) (2022.1)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /home/briarmoss/.local/lib/python3.10/site-packages (from scikit-learn->boston311==0.1.0) (1.10.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /home/briarmoss/.local/lib/python3.10/site-packages (from scikit-learn->boston311==0.1.0) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/briarmoss/.local/lib/python3.10/site-packages (from scikit-learn->boston311==0.1.0) (3.1.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/briarmoss/.local/lib/python3.10/site-packages (from tensorflow->boston311==0.1.0) (0.32.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /home/briarmoss/.local/lib/python3.10/site-packages (from tensorflow->boston311==0.1.0) (3.8.0)\n",
            "Requirement already satisfied: tensorboard<2.14,>=2.13 in /home/briarmoss/.local/lib/python3.10/site-packages (from tensorflow->boston311==0.1.0) (2.13.0)\n",
            "Requirement already satisfied: packaging in /home/briarmoss/.local/lib/python3.10/site-packages (from tensorflow->boston311==0.1.0) (23.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /home/briarmoss/.local/lib/python3.10/site-packages (from tensorflow->boston311==0.1.0) (4.23.3)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /home/briarmoss/.local/lib/python3.10/site-packages (from tensorflow->boston311==0.1.0) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in /home/briarmoss/.local/lib/python3.10/site-packages (from tensorflow->boston311==0.1.0) (2.13.0)\n",
            "Requirement already satisfied: flatbuffers>=23.1.21 in /home/briarmoss/.local/lib/python3.10/site-packages (from tensorflow->boston311==0.1.0) (23.5.26)\n",
            "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from tensorflow->boston311==0.1.0) (59.6.0)\n",
            "Requirement already satisfied: keras<2.14,>=2.13.1 in /home/briarmoss/.local/lib/python3.10/site-packages (from tensorflow->boston311==0.1.0) (2.13.1)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/lib/python3/dist-packages (from tensorflow->boston311==0.1.0) (1.16.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /home/briarmoss/.local/lib/python3.10/site-packages (from tensorflow->boston311==0.1.0) (3.3.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /home/briarmoss/.local/lib/python3.10/site-packages (from tensorflow->boston311==0.1.0) (2.3.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/briarmoss/.local/lib/python3.10/site-packages (from tensorflow->boston311==0.1.0) (1.54.2)\n",
            "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in /home/briarmoss/.local/lib/python3.10/site-packages (from tensorflow->boston311==0.1.0) (4.5.0)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /home/briarmoss/.local/lib/python3.10/site-packages (from tensorflow->boston311==0.1.0) (0.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /home/briarmoss/.local/lib/python3.10/site-packages (from tensorflow->boston311==0.1.0) (1.6.3)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /home/briarmoss/.local/lib/python3.10/site-packages (from tensorflow->boston311==0.1.0) (16.0.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /home/briarmoss/.local/lib/python3.10/site-packages (from tensorflow->boston311==0.1.0) (1.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /home/briarmoss/.local/lib/python3.10/site-packages (from tensorflow->boston311==0.1.0) (0.2.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/lib/python3/dist-packages (from astunparse>=1.6.0->tensorflow->boston311==0.1.0) (0.37.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/lib/python3/dist-packages (from tensorboard<2.14,>=2.13->tensorflow->boston311==0.1.0) (2.25.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /home/briarmoss/.local/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow->boston311==0.1.0) (2.3.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/briarmoss/.local/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow->boston311==0.1.0) (0.7.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /home/briarmoss/.local/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow->boston311==0.1.0) (1.0.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/briarmoss/.local/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow->boston311==0.1.0) (2.20.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /home/briarmoss/.local/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow->boston311==0.1.0) (3.4.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/briarmoss/.local/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow->boston311==0.1.0) (5.3.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /home/briarmoss/.local/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow->boston311==0.1.0) (4.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/briarmoss/.local/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow->boston311==0.1.0) (0.3.0)\n",
            "Requirement already satisfied: urllib3<2.0 in /usr/lib/python3/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow->boston311==0.1.0) (1.26.5)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/briarmoss/.local/lib/python3.10/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow->boston311==0.1.0) (1.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/briarmoss/.local/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow->boston311==0.1.0) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /home/briarmoss/.local/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow->boston311==0.1.0) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/lib/python3/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow->boston311==0.1.0) (3.2.0)\n",
            "Building wheels for collected packages: boston311\n",
            "  Building wheel for boston311 (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for boston311: filename=boston311-0.1.0-py3-none-any.whl size=18804 sha256=3afcc888d939daa36ae23c718006fe8d5a6a73adc4755dc952e3b328962bcd08\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-dd6u3jfz/wheels/3d/69/ee/0a6ac96b9c09c948fc0e74f2724a9703aa39749a41fa757c9e\n",
            "Successfully built boston311\n",
            "Installing collected packages: boston311\n",
            "  Attempting uninstall: boston311\n",
            "    Found existing installation: boston311 0.1.0\n",
            "    Uninstalling boston311-0.1.0:\n",
            "      Successfully uninstalled boston311-0.1.0\n",
            "Successfully installed boston311-0.1.0\n"
          ]
        }
      ],
      "source": [
        "! pip install ../"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XP7Hzen_iEAl"
      },
      "source": [
        "##Import the Boston311Model class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "LdhJESm7eWaY"
      },
      "outputs": [],
      "source": [
        "from boston311 import Boston311LogReg, Boston311EventDecTree, Boston311SurvDecTree, Boston311KerasNLP\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oq06XnVjPxvg"
      },
      "source": [
        "## Get latest file URLS and Current Date Ranges"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "_2FYkUb2P1LR"
      },
      "outputs": [],
      "source": [
        "latest_URLS = Boston311LogReg.get311URLs()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mpg9Czm3QDpu",
        "outputId": "5e2b399b-0999-45d4-f9f9-d80ec19941ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'2023': 'https://data.boston.gov/dataset/8048697b-ad64-4bfc-b090-ee00169f2323/resource/e6013a93-1321-4f2a-bf91-8d8a02f1e62f/download/tmpur_spi78.csv', '2022': 'https://data.boston.gov/dataset/8048697b-ad64-4bfc-b090-ee00169f2323/resource/81a7b022-f8fc-4da5-80e4-b160058ca207/download/tmpfm8veglw.csv', '2021': 'https://data.boston.gov/dataset/8048697b-ad64-4bfc-b090-ee00169f2323/resource/f53ebccd-bc61-49f9-83db-625f209c95f5/download/tmp88p9g82n.csv', '2020': 'https://data.boston.gov/dataset/8048697b-ad64-4bfc-b090-ee00169f2323/resource/6ff6a6fd-3141-4440-a880-6f60a37fe789/download/tmpcv_10m2s.csv', '2019': 'https://data.boston.gov/dataset/8048697b-ad64-4bfc-b090-ee00169f2323/resource/ea2e4696-4a2d-429c-9807-d02eb92e0222/download/tmpcje3ep_w.csv', '2018': 'https://data.boston.gov/dataset/8048697b-ad64-4bfc-b090-ee00169f2323/resource/2be28d90-3a90-4af1-a3f6-f28c1e25880a/download/tmp7602cia8.csv', '2017': 'https://data.boston.gov/dataset/8048697b-ad64-4bfc-b090-ee00169f2323/resource/30022137-709d-465e-baae-ca155b51927d/download/tmpzccn8u4q.csv', '2016': 'https://data.boston.gov/dataset/8048697b-ad64-4bfc-b090-ee00169f2323/resource/b7ea6b1b-3ca4-4c5b-9713-6dc1db52379a/download/tmpzxzxeqfb.csv', '2015': 'https://data.boston.gov/dataset/8048697b-ad64-4bfc-b090-ee00169f2323/resource/c9509ab4-6f6d-4b97-979a-0cf2a10c922b/download/tmphrybkxuh.csv', '2014': 'https://data.boston.gov/dataset/8048697b-ad64-4bfc-b090-ee00169f2323/resource/bdae89c8-d4ce-40e9-a6e1-a5203953a2e0/download/tmp8afxvko_.csv', '2013': 'https://data.boston.gov/dataset/8048697b-ad64-4bfc-b090-ee00169f2323/resource/407c5cd0-f764-4a41-adf8-054ff535049e/download/tmpyzk_wmya.csv', '2012': 'https://data.boston.gov/dataset/8048697b-ad64-4bfc-b090-ee00169f2323/resource/382e10d9-1864-40ba-bef6-4eea3c75463c/download/tmpeyvgdt5u.csv', '2011': 'https://data.boston.gov/dataset/8048697b-ad64-4bfc-b090-ee00169f2323/resource/94b499d9-712a-4d2a-b790-7ceec5c9c4b1/download/tmp_9ogynu0.csv'}\n"
          ]
        }
      ],
      "source": [
        "print(latest_URLS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uUMCPAELR9h7",
        "outputId": "05fcba64-1b74-4fb7-a52c-d3f8a499bcc6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-10-14 2023-09-14 2023-10-15\n"
          ]
        }
      ],
      "source": [
        "from datetime import datetime, timedelta\n",
        "now = datetime.now()\n",
        "thirty_days = timedelta(days=30)\n",
        "thirty_days_ago = now - thirty_days\n",
        "today_datestring = now.strftime(\"%Y-%m-%d\")\n",
        "thirty_days_ago_datestring = thirty_days_ago.strftime(\"%Y-%m-%d\")\n",
        "tomorrow_datestring = (datetime.today() + timedelta(days=1)).strftime('%Y-%m-%d')\n",
        "\n",
        "print(today_datestring, thirty_days_ago_datestring, tomorrow_datestring)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [],
      "source": [
        "#set model folder constant\n",
        "MODEL_FOLDER = './daily_models'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load extra features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [],
      "source": [
        "#set path to mydata\n",
        "EXTRA_mydata_FILE = './cls_and_pooled_embeddings_with_service_id.csv'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NN_UiAIvb9MT"
      },
      "source": [
        "##Define several models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "nmi4jJgDF4Fv"
      },
      "outputs": [],
      "source": [
        "linear_tree_model = Boston311SurvDecTree(train_date_range={'start':'2022-01-01','end':thirty_days_ago_datestring},\n",
        "                            predict_date_range={'start':thirty_days_ago_datestring,'end':today_datestring},\n",
        "                            feature_columns=['type','queue'],\n",
        "                            scenario={'dropColumnValues': {'source':['City Worker App', 'Employee Generated']},\n",
        "                                      'survivalTimeMin':0,\n",
        "                                      'survivalTimeFill':tomorrow_datestring},\n",
        "                            files_dict=latest_URLS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "GGSlYgH6s54c"
      },
      "outputs": [],
      "source": [
        "logistic_model = Boston311LogReg(train_date_range={'start':'2022-01-01','end':thirty_days_ago_datestring},\n",
        "                            predict_date_range={'start':thirty_days_ago_datestring,'end':today_datestring},\n",
        "                            feature_columns=['type', 'queue'],\n",
        "                            scenario={'dropColumnValues': {'source':['City Worker App', 'Employee Generated']},\n",
        "                                      'survivalTimeMin':0},\n",
        "                            files_dict=latest_URLS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [],
      "source": [
        "oldlogistic_model = Boston311LogReg(train_date_range={'start':'2022-01-01','end':thirty_days_ago_datestring},\n",
        "                            predict_date_range={'start':thirty_days_ago_datestring,'end':today_datestring},\n",
        "                            feature_columns=['type', 'queue'],\n",
        "                            scenario={'dropColumnValues': {'source':['City Worker App', 'Employee Generated']},\n",
        "                                      'survivalTimeMin':0},\n",
        "                            files_dict=latest_URLS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "_Ddtw6t8s5rj"
      },
      "outputs": [],
      "source": [
        "logistic_tree_model = Boston311EventDecTree(train_date_range={'start':'2022-01-01','end':thirty_days_ago_datestring},\n",
        "                            predict_date_range={'start':thirty_days_ago_datestring,'end':today_datestring},\n",
        "                            feature_columns=['type', 'queue'],\n",
        "                            scenario={'dropColumnValues': {'source':['City Worker App', 'Employee Generated']},\n",
        "                                      'survivalTimeMin':0},\n",
        "                            files_dict=latest_URLS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {},
      "outputs": [],
      "source": [
        "kerasNLP_model = Boston311KerasNLP(train_date_range={'start':'2010-01-01','end':thirty_days_ago_datestring},\n",
        "                            predict_date_range={'start':thirty_days_ago_datestring,'end':today_datestring},\n",
        "                            feature_columns=['queue', 'subject', 'reason', 'department'],\n",
        "                            scenario={'dropColumnValues': {'source':['City Worker App', 'Employee Generated']},\n",
        "                                      'survivalTimeMin':0,\n",
        "                                      'survivalTimeFill':tomorrow_datestring},\n",
        "                            files_dict=latest_URLS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {},
      "outputs": [],
      "source": [
        "#get current datetime in Boston timezone as string\n",
        "from datetime import datetime\n",
        "from pytz import timezone\n",
        "import pytz\n",
        "boston = timezone('US/Eastern')\n",
        "now = datetime.now(boston)\n",
        "today_datestring = now.strftime(\"%Y-%m-%d\")\n",
        "#get time in Boston timezone as string for a filename\n",
        "now = datetime.now(boston)\n",
        "time_string = now.strftime(\"%H-%M-%S\")\n",
        "#define datetime string\n",
        "my_datetime = today_datestring + '_' + time_string "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {},
      "outputs": [],
      "source": [
        "mydata = None\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "\n",
        "case_data_file = 'case_data.pkl'\n",
        "case_data_csv = 'all_311_cases.csv'\n",
        "mydata = None\n",
        "\n",
        "X = None\n",
        "\n",
        "if os.path.exists(case_data_file):\n",
        "    mydata = pickle.load(open(case_data_file, \"rb\"))\n",
        "else:\n",
        "    data = pd.read_csv(case_data_csv)\n",
        "    mydata = kerasNLP_model.load_data(data)\n",
        "\n",
        "    pickle.dump(mydata, open(case_data_file, \"wb\"))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2235124    101004204966\n",
              "2235125    101004204967\n",
              "2235126    101004204970\n",
              "2235127    101004204968\n",
              "2235128    101004204972\n",
              "               ...     \n",
              "2689969    101005045798\n",
              "2689970    101005045799\n",
              "2689971    101005045800\n",
              "2689972    101005045802\n",
              "2689973    101005045804\n",
              "Name: case_enquiry_id, Length: 454850, dtype: int64"
            ]
          },
          "execution_count": 105,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mydata['case_enquiry_id']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {},
      "outputs": [],
      "source": [
        "mydata = kerasNLP_model.enhance_data(mydata)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {},
      "outputs": [],
      "source": [
        "mydata = kerasNLP_model.apply_scenario(mydata)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "mydata = kerasNLP_model.clean_data(mydata)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2235124    101004204966\n",
            "2235125    101004204967\n",
            "2235126    101004204970\n",
            "2235127    101004204968\n",
            "2235128    101004204972\n",
            "               ...     \n",
            "2689969    101005045798\n",
            "2689970    101005045799\n",
            "2689971    101005045800\n",
            "2689972    101005045802\n",
            "2689973    101005045804\n",
            "Name: case_enquiry_id, Length: 400378, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(mydata['case_enquiry_id'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from ast import literal_eval\n",
        "import pickle\n",
        "\n",
        "pickle_file = 'dataframe.pkl'\n",
        "\n",
        "X = None\n",
        "\n",
        "if os.path.exists(pickle_file):\n",
        "    \n",
        "    X = pickle.load(open(pickle_file, \"rb\"))\n",
        "else:\n",
        "    X = pd.read_csv(EXTRA_mydata_FILE)\n",
        "\n",
        "    #rename service_request_id to case_enquiry_id\n",
        "    X.rename(columns={'service_request_id':'case_enquiry_id'}, inplace=True)\n",
        "    #remove all rows where case_enquiry_id is non-numeric\n",
        "    #X = X[X['case_enquiry_id'].str.isnumeric()]\n",
        "    #convert case_enquiry_id to int64\n",
        "    #X['case_enquiry_id'] = X['case_enquiry_id'].astype('int64')\n",
        "\n",
        "    # Convert stringified arrays back to NumPy arrays\n",
        "    X['cls_embedding'] = X['cls_embedding'].apply(literal_eval).apply(np.array)\n",
        "    X['pooled_embedding'] = X['pooled_embedding'].apply(literal_eval).apply(np.array)\n",
        "\n",
        "    pickle.dump(X, open(pickle_file, \"wb\"))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 265388 entries, 0 to 265387\n",
            "Data columns (total 3 columns):\n",
            " #   Column            Non-Null Count   Dtype \n",
            "---  ------            --------------   ----- \n",
            " 0   case_enquiry_id   265388 non-null  int64 \n",
            " 1   cls_embedding     265388 non-null  object\n",
            " 2   pooled_embedding  265388 non-null  object\n",
            "dtypes: int64(1), object(2)\n",
            "memory usage: 6.1+ MB\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "#print information about X2022\n",
        "print(X.info())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {},
      "outputs": [],
      "source": [
        "#concatenate the two dataframes and reindex\n",
        "df = X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(265388, 3)"
            ]
          },
          "execution_count": 113,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Assuming df is your DataFrame and it has columns 'cls_embedding' and 'pooled_embedding'\n",
        "cls_embedding_flattened = np.stack(df['cls_embedding'].to_numpy())\n",
        "pooled_embedding_flattened = np.stack(df['pooled_embedding'].to_numpy())\n",
        "\n",
        "# Remove the old columns\n",
        "df.drop(['cls_embedding', 'pooled_embedding'], axis=1, inplace=True)\n",
        "\n",
        "# Add the new flattened columns\n",
        "df_cls = pd.DataFrame(cls_embedding_flattened, columns=[f'cls_{i}' for i in range(cls_embedding_flattened.shape[1])])\n",
        "df_pooled = pd.DataFrame(pooled_embedding_flattened, columns=[f'pooled_{i}' for i in range(pooled_embedding_flattened.shape[1])])\n",
        "\n",
        "df = pd.concat([df, df_cls, df_pooled], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {},
      "outputs": [],
      "source": [
        "df['case_enquiry_id'] = df['case_enquiry_id'].astype(str)\n",
        "is_numeric = df['case_enquiry_id'].str.isnumeric()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = df[is_numeric]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {},
      "outputs": [],
      "source": [
        "df['case_enquiry_id'] = df['case_enquiry_id'].astype('int64')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(265388, 257)"
            ]
          },
          "execution_count": 118,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = df.drop_duplicates(subset=['case_enquiry_id']) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(265388, 257)"
            ]
          },
          "execution_count": 120,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>case_enquiry_id</th>\n",
              "      <th>cls_0</th>\n",
              "      <th>cls_1</th>\n",
              "      <th>cls_2</th>\n",
              "      <th>cls_3</th>\n",
              "      <th>cls_4</th>\n",
              "      <th>cls_5</th>\n",
              "      <th>cls_6</th>\n",
              "      <th>cls_7</th>\n",
              "      <th>cls_8</th>\n",
              "      <th>...</th>\n",
              "      <th>pooled_118</th>\n",
              "      <th>pooled_119</th>\n",
              "      <th>pooled_120</th>\n",
              "      <th>pooled_121</th>\n",
              "      <th>pooled_122</th>\n",
              "      <th>pooled_123</th>\n",
              "      <th>pooled_124</th>\n",
              "      <th>pooled_125</th>\n",
              "      <th>pooled_126</th>\n",
              "      <th>pooled_127</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>101004113559</td>\n",
              "      <td>-1.100319</td>\n",
              "      <td>0.180848</td>\n",
              "      <td>-3.067521</td>\n",
              "      <td>-2.449431</td>\n",
              "      <td>0.048062</td>\n",
              "      <td>0.750774</td>\n",
              "      <td>-1.156688</td>\n",
              "      <td>1.701071</td>\n",
              "      <td>-1.121157</td>\n",
              "      <td>...</td>\n",
              "      <td>0.090089</td>\n",
              "      <td>-0.993815</td>\n",
              "      <td>0.030800</td>\n",
              "      <td>-0.999999</td>\n",
              "      <td>-0.700883</td>\n",
              "      <td>0.967637</td>\n",
              "      <td>-0.999964</td>\n",
              "      <td>0.997570</td>\n",
              "      <td>0.920985</td>\n",
              "      <td>0.997373</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>101004113295</td>\n",
              "      <td>-0.136960</td>\n",
              "      <td>0.691521</td>\n",
              "      <td>-3.540846</td>\n",
              "      <td>-1.352687</td>\n",
              "      <td>1.299200</td>\n",
              "      <td>-0.141181</td>\n",
              "      <td>0.158119</td>\n",
              "      <td>2.410162</td>\n",
              "      <td>0.071449</td>\n",
              "      <td>...</td>\n",
              "      <td>0.257915</td>\n",
              "      <td>-0.996913</td>\n",
              "      <td>0.094944</td>\n",
              "      <td>-0.999995</td>\n",
              "      <td>-0.720977</td>\n",
              "      <td>0.951603</td>\n",
              "      <td>-0.999172</td>\n",
              "      <td>0.944971</td>\n",
              "      <td>0.856084</td>\n",
              "      <td>0.836672</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>101004113630</td>\n",
              "      <td>0.175361</td>\n",
              "      <td>0.668518</td>\n",
              "      <td>-3.556810</td>\n",
              "      <td>-1.355421</td>\n",
              "      <td>1.444425</td>\n",
              "      <td>0.603148</td>\n",
              "      <td>-1.361185</td>\n",
              "      <td>1.510217</td>\n",
              "      <td>-0.073560</td>\n",
              "      <td>...</td>\n",
              "      <td>0.026681</td>\n",
              "      <td>-0.997237</td>\n",
              "      <td>-0.056582</td>\n",
              "      <td>-0.999915</td>\n",
              "      <td>-0.639985</td>\n",
              "      <td>0.960599</td>\n",
              "      <td>-0.998327</td>\n",
              "      <td>0.998861</td>\n",
              "      <td>0.978732</td>\n",
              "      <td>0.994388</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>101004113228</td>\n",
              "      <td>-0.649289</td>\n",
              "      <td>0.929046</td>\n",
              "      <td>-2.988562</td>\n",
              "      <td>-1.767200</td>\n",
              "      <td>-0.438132</td>\n",
              "      <td>-0.361119</td>\n",
              "      <td>0.010478</td>\n",
              "      <td>1.114518</td>\n",
              "      <td>-0.448996</td>\n",
              "      <td>...</td>\n",
              "      <td>0.124731</td>\n",
              "      <td>-0.999928</td>\n",
              "      <td>0.179910</td>\n",
              "      <td>-0.999997</td>\n",
              "      <td>-0.888259</td>\n",
              "      <td>0.636486</td>\n",
              "      <td>-0.999839</td>\n",
              "      <td>0.998700</td>\n",
              "      <td>0.636364</td>\n",
              "      <td>0.968712</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>101004113229</td>\n",
              "      <td>-0.649289</td>\n",
              "      <td>0.929046</td>\n",
              "      <td>-2.988562</td>\n",
              "      <td>-1.767200</td>\n",
              "      <td>-0.438132</td>\n",
              "      <td>-0.361119</td>\n",
              "      <td>0.010478</td>\n",
              "      <td>1.114518</td>\n",
              "      <td>-0.448996</td>\n",
              "      <td>...</td>\n",
              "      <td>0.124731</td>\n",
              "      <td>-0.999928</td>\n",
              "      <td>0.179910</td>\n",
              "      <td>-0.999997</td>\n",
              "      <td>-0.888259</td>\n",
              "      <td>0.636486</td>\n",
              "      <td>-0.999839</td>\n",
              "      <td>0.998700</td>\n",
              "      <td>0.636364</td>\n",
              "      <td>0.968712</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 257 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   case_enquiry_id     cls_0     cls_1     cls_2     cls_3     cls_4  \\\n",
              "0     101004113559 -1.100319  0.180848 -3.067521 -2.449431  0.048062   \n",
              "1     101004113295 -0.136960  0.691521 -3.540846 -1.352687  1.299200   \n",
              "2     101004113630  0.175361  0.668518 -3.556810 -1.355421  1.444425   \n",
              "3     101004113228 -0.649289  0.929046 -2.988562 -1.767200 -0.438132   \n",
              "4     101004113229 -0.649289  0.929046 -2.988562 -1.767200 -0.438132   \n",
              "\n",
              "      cls_5     cls_6     cls_7     cls_8  ...  pooled_118  pooled_119  \\\n",
              "0  0.750774 -1.156688  1.701071 -1.121157  ...    0.090089   -0.993815   \n",
              "1 -0.141181  0.158119  2.410162  0.071449  ...    0.257915   -0.996913   \n",
              "2  0.603148 -1.361185  1.510217 -0.073560  ...    0.026681   -0.997237   \n",
              "3 -0.361119  0.010478  1.114518 -0.448996  ...    0.124731   -0.999928   \n",
              "4 -0.361119  0.010478  1.114518 -0.448996  ...    0.124731   -0.999928   \n",
              "\n",
              "   pooled_120  pooled_121  pooled_122  pooled_123  pooled_124  pooled_125  \\\n",
              "0    0.030800   -0.999999   -0.700883    0.967637   -0.999964    0.997570   \n",
              "1    0.094944   -0.999995   -0.720977    0.951603   -0.999172    0.944971   \n",
              "2   -0.056582   -0.999915   -0.639985    0.960599   -0.998327    0.998861   \n",
              "3    0.179910   -0.999997   -0.888259    0.636486   -0.999839    0.998700   \n",
              "4    0.179910   -0.999997   -0.888259    0.636486   -0.999839    0.998700   \n",
              "\n",
              "   pooled_126  pooled_127  \n",
              "0    0.920985    0.997373  \n",
              "1    0.856084    0.836672  \n",
              "2    0.978732    0.994388  \n",
              "3    0.636364    0.968712  \n",
              "4    0.636364    0.968712  \n",
              "\n",
              "[5 rows x 257 columns]"
            ]
          },
          "execution_count": 121,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(400378, 246)"
            ]
          },
          "execution_count": 122,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mydata.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {},
      "outputs": [],
      "source": [
        "mydata = mydata.drop_duplicates(subset=['case_enquiry_id'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(400378, 246)"
            ]
          },
          "execution_count": 124,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mydata.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {},
      "outputs": [],
      "source": [
        "#join them so we are left only with records that have mydata in both files\n",
        "new_mydata = mydata.merge(df, on='case_enquiry_id', how='inner')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(152949, 502)"
            ]
          },
          "execution_count": 126,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "new_mydata.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {},
      "outputs": [],
      "source": [
        "old_bin_edges = [0, 12, 24, 72, 168, 336, 672, 1344, 2688, 9999999]\n",
        "old_bin_labels = [\n",
        "                \"0-12 hours\",      # Less than half a day\n",
        "                \"12-24 hours\",     # Half to one day\n",
        "                \"1-3 days\",        # One to three days\n",
        "                \"4-7 days\",        # Four to seven days\n",
        "                \"1-2 weeks\",       # One to two weeks\n",
        "                \"2-4 weeks\",       # Two to four weeks\n",
        "                \"1-2 months\",      # One to two months\n",
        "                \"2-4 months\",      # Two to four months\n",
        "                \"4+ months\"        # More than four months\n",
        "            ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {},
      "outputs": [],
      "source": [
        "bin_edges = [0, 24, 48, 72, 96, 120, 144, 168, 192, 216, 240, 264, 288, 312, 336, 360, 384, 408, 432, 456, 480, 504, 528, 552, 576, 600, 624, 648, 672, 696, 720, 744, 768, 792, 816, 840, 864, 888, 912, 936, 960, 984, 1008, 1032, 1056, 1080, 1104, 1128, 1152, 1176, 1200, 1224, 1248, 1272, 1296, 1320, 1344, 1368, 1392, 1416, 1440, 1464, 1488, 1512, 1536, 1560, 1584, 1608, 1632, 1656, 1680, 1704, 1728, 1752, 1776, 1800, 1824, 1848, 1872, 1896, 1920, 1944, 1968, 1992, 2016, 2040, 2064, 2088, 2112, 2136, 2160, 2184, 2208, 2232, 2256, 2280, 2304, 2328, 2352, 2376, 2400, 2424, 2448, 2472, 2496, 2520, 2544, 2568, 2592, 2616, 2640, 2664, 2688, 2712, 2736, 2760, 2784, 2808, 2832, 2856, 2880, 2904, 2928, 2952, 2976, 3000, 3024, 3048, 3072, 3096, 3120, 3144, 3168, 3192, 3216, 3240, 3264, 3288, 3312, 3336, 3360, 3384, 3408, 3432, 3456, 3480, 3504, 3528, 3552, 3576, 3600, 3624, 3648, 3672, 3696, 3720, 3744, 3768, 3792, 3816, 3840, 3864, 3888, 3912, 3936, 3960, 3984, 4008, 4032, 4056, 4080, 4104, 4128, 4152, 4176, 4200, 4224, 4248, 4272, 4296, 4320, 1000000]\n",
        "bin_labels = [\n",
        "            \"0-24 hours\", \"1-2 days\", \"2-3 days\", \"3-4 days\", \"4-5 days\", \n",
        "            \"5-6 days\", \"6-7 days\", \"7-8 days\", \"8-9 days\", \"9-10 days\",\n",
        "            \"10-11 days\", \"11-12 days\", \"12-13 days\", \"13-14 days\", \"14-15 days\",\n",
        "            \"15-16 days\", \"16-17 days\", \"17-18 days\", \"18-19 days\", \"19-20 days\",\n",
        "            \"20-21 days\", \"21-22 days\", \"22-23 days\", \"23-24 days\", \"24-25 days\",\n",
        "            \"25-26 days\", \"26-27 days\", \"27-28 days\", \"28-29 days\", \"29-30 days\",\n",
        "            \"30-31 days\", \"31-32 days\", \"32-33 days\", \"33-34 days\", \"34-35 days\",\n",
        "            \"35-36 days\", \"36-37 days\", \"37-38 days\", \"38-39 days\", \"39-40 days\",\n",
        "            \"40-41 days\", \"41-42 days\", \"42-43 days\", \"43-44 days\", \"44-45 days\",\n",
        "            \"45-46 days\", \"46-47 days\", \"47-48 days\", \"48-49 days\", \"49-50 days\",\n",
        "            \"50-51 days\", \"51-52 days\", \"52-53 days\", \"53-54 days\", \"54-55 days\",\n",
        "            \"55-56 days\", \"56-57 days\", \"57-58 days\", \"58-59 days\", \"59-60 days\",\n",
        "            \"60-61 days\", \"61-62 days\", \"62-63 days\", \"63-64 days\", \"64-65 days\",\n",
        "            \"65-66 days\", \"66-67 days\", \"67-68 days\", \"68-69 days\", \"69-70 days\",\n",
        "            \"70-71 days\", \"71-72 days\", \"72-73 days\", \"73-74 days\", \"74-75 days\",\n",
        "            \"75-76 days\", \"76-77 days\", \"77-78 days\", \"78-79 days\", \"79-80 days\",\n",
        "            \"80-81 days\", \"81-82 days\", \"82-83 days\", \"83-84 days\", \"84-85 days\",\n",
        "            \"85-86 days\", \"86-87 days\", \"87-88 days\", \"88-89 days\", \"89-90 days\",\n",
        "            \"90-91 days\", \"91-92 days\", \"92-93 days\", \"93-94 days\", \"94-95 days\",\n",
        "            \"95-96 days\", \"96-97 days\", \"97-98 days\", \"98-99 days\", \"99-100 days\",\n",
        "            \"100-101 days\", \"101-102 days\", \"102-103 days\", \"103-104 days\", \"104-105 days\",\n",
        "            \"105-106 days\", \"106-107 days\", \"107-108 days\", \"108-109 days\", \"109-110 days\",\n",
        "            \"110-111 days\", \"111-112 days\", \"112-113 days\", \"113-114 days\", \"114-115 days\",\n",
        "            \"115-116 days\", \"116-117 days\", \"117-118 days\", \"118-119 days\", \"119-120 days\",\n",
        "            \"120-121 days\", \"121-122 days\", \"122-123 days\", \"123-124 days\", \"124-125 days\",\n",
        "            \"125-126 days\", \"126-127 days\", \"127-128 days\", \"128-129 days\", \"129-130 days\",\n",
        "            \"130-131 days\", \"131-132 days\", \"132-133 days\", \"133-134 days\", \"134-135 days\",\n",
        "            \"135-136 days\", \"136-137 days\", \"137-138 days\", \"138-139 days\", \"139-140 days\",\n",
        "            \"140-141 days\", \"141-142 days\", \"142-143 days\", \"143-144 days\", \"144-145 days\",\n",
        "            \"145-146 days\", \"146-147 days\", \"147-148 days\", \"148-149 days\", \"149-150 days\",\n",
        "            \"150-151 days\", \"151-152 days\", \"152-153 days\", \"153-154 days\", \"154-155 days\",\n",
        "            \"155-156 days\", \"156-157 days\", \"157-158 days\", \"158-159 days\", \"159-160 days\",\n",
        "            \"160-161 days\", \"161-162 days\", \"162-163 days\", \"163-164 days\", \"164-165 days\",\n",
        "            \"165-166 days\", \"166-167 days\", \"167-168 days\", \"168-169 days\", \"169-170 days\",\n",
        "            \"170-171 days\", \"171-172 days\", \"172-173 days\", \"173-174 days\", \"174-175 days\",\n",
        "            \"175-176 days\", \"176-177 days\", \"177-178 days\", \"178-179 days\", \"179-180 days\",\n",
        "            \"180+ days\"]\n",
        "bin_number = len(bin_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "$prediction_timespans = [\n",
            "    \"0-24 hours\" => [0, 24],\n",
            "    \"1-2 days\" => [24, 48],\n",
            "    \"2-3 days\" => [48, 72],\n",
            "    \"3-4 days\" => [72, 96],\n",
            "    \"4-5 days\" => [96, 120],\n",
            "    \"5-6 days\" => [120, 144],\n",
            "    \"6-7 days\" => [144, 168],\n",
            "    \"7-8 days\" => [168, 192],\n",
            "    \"8-9 days\" => [192, 216],\n",
            "    \"9-10 days\" => [216, 240],\n",
            "    \"10-11 days\" => [240, 264],\n",
            "    \"11-12 days\" => [264, 288],\n",
            "    \"12-13 days\" => [288, 312],\n",
            "    \"13-14 days\" => [312, 336],\n",
            "    \"14-15 days\" => [336, 360],\n",
            "    \"15-16 days\" => [360, 384],\n",
            "    \"16-17 days\" => [384, 408],\n",
            "    \"17-18 days\" => [408, 432],\n",
            "    \"18-19 days\" => [432, 456],\n",
            "    \"19-20 days\" => [456, 480],\n",
            "    \"20-21 days\" => [480, 504],\n",
            "    \"21-22 days\" => [504, 528],\n",
            "    \"22-23 days\" => [528, 552],\n",
            "    \"23-24 days\" => [552, 576],\n",
            "    \"24-25 days\" => [576, 600],\n",
            "    \"25-26 days\" => [600, 624],\n",
            "    \"26-27 days\" => [624, 648],\n",
            "    \"27-28 days\" => [648, 672],\n",
            "    \"28-29 days\" => [672, 696],\n",
            "    \"29-30 days\" => [696, 720],\n",
            "    \"30-31 days\" => [720, 744],\n",
            "    \"31-32 days\" => [744, 768],\n",
            "    \"32-33 days\" => [768, 792],\n",
            "    \"33-34 days\" => [792, 816],\n",
            "    \"34-35 days\" => [816, 840],\n",
            "    \"35-36 days\" => [840, 864],\n",
            "    \"36-37 days\" => [864, 888],\n",
            "    \"37-38 days\" => [888, 912],\n",
            "    \"38-39 days\" => [912, 936],\n",
            "    \"39-40 days\" => [936, 960],\n",
            "    \"40-41 days\" => [960, 984],\n",
            "    \"41-42 days\" => [984, 1008],\n",
            "    \"42-43 days\" => [1008, 1032],\n",
            "    \"43-44 days\" => [1032, 1056],\n",
            "    \"44-45 days\" => [1056, 1080],\n",
            "    \"45-46 days\" => [1080, 1104],\n",
            "    \"46-47 days\" => [1104, 1128],\n",
            "    \"47-48 days\" => [1128, 1152],\n",
            "    \"48-49 days\" => [1152, 1176],\n",
            "    \"49-50 days\" => [1176, 1200],\n",
            "    \"50-51 days\" => [1200, 1224],\n",
            "    \"51-52 days\" => [1224, 1248],\n",
            "    \"52-53 days\" => [1248, 1272],\n",
            "    \"53-54 days\" => [1272, 1296],\n",
            "    \"54-55 days\" => [1296, 1320],\n",
            "    \"55-56 days\" => [1320, 1344],\n",
            "    \"56-57 days\" => [1344, 1368],\n",
            "    \"57-58 days\" => [1368, 1392],\n",
            "    \"58-59 days\" => [1392, 1416],\n",
            "    \"59-60 days\" => [1416, 1440],\n",
            "    \"60-61 days\" => [1440, 1464],\n",
            "    \"61-62 days\" => [1464, 1488],\n",
            "    \"62-63 days\" => [1488, 1512],\n",
            "    \"63-64 days\" => [1512, 1536],\n",
            "    \"64-65 days\" => [1536, 1560],\n",
            "    \"65-66 days\" => [1560, 1584],\n",
            "    \"66-67 days\" => [1584, 1608],\n",
            "    \"67-68 days\" => [1608, 1632],\n",
            "    \"68-69 days\" => [1632, 1656],\n",
            "    \"69-70 days\" => [1656, 1680],\n",
            "    \"70-71 days\" => [1680, 1704],\n",
            "    \"71-72 days\" => [1704, 1728],\n",
            "    \"72-73 days\" => [1728, 1752],\n",
            "    \"73-74 days\" => [1752, 1776],\n",
            "    \"74-75 days\" => [1776, 1800],\n",
            "    \"75-76 days\" => [1800, 1824],\n",
            "    \"76-77 days\" => [1824, 1848],\n",
            "    \"77-78 days\" => [1848, 1872],\n",
            "    \"78-79 days\" => [1872, 1896],\n",
            "    \"79-80 days\" => [1896, 1920],\n",
            "    \"80-81 days\" => [1920, 1944],\n",
            "    \"81-82 days\" => [1944, 1968],\n",
            "    \"82-83 days\" => [1968, 1992],\n",
            "    \"83-84 days\" => [1992, 2016],\n",
            "    \"84-85 days\" => [2016, 2040],\n",
            "    \"85-86 days\" => [2040, 2064],\n",
            "    \"86-87 days\" => [2064, 2088],\n",
            "    \"87-88 days\" => [2088, 2112],\n",
            "    \"88-89 days\" => [2112, 2136],\n",
            "    \"89-90 days\" => [2136, 2160],\n",
            "    \"90-91 days\" => [2160, 2184],\n",
            "    \"91-92 days\" => [2184, 2208],\n",
            "    \"92-93 days\" => [2208, 2232],\n",
            "    \"93-94 days\" => [2232, 2256],\n",
            "    \"94-95 days\" => [2256, 2280],\n",
            "    \"95-96 days\" => [2280, 2304],\n",
            "    \"96-97 days\" => [2304, 2328],\n",
            "    \"97-98 days\" => [2328, 2352],\n",
            "    \"98-99 days\" => [2352, 2376],\n",
            "    \"99-100 days\" => [2376, 2400],\n",
            "    \"100-101 days\" => [2400, 2424],\n",
            "    \"101-102 days\" => [2424, 2448],\n",
            "    \"102-103 days\" => [2448, 2472],\n",
            "    \"103-104 days\" => [2472, 2496],\n",
            "    \"104-105 days\" => [2496, 2520],\n",
            "    \"105-106 days\" => [2520, 2544],\n",
            "    \"106-107 days\" => [2544, 2568],\n",
            "    \"107-108 days\" => [2568, 2592],\n",
            "    \"108-109 days\" => [2592, 2616],\n",
            "    \"109-110 days\" => [2616, 2640],\n",
            "    \"110-111 days\" => [2640, 2664],\n",
            "    \"111-112 days\" => [2664, 2688],\n",
            "    \"112-113 days\" => [2688, 2712],\n",
            "    \"113-114 days\" => [2712, 2736],\n",
            "    \"114-115 days\" => [2736, 2760],\n",
            "    \"115-116 days\" => [2760, 2784],\n",
            "    \"116-117 days\" => [2784, 2808],\n",
            "    \"117-118 days\" => [2808, 2832],\n",
            "    \"118-119 days\" => [2832, 2856],\n",
            "    \"119-120 days\" => [2856, 2880],\n",
            "    \"120-121 days\" => [2880, 2904],\n",
            "    \"121-122 days\" => [2904, 2928],\n",
            "    \"122-123 days\" => [2928, 2952],\n",
            "    \"123-124 days\" => [2952, 2976],\n",
            "    \"124-125 days\" => [2976, 3000],\n",
            "    \"125-126 days\" => [3000, 3024],\n",
            "    \"126-127 days\" => [3024, 3048],\n",
            "    \"127-128 days\" => [3048, 3072],\n",
            "    \"128-129 days\" => [3072, 3096],\n",
            "    \"129-130 days\" => [3096, 3120],\n",
            "    \"130-131 days\" => [3120, 3144],\n",
            "    \"131-132 days\" => [3144, 3168],\n",
            "    \"132-133 days\" => [3168, 3192],\n",
            "    \"133-134 days\" => [3192, 3216],\n",
            "    \"134-135 days\" => [3216, 3240],\n",
            "    \"135-136 days\" => [3240, 3264],\n",
            "    \"136-137 days\" => [3264, 3288],\n",
            "    \"137-138 days\" => [3288, 3312],\n",
            "    \"138-139 days\" => [3312, 3336],\n",
            "    \"139-140 days\" => [3336, 3360],\n",
            "    \"140-141 days\" => [3360, 3384],\n",
            "    \"141-142 days\" => [3384, 3408],\n",
            "    \"142-143 days\" => [3408, 3432],\n",
            "    \"143-144 days\" => [3432, 3456],\n",
            "    \"144-145 days\" => [3456, 3480],\n",
            "    \"145-146 days\" => [3480, 3504],\n",
            "    \"146-147 days\" => [3504, 3528],\n",
            "    \"147-148 days\" => [3528, 3552],\n",
            "    \"148-149 days\" => [3552, 3576],\n",
            "    \"149-150 days\" => [3576, 3600],\n",
            "    \"150-151 days\" => [3600, 3624],\n",
            "    \"151-152 days\" => [3624, 3648],\n",
            "    \"152-153 days\" => [3648, 3672],\n",
            "    \"153-154 days\" => [3672, 3696],\n",
            "    \"154-155 days\" => [3696, 3720],\n",
            "    \"155-156 days\" => [3720, 3744],\n",
            "    \"156-157 days\" => [3744, 3768],\n",
            "    \"157-158 days\" => [3768, 3792],\n",
            "    \"158-159 days\" => [3792, 3816],\n",
            "    \"159-160 days\" => [3816, 3840],\n",
            "    \"160-161 days\" => [3840, 3864],\n",
            "    \"161-162 days\" => [3864, 3888],\n",
            "    \"162-163 days\" => [3888, 3912],\n",
            "    \"163-164 days\" => [3912, 3936],\n",
            "    \"164-165 days\" => [3936, 3960],\n",
            "    \"165-166 days\" => [3960, 3984],\n",
            "    \"166-167 days\" => [3984, 4008],\n",
            "    \"167-168 days\" => [4008, 4032],\n",
            "    \"168-169 days\" => [4032, 4056],\n",
            "    \"169-170 days\" => [4056, 4080],\n",
            "    \"170-171 days\" => [4080, 4104],\n",
            "    \"171-172 days\" => [4104, 4128],\n",
            "    \"172-173 days\" => [4128, 4152],\n",
            "    \"173-174 days\" => [4152, 4176],\n",
            "    \"174-175 days\" => [4176, 4200],\n",
            "    \"175-176 days\" => [4200, 4224],\n",
            "    \"176-177 days\" => [4224, 4248],\n",
            "    \"177-178 days\" => [4248, 4272],\n",
            "    \"178-179 days\" => [4272, 4296],\n",
            "    \"179-180 days\" => [4296, 4320],\n",
            "    \"180+ days\" => [4320, 1000000],\n",
            "];\n"
          ]
        }
      ],
      "source": [
        "php_array = \"$prediction_timespans = [\\n\"\n",
        "for i, label in enumerate(bin_labels):\n",
        "    php_array += f'    \"{label}\" => [{bin_edges[i]}, {bin_edges[i + 1]}],\\n'\n",
        "php_array += \"];\"\n",
        "\n",
        "print(php_array)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "df, y = kerasNLP_model.split_data(new_mydata, bin_edges=bin_edges, bin_labels=bin_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {},
      "outputs": [],
      "source": [
        "#cast all columns that are type bool to float\n",
        "for col in df.columns:\n",
        "    if df[col].dtype == 'bool':\n",
        "        df[col] = df[col].astype('float64')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(152949, 499)\n",
            "(152949,)\n"
          ]
        }
      ],
      "source": [
        "#list the number of rows in X and y\n",
        "print(df.shape)\n",
        "print(y.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {},
      "outputs": [],
      "source": [
        "#best_model, best_hyperparameters = kerasNLP_model.tune_model(df, y, '/home/briarmoss/Documents/Boston_311/models/tuning')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {},
      "outputs": [],
      "source": [
        "#define hyperparameters\n",
        "from kerastuner import HyperParameters\n",
        "\n",
        "#set constants\n",
        "start_nodes = 1024\n",
        "end_nodes = 256\n",
        "#l2_0 = 0.00001\n",
        "#learning_rate = 7.5842e-05\n",
        "l2_0 = 0.001\n",
        "learning_rate = 0.0001\n",
        "\n",
        "\n",
        "hp = HyperParameters()\n",
        "hp.Fixed('start_nodes', start_nodes)\n",
        "hp.Fixed('end_nodes', end_nodes)\n",
        "hp.Fixed('l2_0', l2_0)\n",
        "hp.Fixed('learning_rate', learning_rate)\n",
        "hp.Fixed('final_layer', bin_number)\n",
        "hp.Fixed('final_activation', 'softmax')\n",
        "kerasNLP_model.best_hyperparameters = hp\n",
        "\n",
        "\n",
        "#parameters for linear regression\n",
        "linear='''\n",
        "hp = HyperParameters()\n",
        "hp.Fixed('start_nodes', start_nodes)\n",
        "hp.Fixed('end_nodes', end_nodes)\n",
        "hp.Fixed('l2_0', l2_0)\n",
        "hp.Fixed('learning_rate', learning_rate)\n",
        "hp.Fixed('final_layer', 1)\n",
        "hp.Fixed('final_activation', 'linear')\n",
        "kerasNLP_model.best_hyperparameters = hp\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {},
      "outputs": [],
      "source": [
        "#free all unused dataframes\n",
        "df_to_delete = [cls_embedding_flattened, pooled_embedding_flattened, df_cls, df_pooled, X, new_mydata, is_numeric, mydata]\n",
        "\n",
        "for data_frame in df_to_delete:\n",
        "    del data_frame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "25"
            ]
          },
          "execution_count": 136,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import gc\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting Training at 2023-10-14 22:57:23.057345\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_12 (Dense)            (None, 1024)              512000    \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 512)               524800    \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 256)               131328    \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 181)               46517     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1214645 (4.63 MB)\n",
            "Trainable params: 1214645 (4.63 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n",
            "<class 'pandas.core.frame.DataFrame'> (122359, 181)\n",
            "<class 'pandas.core.frame.DataFrame'> (30590, 181)\n",
            "run fit\n",
            "\n",
            "Epoch 1/100\n",
            "3824/3824 [==============================] - 29s 8ms/step - loss: 2.2903 - accuracy: 0.6494 - top_k_categorical_accuracy: 0.7290 - val_loss: 1.9647 - val_accuracy: 0.6526 - val_top_k_categorical_accuracy: 0.7347\n",
            "Epoch 2/100\n",
            "3824/3824 [==============================] - 29s 8ms/step - loss: 1.8476 - accuracy: 0.6582 - top_k_categorical_accuracy: 0.7366 - val_loss: 1.7919 - val_accuracy: 0.6540 - val_top_k_categorical_accuracy: 0.7368\n",
            "Epoch 3/100\n",
            "3824/3824 [==============================] - 29s 8ms/step - loss: 1.7300 - accuracy: 0.6592 - top_k_categorical_accuracy: 0.7385 - val_loss: 1.7099 - val_accuracy: 0.6547 - val_top_k_categorical_accuracy: 0.7363\n",
            "Epoch 4/100\n",
            "3824/3824 [==============================] - 29s 8ms/step - loss: 1.6753 - accuracy: 0.6596 - top_k_categorical_accuracy: 0.7389 - val_loss: 1.6889 - val_accuracy: 0.6543 - val_top_k_categorical_accuracy: 0.7361\n",
            "Epoch 5/100\n",
            "1423/3824 [==========>...................] - ETA: 17s - loss: 1.6398 - accuracy: 0.6648 - top_k_categorical_accuracy: 0.7425"
          ]
        }
      ],
      "source": [
        "\n",
        "#parse CLS embedding column as array\n",
        "test_acc = kerasNLP_model.train_model( df, y )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sSSkyth-2K3A"
      },
      "source": [
        "## Train several models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "learning is fun!\n"
          ]
        }
      ],
      "source": [
        "print(\"learning is fun!\") "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lv4ivBuvinss",
        "outputId": "814ef4fb-e100-4b22-ccbc-6b9d91e5a341"
      },
      "outputs": [],
      "source": [
        "#logistic_tree_model.run_pipeline()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_UIaks6jjPkU",
        "outputId": "0e365ed1-472e-4cb1-cdde-ae0a2d32722e"
      },
      "outputs": [],
      "source": [
        "#logistic_model.run_pipeline()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2290"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import gc\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#linear_tree_model.run_pipeline()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/briarmoss/.local/lib/python3.10/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ],
      "source": [
        "import datetime\n",
        "\n",
        "def save_model_to_dir(model, folder_name):\n",
        "    dir_path = os.path.join(MODEL_FOLDER, folder_name)\n",
        "    \n",
        "    if not os.path.exists(dir_path):\n",
        "        os.mkdir(dir_path)\n",
        "    \n",
        "    timestamp = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "    model_name = timestamp + \"_\" + model.model_type\n",
        "    properties_name = model_name\n",
        "    \n",
        "    model.save(dir_path, model_name, properties_name)\n",
        "\n",
        "# List of models\n",
        "models = [kerasNLP_model]\n",
        "\n",
        "\n",
        "# Iterate over models and save\n",
        "for model in models:\n",
        "    save_model_to_dir(model, model.model_type)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"\\ndata = kerasNLP_model.load_data( 'predict' )\\ndata = kerasNLP_model.enhance_data( data, 'predict')\\nclean_data = kerasNLP_model.clean_data_for_prediction( data )\\n\\nX_predict, y_predict = kerasNLP_model.split_data( clean_data )\\ny_predict = kerasNLP_model.model.predict(X_predict)\\ndata['survival_prediction'] = y_predict\\nreturn data\\n\""
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\"\"\"\n",
        "data = kerasNLP_model.load_data( 'predict' )\n",
        "data = kerasNLP_model.enhance_data( data, 'predict')\n",
        "clean_data = kerasNLP_model.clean_data_for_prediction( data )\n",
        "\n",
        "X_predict, y_predict = kerasNLP_model.split_data( clean_data )\n",
        "y_predict = kerasNLP_model.model.predict(X_predict)\n",
        "data['survival_prediction'] = y_predict\n",
        "return data\n",
        "\"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "import datetime\n",
        "\n",
        "def save_model_to_dir(model, folder_name):\n",
        "    dir_path = os.path.join(MODEL_FOLDER, folder_name)\n",
        "    \n",
        "    if not os.path.exists(dir_path):\n",
        "        os.mkdir(dir_path)\n",
        "    \n",
        "    timestamp = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "    model_name = timestamp + \"_\" + model.model_type\n",
        "    properties_name = model_name\n",
        "    \n",
        "    model.save(dir_path, model_name, properties_name)\n",
        "\n",
        "# List of models\n",
        "models = [kerasNLP_model]\n",
        "\n",
        "\n",
        "# Iterate over models and save\n",
        "for model in models:\n",
        "    save_model_to_dir(model, model.model_type)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
