{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P1BXqsllgueC"
      },
      "source": [
        "#Boston 311 Tutorial\n",
        "\n",
        "This notebook will run you through the basic usage of this package to train 3 models on the Boston 311 mydata and use them to predict the outcome of cases from the last 30 days"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: keras-tuner in /home/briarmoss/.local/lib/python3.10/site-packages (1.4.0)\n",
            "Requirement already satisfied: requests in /usr/lib/python3/dist-packages (from keras-tuner) (2.25.1)\n",
            "Requirement already satisfied: kt-legacy in /home/briarmoss/.local/lib/python3.10/site-packages (from keras-tuner) (1.0.5)\n",
            "Requirement already satisfied: keras-core in /home/briarmoss/.local/lib/python3.10/site-packages (from keras-tuner) (0.1.7)\n",
            "Requirement already satisfied: packaging in /home/briarmoss/.local/lib/python3.10/site-packages (from keras-tuner) (23.1)\n",
            "Requirement already satisfied: numpy in /home/briarmoss/.local/lib/python3.10/site-packages (from keras-core->keras-tuner) (1.23.5)\n",
            "Requirement already satisfied: rich in /home/briarmoss/.local/lib/python3.10/site-packages (from keras-core->keras-tuner) (13.5.3)\n",
            "Requirement already satisfied: namex in /home/briarmoss/.local/lib/python3.10/site-packages (from keras-core->keras-tuner) (0.0.7)\n",
            "Requirement already satisfied: absl-py in /home/briarmoss/.local/lib/python3.10/site-packages (from keras-core->keras-tuner) (1.4.0)\n",
            "Requirement already satisfied: dm-tree in /home/briarmoss/.local/lib/python3.10/site-packages (from keras-core->keras-tuner) (0.1.8)\n",
            "Requirement already satisfied: h5py in /home/briarmoss/.local/lib/python3.10/site-packages (from keras-core->keras-tuner) (3.8.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/briarmoss/.local/lib/python3.10/site-packages (from rich->keras-core->keras-tuner) (2.15.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/briarmoss/.local/lib/python3.10/site-packages (from rich->keras-core->keras-tuner) (3.0.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /home/briarmoss/.local/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras-core->keras-tuner) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install keras-tuner"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Processing /home/briarmoss/Documents/Boston_311\n",
            "  Installing build dependencies ... \u001b[?25ldone\n",
            "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
            "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25hRequirement already satisfied: tensorflow in /home/briarmoss/.local/lib/python3.10/site-packages (from boston311==0.1.0) (2.13.0)\n",
            "Requirement already satisfied: pandas in /home/briarmoss/.local/lib/python3.10/site-packages (from boston311==0.1.0) (2.0.2)\n",
            "Requirement already satisfied: matplotlib in /usr/lib/python3/dist-packages (from boston311==0.1.0) (3.5.1)\n",
            "Requirement already satisfied: scikit-learn in /home/briarmoss/.local/lib/python3.10/site-packages (from boston311==0.1.0) (1.2.2)\n",
            "Requirement already satisfied: numpy in /home/briarmoss/.local/lib/python3.10/site-packages (from boston311==0.1.0) (1.23.5)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /home/briarmoss/.local/lib/python3.10/site-packages (from pandas->boston311==0.1.0) (2023.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /home/briarmoss/.local/lib/python3.10/site-packages (from pandas->boston311==0.1.0) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas->boston311==0.1.0) (2022.1)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /home/briarmoss/.local/lib/python3.10/site-packages (from scikit-learn->boston311==0.1.0) (1.10.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/briarmoss/.local/lib/python3.10/site-packages (from scikit-learn->boston311==0.1.0) (3.1.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /home/briarmoss/.local/lib/python3.10/site-packages (from scikit-learn->boston311==0.1.0) (1.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /home/briarmoss/.local/lib/python3.10/site-packages (from tensorflow->boston311==0.1.0) (3.3.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /home/briarmoss/.local/lib/python3.10/site-packages (from tensorflow->boston311==0.1.0) (1.14.1)\n",
            "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from tensorflow->boston311==0.1.0) (59.6.0)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /home/briarmoss/.local/lib/python3.10/site-packages (from tensorflow->boston311==0.1.0) (0.4.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /home/briarmoss/.local/lib/python3.10/site-packages (from tensorflow->boston311==0.1.0) (3.8.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /home/briarmoss/.local/lib/python3.10/site-packages (from tensorflow->boston311==0.1.0) (1.4.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /home/briarmoss/.local/lib/python3.10/site-packages (from tensorflow->boston311==0.1.0) (16.0.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /home/briarmoss/.local/lib/python3.10/site-packages (from tensorflow->boston311==0.1.0) (2.3.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/briarmoss/.local/lib/python3.10/site-packages (from tensorflow->boston311==0.1.0) (1.54.2)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/briarmoss/.local/lib/python3.10/site-packages (from tensorflow->boston311==0.1.0) (0.32.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/lib/python3/dist-packages (from tensorflow->boston311==0.1.0) (1.16.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /home/briarmoss/.local/lib/python3.10/site-packages (from tensorflow->boston311==0.1.0) (1.6.3)\n",
            "Requirement already satisfied: tensorboard<2.14,>=2.13 in /home/briarmoss/.local/lib/python3.10/site-packages (from tensorflow->boston311==0.1.0) (2.13.0)\n",
            "Requirement already satisfied: flatbuffers>=23.1.21 in /home/briarmoss/.local/lib/python3.10/site-packages (from tensorflow->boston311==0.1.0) (23.5.26)\n",
            "Requirement already satisfied: packaging in /home/briarmoss/.local/lib/python3.10/site-packages (from tensorflow->boston311==0.1.0) (23.1)\n",
            "Requirement already satisfied: keras<2.14,>=2.13.1 in /home/briarmoss/.local/lib/python3.10/site-packages (from tensorflow->boston311==0.1.0) (2.13.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /home/briarmoss/.local/lib/python3.10/site-packages (from tensorflow->boston311==0.1.0) (4.23.3)\n",
            "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in /home/briarmoss/.local/lib/python3.10/site-packages (from tensorflow->boston311==0.1.0) (4.5.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in /home/briarmoss/.local/lib/python3.10/site-packages (from tensorflow->boston311==0.1.0) (2.13.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /home/briarmoss/.local/lib/python3.10/site-packages (from tensorflow->boston311==0.1.0) (0.2.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/lib/python3/dist-packages (from astunparse>=1.6.0->tensorflow->boston311==0.1.0) (0.37.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/lib/python3/dist-packages (from tensorboard<2.14,>=2.13->tensorflow->boston311==0.1.0) (2.25.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /home/briarmoss/.local/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow->boston311==0.1.0) (2.3.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/briarmoss/.local/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow->boston311==0.1.0) (0.7.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /home/briarmoss/.local/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow->boston311==0.1.0) (1.0.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/briarmoss/.local/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow->boston311==0.1.0) (2.20.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /home/briarmoss/.local/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow->boston311==0.1.0) (3.4.3)\n",
            "Requirement already satisfied: urllib3<2.0 in /usr/lib/python3/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow->boston311==0.1.0) (1.26.5)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/briarmoss/.local/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow->boston311==0.1.0) (0.3.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/briarmoss/.local/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow->boston311==0.1.0) (5.3.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /home/briarmoss/.local/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow->boston311==0.1.0) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/briarmoss/.local/lib/python3.10/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow->boston311==0.1.0) (1.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/briarmoss/.local/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow->boston311==0.1.0) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /home/briarmoss/.local/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow->boston311==0.1.0) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/lib/python3/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow->boston311==0.1.0) (3.2.0)\n",
            "Building wheels for collected packages: boston311\n",
            "  Building wheel for boston311 (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for boston311: filename=boston311-0.1.0-py3-none-any.whl size=18836 sha256=f912ed33224f63b5d669fda420ab5b96d5fb49249db9dfafc8c379e0d93f4f38\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-nv6ymqkc/wheels/3d/69/ee/0a6ac96b9c09c948fc0e74f2724a9703aa39749a41fa757c9e\n",
            "Successfully built boston311\n",
            "Installing collected packages: boston311\n",
            "  Attempting uninstall: boston311\n",
            "    Found existing installation: boston311 0.1.0\n",
            "    Uninstalling boston311-0.1.0:\n",
            "      Successfully uninstalled boston311-0.1.0\n",
            "Successfully installed boston311-0.1.0\n"
          ]
        }
      ],
      "source": [
        "! pip install ../"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XP7Hzen_iEAl"
      },
      "source": [
        "##Import the Boston311Model class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "LdhJESm7eWaY"
      },
      "outputs": [],
      "source": [
        "from boston311 import Boston311LogReg, Boston311EventDecTree, Boston311SurvDecTree, Boston311KerasNLP\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oq06XnVjPxvg"
      },
      "source": [
        "## Get latest file URLS and Current Date Ranges"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "_2FYkUb2P1LR"
      },
      "outputs": [],
      "source": [
        "latest_URLS = Boston311LogReg.get311URLs()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mpg9Czm3QDpu",
        "outputId": "5e2b399b-0999-45d4-f9f9-d80ec19941ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'2023': 'https://data.boston.gov/dataset/8048697b-ad64-4bfc-b090-ee00169f2323/resource/e6013a93-1321-4f2a-bf91-8d8a02f1e62f/download/tmp518q5snq.csv', '2022': 'https://data.boston.gov/dataset/8048697b-ad64-4bfc-b090-ee00169f2323/resource/81a7b022-f8fc-4da5-80e4-b160058ca207/download/tmpfm8veglw.csv', '2021': 'https://data.boston.gov/dataset/8048697b-ad64-4bfc-b090-ee00169f2323/resource/f53ebccd-bc61-49f9-83db-625f209c95f5/download/tmp88p9g82n.csv', '2020': 'https://data.boston.gov/dataset/8048697b-ad64-4bfc-b090-ee00169f2323/resource/6ff6a6fd-3141-4440-a880-6f60a37fe789/download/tmpcv_10m2s.csv', '2019': 'https://data.boston.gov/dataset/8048697b-ad64-4bfc-b090-ee00169f2323/resource/ea2e4696-4a2d-429c-9807-d02eb92e0222/download/tmpcje3ep_w.csv', '2018': 'https://data.boston.gov/dataset/8048697b-ad64-4bfc-b090-ee00169f2323/resource/2be28d90-3a90-4af1-a3f6-f28c1e25880a/download/tmp7602cia8.csv', '2017': 'https://data.boston.gov/dataset/8048697b-ad64-4bfc-b090-ee00169f2323/resource/30022137-709d-465e-baae-ca155b51927d/download/tmpzccn8u4q.csv', '2016': 'https://data.boston.gov/dataset/8048697b-ad64-4bfc-b090-ee00169f2323/resource/b7ea6b1b-3ca4-4c5b-9713-6dc1db52379a/download/tmpzxzxeqfb.csv', '2015': 'https://data.boston.gov/dataset/8048697b-ad64-4bfc-b090-ee00169f2323/resource/c9509ab4-6f6d-4b97-979a-0cf2a10c922b/download/tmphrybkxuh.csv', '2014': 'https://data.boston.gov/dataset/8048697b-ad64-4bfc-b090-ee00169f2323/resource/bdae89c8-d4ce-40e9-a6e1-a5203953a2e0/download/tmp8afxvko_.csv', '2013': 'https://data.boston.gov/dataset/8048697b-ad64-4bfc-b090-ee00169f2323/resource/407c5cd0-f764-4a41-adf8-054ff535049e/download/tmpyzk_wmya.csv', '2012': 'https://data.boston.gov/dataset/8048697b-ad64-4bfc-b090-ee00169f2323/resource/382e10d9-1864-40ba-bef6-4eea3c75463c/download/tmpeyvgdt5u.csv', '2011': 'https://data.boston.gov/dataset/8048697b-ad64-4bfc-b090-ee00169f2323/resource/94b499d9-712a-4d2a-b790-7ceec5c9c4b1/download/tmp_9ogynu0.csv'}\n"
          ]
        }
      ],
      "source": [
        "print(latest_URLS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uUMCPAELR9h7",
        "outputId": "05fcba64-1b74-4fb7-a52c-d3f8a499bcc6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-10-03 2023-09-03 2023-10-04\n"
          ]
        }
      ],
      "source": [
        "from datetime import datetime, timedelta\n",
        "now = datetime.now()\n",
        "thirty_days = timedelta(days=30)\n",
        "thirty_days_ago = now - thirty_days\n",
        "today_datestring = now.strftime(\"%Y-%m-%d\")\n",
        "thirty_days_ago_datestring = thirty_days_ago.strftime(\"%Y-%m-%d\")\n",
        "tomorrow_datestring = (datetime.today() + timedelta(days=1)).strftime('%Y-%m-%d')\n",
        "\n",
        "print(today_datestring, thirty_days_ago_datestring, tomorrow_datestring)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [],
      "source": [
        "#set model folder constant\n",
        "MODEL_FOLDER = './daily_models'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load extra features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [],
      "source": [
        "#set path to mydata\n",
        "EXTRA_mydata_FILE = './cls_and_pooled_embeddings_with_service_id_2023.csv'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NN_UiAIvb9MT"
      },
      "source": [
        "##Define several models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "nmi4jJgDF4Fv"
      },
      "outputs": [],
      "source": [
        "linear_tree_model = Boston311SurvDecTree(train_date_range={'start':'2022-01-01','end':thirty_days_ago_datestring},\n",
        "                            predict_date_range={'start':thirty_days_ago_datestring,'end':today_datestring},\n",
        "                            feature_columns=['type','queue'],\n",
        "                            scenario={'dropColumnValues': {'source':['City Worker App', 'Employee Generated']},\n",
        "                                      'survivalTimeMin':0,\n",
        "                                      'survivalTimeFill':tomorrow_datestring},\n",
        "                            files_dict=latest_URLS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "GGSlYgH6s54c"
      },
      "outputs": [],
      "source": [
        "logistic_model = Boston311LogReg(train_date_range={'start':'2022-01-01','end':thirty_days_ago_datestring},\n",
        "                            predict_date_range={'start':thirty_days_ago_datestring,'end':today_datestring},\n",
        "                            feature_columns=['type', 'queue'],\n",
        "                            scenario={'dropColumnValues': {'source':['City Worker App', 'Employee Generated']},\n",
        "                                      'survivalTimeMin':0},\n",
        "                            files_dict=latest_URLS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [],
      "source": [
        "oldlogistic_model = Boston311LogReg(train_date_range={'start':'2022-01-01','end':thirty_days_ago_datestring},\n",
        "                            predict_date_range={'start':thirty_days_ago_datestring,'end':today_datestring},\n",
        "                            feature_columns=['type', 'queue'],\n",
        "                            scenario={'dropColumnValues': {'source':['City Worker App', 'Employee Generated']},\n",
        "                                      'survivalTimeMin':0},\n",
        "                            files_dict=latest_URLS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "_Ddtw6t8s5rj"
      },
      "outputs": [],
      "source": [
        "logistic_tree_model = Boston311EventDecTree(train_date_range={'start':'2022-01-01','end':thirty_days_ago_datestring},\n",
        "                            predict_date_range={'start':thirty_days_ago_datestring,'end':today_datestring},\n",
        "                            feature_columns=['type', 'queue'],\n",
        "                            scenario={'dropColumnValues': {'source':['City Worker App', 'Employee Generated']},\n",
        "                                      'survivalTimeMin':0},\n",
        "                            files_dict=latest_URLS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [],
      "source": [
        "kerasNLP_model = Boston311KerasNLP(train_date_range={'start':'2022-03-01','end':thirty_days_ago_datestring},\n",
        "                            predict_date_range={'start':thirty_days_ago_datestring,'end':today_datestring},\n",
        "                            feature_columns=['type', 'queue', 'source', 'subject', 'reason', 'department', 'ward_number'],\n",
        "                            scenario={'dropColumnValues': {'source':['City Worker App', 'Employee Generated']},\n",
        "                                      'survivalTimeMin':0,\n",
        "                                      'survivalTimeFill':tomorrow_datestring},\n",
        "                            files_dict=latest_URLS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [],
      "source": [
        "#get current datetime in Boston timezone as string\n",
        "from datetime import datetime\n",
        "from pytz import timezone\n",
        "import pytz\n",
        "boston = timezone('US/Eastern')\n",
        "now = datetime.now(boston)\n",
        "today_datestring = now.strftime(\"%Y-%m-%d\")\n",
        "#get time in Boston timezone as string for a filename\n",
        "now = datetime.now(boston)\n",
        "time_string = now.strftime(\"%H-%M-%S\")\n",
        "#define datetime string\n",
        "my_datetime = today_datestring + '_' + time_string "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/briarmoss/.local/lib/python3.10/site-packages/boston311/Boston311Model.py:262: DtypeWarning: Columns (13) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(file)\n",
            "/home/briarmoss/.local/lib/python3.10/site-packages/boston311/Boston311Model.py:262: DtypeWarning: Columns (13) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(file)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files with different number of columns from File 0:  []\n",
            "Files with same number of columns as File 0:  [0, 1]\n",
            "Files with different column order from File 0:  []\n",
            "Files with same column order as File 0:  [0, 1]\n"
          ]
        }
      ],
      "source": [
        "mydata = None\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "\n",
        "case_data_file = 'case_data.pkl'\n",
        "mydata = None\n",
        "\n",
        "X = None\n",
        "\n",
        "if os.path.exists(case_data_file):\n",
        "    mydata = pickle.load(open(case_data_file, \"rb\"))\n",
        "else:\n",
        "    mydata = kerasNLP_model.load_data()\n",
        "\n",
        "    pickle.dump(mydata, open(case_data_file, \"wb\"))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "43677     101004204966\n",
              "43678     101004204967\n",
              "43679     101004204970\n",
              "43680     101004204968\n",
              "43681     101004204972\n",
              "              ...     \n",
              "489419    101005031811\n",
              "489420    101005031812\n",
              "489421    101005031813\n",
              "489422    101005031814\n",
              "489423    101005031815\n",
              "Name: case_enquiry_id, Length: 445747, dtype: int64"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mydata['case_enquiry_id']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [],
      "source": [
        "mydata = kerasNLP_model.enhance_data(mydata)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [],
      "source": [
        "mydata = kerasNLP_model.apply_scenario(mydata)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "mydata = kerasNLP_model.clean_data(mydata)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "43677     101004204966\n",
            "43678     101004204967\n",
            "43679     101004204970\n",
            "43680     101004204968\n",
            "43681     101004204972\n",
            "              ...     \n",
            "489405    101005031796\n",
            "489407    101005031798\n",
            "489417    101005031808\n",
            "489418    101005031810\n",
            "489420    101005031812\n",
            "Name: case_enquiry_id, Length: 392488, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(mydata['case_enquiry_id'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_663778/2198591999.py:13: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  X = pd.read_csv(EXTRA_mydata_FILE)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from ast import literal_eval\n",
        "import pickle\n",
        "\n",
        "pickle_file = 'dataframe.pkl'\n",
        "\n",
        "X = None\n",
        "\n",
        "if os.path.exists(pickle_file):\n",
        "    X = pickle.load(open(pickle_file, \"rb\"))\n",
        "else:\n",
        "    X = pd.read_csv(EXTRA_mydata_FILE)\n",
        "\n",
        "    #rename service_request_id to case_enquiry_id\n",
        "    X.rename(columns={'service_request_id':'case_enquiry_id'}, inplace=True)\n",
        "    #remove all rows where case_enquiry_id is non-numeric\n",
        "    #X = X[X['case_enquiry_id'].str.isnumeric()]\n",
        "    #convert case_enquiry_id to int64\n",
        "    #X['case_enquiry_id'] = X['case_enquiry_id'].astype('int64')\n",
        "\n",
        "    # Convert stringified arrays back to NumPy arrays\n",
        "    X['cls_embedding'] = X['cls_embedding'].apply(literal_eval).apply(np.array)\n",
        "    X['pooled_embedding'] = X['pooled_embedding'].apply(literal_eval).apply(np.array)\n",
        "\n",
        "    pickle.dump(X, open(pickle_file, \"wb\"))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [],
      "source": [
        "#load second file form pickle or from csv\n",
        "pickle_file2022 = 'dataframe2.pkl'\n",
        "EXTRA_mydata_FILE_2022 = './cls_and_pooled_embeddings_with_service_id_2022.csv'\n",
        "\n",
        "X2022 = None\n",
        "\n",
        "if os.path.exists(pickle_file2022):\n",
        "    X2022 = pickle.load(open(pickle_file2022, \"rb\"))\n",
        "else:\n",
        "    X2022 = pd.read_csv(EXTRA_mydata_FILE_2022)\n",
        "\n",
        "    #rename service_request_id to case_enquiry_id\n",
        "    X2022.rename(columns={'service_request_id':'case_enquiry_id'}, inplace=True)\n",
        "    #remove all rows where case_enquiry_id is non-numeric\n",
        "    #X2022 = X2022[X2022['case_enquiry_id'].str.isnumeric()]\n",
        "    #convert case_enquiry_id to int64\n",
        "    #X2022['case_enquiry_id'] = X2022['case_enquiry_id'].astype('int64')\n",
        "\n",
        "    # Convert stringified arrays back to NumPy arrays\n",
        "    X2022['cls_embedding'] = X2022['cls_embedding'].apply(literal_eval).apply(np.array)\n",
        "    X2022['pooled_embedding'] = X2022['pooled_embedding'].apply(literal_eval).apply(np.array)\n",
        "\n",
        "    pickle.dump(X2022, open(pickle_file2022, \"wb\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 275503 entries, 0 to 275502\n",
            "Data columns (total 3 columns):\n",
            " #   Column            Non-Null Count   Dtype \n",
            "---  ------            --------------   ----- \n",
            " 0   case_enquiry_id   275503 non-null  object\n",
            " 1   cls_embedding     275503 non-null  object\n",
            " 2   pooled_embedding  275503 non-null  object\n",
            "dtypes: object(3)\n",
            "memory usage: 6.3+ MB\n",
            "None\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 305359 entries, 0 to 305358\n",
            "Data columns (total 3 columns):\n",
            " #   Column            Non-Null Count   Dtype \n",
            "---  ------            --------------   ----- \n",
            " 0   case_enquiry_id   305359 non-null  int64 \n",
            " 1   cls_embedding     305359 non-null  object\n",
            " 2   pooled_embedding  305359 non-null  object\n",
            "dtypes: int64(1), object(2)\n",
            "memory usage: 7.0+ MB\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "#print information about X2022\n",
        "print(X.info())\n",
        "print(X2022.info())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [],
      "source": [
        "#concatenate the two dataframes and reindex\n",
        "df = pd.concat([X, X2022], ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(580862, 3)"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Assuming df is your DataFrame and it has columns 'cls_embedding' and 'pooled_embedding'\n",
        "cls_embedding_flattened = np.stack(df['cls_embedding'].to_numpy())\n",
        "pooled_embedding_flattened = np.stack(df['pooled_embedding'].to_numpy())\n",
        "\n",
        "# Remove the old columns\n",
        "df.drop(['cls_embedding', 'pooled_embedding'], axis=1, inplace=True)\n",
        "\n",
        "# Add the new flattened columns\n",
        "df_cls = pd.DataFrame(cls_embedding_flattened, columns=[f'cls_{i}' for i in range(cls_embedding_flattened.shape[1])])\n",
        "df_pooled = pd.DataFrame(pooled_embedding_flattened, columns=[f'pooled_{i}' for i in range(pooled_embedding_flattened.shape[1])])\n",
        "\n",
        "df = pd.concat([df, df_cls, df_pooled], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [],
      "source": [
        "df['case_enquiry_id'] = df['case_enquiry_id'].astype(str)\n",
        "is_numeric = df['case_enquiry_id'].str.isnumeric()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = df[is_numeric]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [],
      "source": [
        "df['case_enquiry_id'] = df['case_enquiry_id'].astype('int64')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(580861, 257)"
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = df.drop_duplicates(subset=['case_enquiry_id']) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(235842, 257)"
            ]
          },
          "execution_count": 71,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(392488, 438)"
            ]
          },
          "execution_count": 72,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mydata.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [],
      "source": [
        "mydata = mydata.drop_duplicates(subset=['case_enquiry_id'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(392488, 438)"
            ]
          },
          "execution_count": 74,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mydata.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {},
      "outputs": [],
      "source": [
        "#join them so we are left only with records that have mydata in both files\n",
        "new_mydata = mydata.merge(df, on='case_enquiry_id', how='inner')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(143205, 694)"
            ]
          },
          "execution_count": 76,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "new_mydata.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "df, y = kerasNLP_model.split_data(new_mydata)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {},
      "outputs": [],
      "source": [
        "#cast all columns that are type bool to float\n",
        "for col in df.columns:\n",
        "    if df[col].dtype == 'bool':\n",
        "        df[col] = df[col].astype('float64')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(143205, 691)\n",
            "(143205,)\n"
          ]
        }
      ],
      "source": [
        "#list the number of rows in X and y\n",
        "print(df.shape)\n",
        "print(y.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {},
      "outputs": [],
      "source": [
        "#best_model, best_hyperparameters = kerasNLP_model.tune_model(df, y, '/home/briarmoss/Documents/Boston_311/models/tuning')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {},
      "outputs": [],
      "source": [
        "#define hyperparameters\n",
        "from kerastuner import HyperParameters\n",
        "\n",
        "#set constants\n",
        "start_nodes = 128\n",
        "end_nodes = 64\n",
        "#l2_0 = 0.00001\n",
        "#learning_rate = 7.5842e-05\n",
        "l2_0 = 0.001\n",
        "learning_rate = 0.0001\n",
        "\n",
        "\n",
        "hp = HyperParameters()\n",
        "hp.Fixed('start_nodes', start_nodes)\n",
        "hp.Fixed('end_nodes', end_nodes)\n",
        "hp.Fixed('l2_0', l2_0)\n",
        "hp.Fixed('learning_rate', learning_rate)\n",
        "\n",
        "kerasNLP_model.best_hyperparameters = hp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {},
      "outputs": [],
      "source": [
        "#free all unused dataframes\n",
        "df_to_delete = [cls_embedding_flattened, pooled_embedding_flattened, df_cls, df_pooled, X, X2022, new_mydata, is_numeric, mydata]\n",
        "\n",
        "for data_frame in df_to_delete:\n",
        "    del data_frame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting Training at 2023-10-03 03:05:44.713034\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 128)               88576     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 9)                 585       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 97417 (380.54 KB)\n",
            "Trainable params: 97417 (380.54 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n",
            "<class 'pandas.core.frame.DataFrame'> (114564, 9)\n",
            "<class 'pandas.core.frame.DataFrame'> (28641, 9)\n",
            "run fit\n",
            "\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-10-03 03:05:45.903434: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 633309792 exceeds 10% of free system memory.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3581/3581 [==============================] - 6s 1ms/step - loss: 1.5094 - accuracy: 0.5381 - top_k_categorical_accuracy: 0.7113 - val_loss: 1.3759 - val_accuracy: 0.5632 - val_top_k_categorical_accuracy: 0.7417\n",
            "Epoch 2/100\n",
            "3581/3581 [==============================] - 5s 1ms/step - loss: 1.3506 - accuracy: 0.5657 - top_k_categorical_accuracy: 0.7473 - val_loss: 1.3286 - val_accuracy: 0.5687 - val_top_k_categorical_accuracy: 0.7496\n",
            "Epoch 3/100\n",
            "3581/3581 [==============================] - 5s 1ms/step - loss: 1.3162 - accuracy: 0.5701 - top_k_categorical_accuracy: 0.7547 - val_loss: 1.3069 - val_accuracy: 0.5712 - val_top_k_categorical_accuracy: 0.7536\n",
            "Epoch 4/100\n",
            "3581/3581 [==============================] - 5s 1ms/step - loss: 1.2965 - accuracy: 0.5725 - top_k_categorical_accuracy: 0.7569 - val_loss: 1.2891 - val_accuracy: 0.5732 - val_top_k_categorical_accuracy: 0.7558\n",
            "Epoch 5/100\n",
            "3581/3581 [==============================] - 5s 2ms/step - loss: 1.2822 - accuracy: 0.5737 - top_k_categorical_accuracy: 0.7588 - val_loss: 1.2856 - val_accuracy: 0.5713 - val_top_k_categorical_accuracy: 0.7538\n",
            "Epoch 6/100\n",
            "3581/3581 [==============================] - 5s 1ms/step - loss: 1.2711 - accuracy: 0.5733 - top_k_categorical_accuracy: 0.7605 - val_loss: 1.2751 - val_accuracy: 0.5715 - val_top_k_categorical_accuracy: 0.7546\n",
            "Epoch 7/100\n",
            "3581/3581 [==============================] - 5s 1ms/step - loss: 1.2617 - accuracy: 0.5751 - top_k_categorical_accuracy: 0.7613 - val_loss: 1.2586 - val_accuracy: 0.5750 - val_top_k_categorical_accuracy: 0.7602\n",
            "Epoch 8/100\n",
            "3581/3581 [==============================] - 5s 1ms/step - loss: 1.2546 - accuracy: 0.5748 - top_k_categorical_accuracy: 0.7622 - val_loss: 1.2546 - val_accuracy: 0.5748 - val_top_k_categorical_accuracy: 0.7603\n",
            "Epoch 9/100\n",
            "3581/3581 [==============================] - 5s 1ms/step - loss: 1.2481 - accuracy: 0.5747 - top_k_categorical_accuracy: 0.7628 - val_loss: 1.2671 - val_accuracy: 0.5746 - val_top_k_categorical_accuracy: 0.7602\n",
            "Epoch 10/100\n",
            "3581/3581 [==============================] - 5s 1ms/step - loss: 1.2410 - accuracy: 0.5762 - top_k_categorical_accuracy: 0.7642 - val_loss: 1.2443 - val_accuracy: 0.5762 - val_top_k_categorical_accuracy: 0.7594\n",
            "Epoch 11/100\n",
            "3581/3581 [==============================] - 5s 1ms/step - loss: 1.2357 - accuracy: 0.5760 - top_k_categorical_accuracy: 0.7643 - val_loss: 1.2379 - val_accuracy: 0.5752 - val_top_k_categorical_accuracy: 0.7589\n",
            "Epoch 12/100\n",
            "3581/3581 [==============================] - 5s 1ms/step - loss: 1.2318 - accuracy: 0.5763 - top_k_categorical_accuracy: 0.7637 - val_loss: 1.2350 - val_accuracy: 0.5759 - val_top_k_categorical_accuracy: 0.7622\n",
            "Epoch 13/100\n",
            "3581/3581 [==============================] - 5s 1ms/step - loss: 1.2275 - accuracy: 0.5764 - top_k_categorical_accuracy: 0.7647 - val_loss: 1.2347 - val_accuracy: 0.5751 - val_top_k_categorical_accuracy: 0.7614\n",
            "Epoch 14/100\n",
            "3581/3581 [==============================] - 5s 2ms/step - loss: 1.2235 - accuracy: 0.5764 - top_k_categorical_accuracy: 0.7653 - val_loss: 1.2281 - val_accuracy: 0.5771 - val_top_k_categorical_accuracy: 0.7620\n",
            "Epoch 15/100\n",
            "3581/3581 [==============================] - 5s 1ms/step - loss: 1.2195 - accuracy: 0.5772 - top_k_categorical_accuracy: 0.7663 - val_loss: 1.2302 - val_accuracy: 0.5759 - val_top_k_categorical_accuracy: 0.7607\n",
            "Epoch 16/100\n",
            "3581/3581 [==============================] - 5s 1ms/step - loss: 1.2171 - accuracy: 0.5780 - top_k_categorical_accuracy: 0.7659 - val_loss: 1.2363 - val_accuracy: 0.5732 - val_top_k_categorical_accuracy: 0.7563\n",
            "Epoch 17/100\n",
            "3581/3581 [==============================] - 5s 1ms/step - loss: 1.2138 - accuracy: 0.5783 - top_k_categorical_accuracy: 0.7667 - val_loss: 1.2354 - val_accuracy: 0.5734 - val_top_k_categorical_accuracy: 0.7564\n",
            "Epoch 18/100\n",
            "3581/3581 [==============================] - 5s 2ms/step - loss: 1.2111 - accuracy: 0.5780 - top_k_categorical_accuracy: 0.7664 - val_loss: 1.2181 - val_accuracy: 0.5767 - val_top_k_categorical_accuracy: 0.7618\n",
            "Epoch 19/100\n",
            "3581/3581 [==============================] - 5s 1ms/step - loss: 1.2093 - accuracy: 0.5780 - top_k_categorical_accuracy: 0.7671 - val_loss: 1.2188 - val_accuracy: 0.5790 - val_top_k_categorical_accuracy: 0.7632\n",
            "Epoch 20/100\n",
            "3581/3581 [==============================] - 5s 2ms/step - loss: 1.2063 - accuracy: 0.5780 - top_k_categorical_accuracy: 0.7668 - val_loss: 1.2182 - val_accuracy: 0.5762 - val_top_k_categorical_accuracy: 0.7603\n",
            "Epoch 21/100\n",
            "3581/3581 [==============================] - 5s 1ms/step - loss: 1.2042 - accuracy: 0.5784 - top_k_categorical_accuracy: 0.7669 - val_loss: 1.2243 - val_accuracy: 0.5735 - val_top_k_categorical_accuracy: 0.7595\n",
            "Epoch 22/100\n",
            "3581/3581 [==============================] - 5s 1ms/step - loss: 1.2018 - accuracy: 0.5793 - top_k_categorical_accuracy: 0.7683 - val_loss: 1.2086 - val_accuracy: 0.5786 - val_top_k_categorical_accuracy: 0.7638\n",
            "Epoch 23/100\n",
            "3581/3581 [==============================] - 5s 1ms/step - loss: 1.2002 - accuracy: 0.5792 - top_k_categorical_accuracy: 0.7687 - val_loss: 1.2122 - val_accuracy: 0.5774 - val_top_k_categorical_accuracy: 0.7617\n",
            "Epoch 24/100\n",
            "3581/3581 [==============================] - 5s 2ms/step - loss: 1.1977 - accuracy: 0.5792 - top_k_categorical_accuracy: 0.7689 - val_loss: 1.2165 - val_accuracy: 0.5734 - val_top_k_categorical_accuracy: 0.7602\n",
            "Epoch 25/100\n",
            "3581/3581 [==============================] - 5s 2ms/step - loss: 1.1960 - accuracy: 0.5792 - top_k_categorical_accuracy: 0.7694 - val_loss: 1.2114 - val_accuracy: 0.5751 - val_top_k_categorical_accuracy: 0.7622\n",
            "Epoch 26/100\n",
            "3581/3581 [==============================] - 5s 2ms/step - loss: 1.1945 - accuracy: 0.5794 - top_k_categorical_accuracy: 0.7695 - val_loss: 1.2196 - val_accuracy: 0.5754 - val_top_k_categorical_accuracy: 0.7618\n",
            "Epoch 27/100\n",
            "3581/3581 [==============================] - 5s 1ms/step - loss: 1.1927 - accuracy: 0.5793 - top_k_categorical_accuracy: 0.7700 - val_loss: 1.2064 - val_accuracy: 0.5782 - val_top_k_categorical_accuracy: 0.7625\n",
            "Epoch 28/100\n",
            "3581/3581 [==============================] - 5s 1ms/step - loss: 1.1917 - accuracy: 0.5798 - top_k_categorical_accuracy: 0.7692 - val_loss: 1.2031 - val_accuracy: 0.5771 - val_top_k_categorical_accuracy: 0.7635\n",
            "Epoch 29/100\n",
            "3581/3581 [==============================] - 5s 1ms/step - loss: 1.1903 - accuracy: 0.5799 - top_k_categorical_accuracy: 0.7695 - val_loss: 1.2033 - val_accuracy: 0.5761 - val_top_k_categorical_accuracy: 0.7629\n",
            "Epoch 30/100\n",
            "3581/3581 [==============================] - 5s 2ms/step - loss: 1.1890 - accuracy: 0.5799 - top_k_categorical_accuracy: 0.7695 - val_loss: 1.2013 - val_accuracy: 0.5772 - val_top_k_categorical_accuracy: 0.7628\n",
            "Epoch 31/100\n",
            "3581/3581 [==============================] - 5s 1ms/step - loss: 1.1873 - accuracy: 0.5807 - top_k_categorical_accuracy: 0.7702 - val_loss: 1.2110 - val_accuracy: 0.5733 - val_top_k_categorical_accuracy: 0.7622\n",
            "Epoch 32/100\n",
            "3581/3581 [==============================] - 5s 1ms/step - loss: 1.1863 - accuracy: 0.5803 - top_k_categorical_accuracy: 0.7700 - val_loss: 1.2003 - val_accuracy: 0.5780 - val_top_k_categorical_accuracy: 0.7617\n",
            "Epoch 33/100\n",
            "3581/3581 [==============================] - 5s 1ms/step - loss: 1.1847 - accuracy: 0.5805 - top_k_categorical_accuracy: 0.7698 - val_loss: 1.1985 - val_accuracy: 0.5775 - val_top_k_categorical_accuracy: 0.7653\n",
            "Epoch 34/100\n",
            "3581/3581 [==============================] - 5s 2ms/step - loss: 1.1842 - accuracy: 0.5795 - top_k_categorical_accuracy: 0.7709 - val_loss: 1.2010 - val_accuracy: 0.5768 - val_top_k_categorical_accuracy: 0.7625\n",
            "Epoch 35/100\n",
            "3581/3581 [==============================] - 5s 1ms/step - loss: 1.1830 - accuracy: 0.5805 - top_k_categorical_accuracy: 0.7719 - val_loss: 1.1981 - val_accuracy: 0.5768 - val_top_k_categorical_accuracy: 0.7618\n",
            "Epoch 36/100\n",
            "3581/3581 [==============================] - 5s 1ms/step - loss: 1.1816 - accuracy: 0.5804 - top_k_categorical_accuracy: 0.7707 - val_loss: 1.1966 - val_accuracy: 0.5786 - val_top_k_categorical_accuracy: 0.7649\n",
            "Epoch 37/100\n",
            "3581/3581 [==============================] - 5s 1ms/step - loss: 1.1798 - accuracy: 0.5810 - top_k_categorical_accuracy: 0.7716 - val_loss: 1.1941 - val_accuracy: 0.5781 - val_top_k_categorical_accuracy: 0.7639\n",
            "Epoch 38/100\n",
            "3581/3581 [==============================] - 5s 1ms/step - loss: 1.1796 - accuracy: 0.5814 - top_k_categorical_accuracy: 0.7725 - val_loss: 1.1975 - val_accuracy: 0.5774 - val_top_k_categorical_accuracy: 0.7637\n",
            "Epoch 39/100\n",
            "3581/3581 [==============================] - 5s 2ms/step - loss: 1.1781 - accuracy: 0.5816 - top_k_categorical_accuracy: 0.7725 - val_loss: 1.1999 - val_accuracy: 0.5773 - val_top_k_categorical_accuracy: 0.7621\n",
            "Epoch 40/100\n",
            "3581/3581 [==============================] - 5s 2ms/step - loss: 1.1768 - accuracy: 0.5821 - top_k_categorical_accuracy: 0.7726 - val_loss: 1.2050 - val_accuracy: 0.5748 - val_top_k_categorical_accuracy: 0.7619\n",
            "Epoch 41/100\n",
            "3581/3581 [==============================] - 5s 1ms/step - loss: 1.1763 - accuracy: 0.5817 - top_k_categorical_accuracy: 0.7727 - val_loss: 1.2026 - val_accuracy: 0.5764 - val_top_k_categorical_accuracy: 0.7642\n",
            "Epoch 42/100\n",
            "3581/3581 [==============================] - 5s 2ms/step - loss: 1.1750 - accuracy: 0.5815 - top_k_categorical_accuracy: 0.7719 - val_loss: 1.1929 - val_accuracy: 0.5784 - val_top_k_categorical_accuracy: 0.7648\n",
            "Epoch 43/100\n",
            "3581/3581 [==============================] - 5s 1ms/step - loss: 1.1748 - accuracy: 0.5819 - top_k_categorical_accuracy: 0.7729 - val_loss: 1.1931 - val_accuracy: 0.5790 - val_top_k_categorical_accuracy: 0.7647\n",
            "Epoch 44/100\n",
            "3581/3581 [==============================] - 5s 1ms/step - loss: 1.1738 - accuracy: 0.5825 - top_k_categorical_accuracy: 0.7729 - val_loss: 1.2059 - val_accuracy: 0.5744 - val_top_k_categorical_accuracy: 0.7609\n",
            "Epoch 45/100\n",
            "3581/3581 [==============================] - 5s 1ms/step - loss: 1.1723 - accuracy: 0.5822 - top_k_categorical_accuracy: 0.7742 - val_loss: 1.1895 - val_accuracy: 0.5804 - val_top_k_categorical_accuracy: 0.7653\n",
            "Epoch 46/100\n",
            "3581/3581 [==============================] - 5s 1ms/step - loss: 1.1717 - accuracy: 0.5828 - top_k_categorical_accuracy: 0.7730 - val_loss: 1.2021 - val_accuracy: 0.5762 - val_top_k_categorical_accuracy: 0.7602\n",
            "Epoch 47/100\n",
            "3581/3581 [==============================] - 5s 2ms/step - loss: 1.1712 - accuracy: 0.5828 - top_k_categorical_accuracy: 0.7741 - val_loss: 1.2154 - val_accuracy: 0.5738 - val_top_k_categorical_accuracy: 0.7595\n",
            "Epoch 48/100\n",
            "3581/3581 [==============================] - 5s 1ms/step - loss: 1.1705 - accuracy: 0.5828 - top_k_categorical_accuracy: 0.7737 - val_loss: 1.1909 - val_accuracy: 0.5801 - val_top_k_categorical_accuracy: 0.7661\n",
            "Epoch 49/100\n",
            "3581/3581 [==============================] - 5s 1ms/step - loss: 1.1702 - accuracy: 0.5831 - top_k_categorical_accuracy: 0.7734 - val_loss: 1.1890 - val_accuracy: 0.5794 - val_top_k_categorical_accuracy: 0.7642\n",
            "Epoch 50/100\n",
            "3581/3581 [==============================] - 5s 1ms/step - loss: 1.1693 - accuracy: 0.5828 - top_k_categorical_accuracy: 0.7737 - val_loss: 1.1930 - val_accuracy: 0.5778 - val_top_k_categorical_accuracy: 0.7644\n",
            "Epoch 51/100\n",
            "3581/3581 [==============================] - 5s 2ms/step - loss: 1.1682 - accuracy: 0.5829 - top_k_categorical_accuracy: 0.7741 - val_loss: 1.1965 - val_accuracy: 0.5779 - val_top_k_categorical_accuracy: 0.7650\n",
            "Epoch 52/100\n",
            "3581/3581 [==============================] - 5s 1ms/step - loss: 1.1677 - accuracy: 0.5828 - top_k_categorical_accuracy: 0.7744 - val_loss: 1.2017 - val_accuracy: 0.5784 - val_top_k_categorical_accuracy: 0.7639\n",
            "Epoch 53/100\n",
            "3581/3581 [==============================] - 5s 1ms/step - loss: 1.1662 - accuracy: 0.5838 - top_k_categorical_accuracy: 0.7753 - val_loss: 1.1897 - val_accuracy: 0.5783 - val_top_k_categorical_accuracy: 0.7636\n",
            "Epoch 54/100\n",
            "3581/3581 [==============================] - 5s 1ms/step - loss: 1.1662 - accuracy: 0.5838 - top_k_categorical_accuracy: 0.7756 - val_loss: 1.1908 - val_accuracy: 0.5794 - val_top_k_categorical_accuracy: 0.7640\n",
            "Epoch 55/100\n",
            "3581/3581 [==============================] - 5s 1ms/step - loss: 1.1660 - accuracy: 0.5836 - top_k_categorical_accuracy: 0.7748 - val_loss: 1.1993 - val_accuracy: 0.5763 - val_top_k_categorical_accuracy: 0.7613\n",
            "Epoch 56/100\n",
            "3581/3581 [==============================] - 5s 1ms/step - loss: 1.1649 - accuracy: 0.5840 - top_k_categorical_accuracy: 0.7757 - val_loss: 1.1922 - val_accuracy: 0.5784 - val_top_k_categorical_accuracy: 0.7654\n",
            "Epoch 57/100\n",
            "3581/3581 [==============================] - 5s 1ms/step - loss: 1.1642 - accuracy: 0.5840 - top_k_categorical_accuracy: 0.7751 - val_loss: 1.2000 - val_accuracy: 0.5790 - val_top_k_categorical_accuracy: 0.7629\n",
            "Epoch 58/100\n",
            "3581/3581 [==============================] - 5s 1ms/step - loss: 1.1640 - accuracy: 0.5844 - top_k_categorical_accuracy: 0.7755 - val_loss: 1.2075 - val_accuracy: 0.5719 - val_top_k_categorical_accuracy: 0.7579\n",
            "Epoch 59/100\n",
            "3581/3581 [==============================] - 5s 2ms/step - loss: 1.1632 - accuracy: 0.5842 - top_k_categorical_accuracy: 0.7751 - val_loss: 1.1925 - val_accuracy: 0.5772 - val_top_k_categorical_accuracy: 0.7622\n",
            "896/896 [==============================] - 1s 576us/step - loss: 1.1890 - accuracy: 0.5794 - top_k_categorical_accuracy: 0.7642\n",
            "Testing accuracy: 0.5793792009353638 \n",
            "Top-2 accuracy: 0.7641842365264893 \n",
            "Test loss: 1.1890246868133545\n",
            "Ending Training at 2023-10-03 03:10:59.019105\n",
            "Training took 0:05:14.306071\n"
          ]
        }
      ],
      "source": [
        "\n",
        "#parse CLS embedding column as array\n",
        "test_acc = kerasNLP_model.train_model( df, y )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sSSkyth-2K3A"
      },
      "source": [
        "## Train several models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "learning is fun!\n"
          ]
        }
      ],
      "source": [
        "print(\"learning is fun!\") "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lv4ivBuvinss",
        "outputId": "814ef4fb-e100-4b22-ccbc-6b9d91e5a341"
      },
      "outputs": [],
      "source": [
        "#logistic_tree_model.run_pipeline()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_UIaks6jjPkU",
        "outputId": "0e365ed1-472e-4cb1-cdde-ae0a2d32722e"
      },
      "outputs": [],
      "source": [
        "#logistic_model.run_pipeline()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2730"
            ]
          },
          "execution_count": 87,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import gc\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {},
      "outputs": [],
      "source": [
        "#linear_tree_model.run_pipeline()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/briarmoss/.local/lib/python3.10/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ],
      "source": [
        "import datetime\n",
        "\n",
        "def save_model_to_dir(model, folder_name):\n",
        "    dir_path = os.path.join(MODEL_FOLDER, folder_name)\n",
        "    \n",
        "    if not os.path.exists(dir_path):\n",
        "        os.mkdir(dir_path)\n",
        "    \n",
        "    timestamp = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "    model_name = timestamp + \"_\" + model.model_type\n",
        "    properties_name = model_name\n",
        "    \n",
        "    model.save(dir_path, model_name, properties_name)\n",
        "\n",
        "# List of models\n",
        "models = [kerasNLP_model]\n",
        "\n",
        "\n",
        "# Iterate over models and save\n",
        "for model in models:\n",
        "    save_model_to_dir(model, model.model_type)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"\\ndata = kerasNLP_model.load_data( 'predict' )\\ndata = kerasNLP_model.enhance_data( data, 'predict')\\nclean_data = kerasNLP_model.clean_data_for_prediction( data )\\n\\nX_predict, y_predict = kerasNLP_model.split_data( clean_data )\\ny_predict = kerasNLP_model.model.predict(X_predict)\\ndata['survival_prediction'] = y_predict\\nreturn data\\n\""
            ]
          },
          "execution_count": 90,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\"\"\"\n",
        "data = kerasNLP_model.load_data( 'predict' )\n",
        "data = kerasNLP_model.enhance_data( data, 'predict')\n",
        "clean_data = kerasNLP_model.clean_data_for_prediction( data )\n",
        "\n",
        "X_predict, y_predict = kerasNLP_model.split_data( clean_data )\n",
        "y_predict = kerasNLP_model.model.predict(X_predict)\n",
        "data['survival_prediction'] = y_predict\n",
        "return data\n",
        "\"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/briarmoss/.local/lib/python3.10/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import datetime\n",
        "\n",
        "def save_model_to_dir(model, folder_name):\n",
        "    dir_path = os.path.join(MODEL_FOLDER, folder_name)\n",
        "    \n",
        "    if not os.path.exists(dir_path):\n",
        "        os.mkdir(dir_path)\n",
        "    \n",
        "    timestamp = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "    model_name = timestamp + \"_\" + model.model_type\n",
        "    properties_name = model_name\n",
        "    \n",
        "    model.save(dir_path, model_name, properties_name)\n",
        "\n",
        "# List of models\n",
        "models = [kerasNLP_model]\n",
        "\n",
        "\n",
        "# Iterate over models and save\n",
        "for model in models:\n",
        "    save_model_to_dir(model, model.model_type)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
