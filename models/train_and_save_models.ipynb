{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P1BXqsllgueC"
      },
      "source": [
        "#Boston 311 Tutorial\n",
        "\n",
        "This notebook will run you through the basic usage of this package to train 3 models on the Boston 311 mydata and use them to predict the outcome of cases from the last 30 days"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: keras-tuner in /home/briarmoss/.local/lib/python3.10/site-packages (1.4.0)\n",
            "Requirement already satisfied: packaging in /home/briarmoss/.local/lib/python3.10/site-packages (from keras-tuner) (23.1)\n",
            "Requirement already satisfied: requests in /usr/lib/python3/dist-packages (from keras-tuner) (2.25.1)\n",
            "Requirement already satisfied: keras-core in /home/briarmoss/.local/lib/python3.10/site-packages (from keras-tuner) (0.1.7)\n",
            "Requirement already satisfied: kt-legacy in /home/briarmoss/.local/lib/python3.10/site-packages (from keras-tuner) (1.0.5)\n",
            "Requirement already satisfied: absl-py in /home/briarmoss/.local/lib/python3.10/site-packages (from keras-core->keras-tuner) (1.4.0)\n",
            "Requirement already satisfied: namex in /home/briarmoss/.local/lib/python3.10/site-packages (from keras-core->keras-tuner) (0.0.7)\n",
            "Requirement already satisfied: numpy in /home/briarmoss/.local/lib/python3.10/site-packages (from keras-core->keras-tuner) (1.23.5)\n",
            "Requirement already satisfied: h5py in /home/briarmoss/.local/lib/python3.10/site-packages (from keras-core->keras-tuner) (3.8.0)\n",
            "Requirement already satisfied: dm-tree in /home/briarmoss/.local/lib/python3.10/site-packages (from keras-core->keras-tuner) (0.1.8)\n",
            "Requirement already satisfied: rich in /home/briarmoss/.local/lib/python3.10/site-packages (from keras-core->keras-tuner) (13.5.3)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/briarmoss/.local/lib/python3.10/site-packages (from rich->keras-core->keras-tuner) (2.15.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/briarmoss/.local/lib/python3.10/site-packages (from rich->keras-core->keras-tuner) (3.0.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /home/briarmoss/.local/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras-core->keras-tuner) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install keras-tuner"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Processing /home/briarmoss/Documents/Boston_311\n",
            "  Installing build dependencies ... \u001b[?25ldone\n",
            "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
            "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/lib/python3/dist-packages (from boston311==0.1.0) (3.5.1)\n",
            "Requirement already satisfied: pandas in /home/briarmoss/.local/lib/python3.10/site-packages (from boston311==0.1.0) (2.0.2)\n",
            "Requirement already satisfied: tensorflow in /home/briarmoss/.local/lib/python3.10/site-packages (from boston311==0.1.0) (2.13.0)\n",
            "Requirement already satisfied: scikit-learn in /home/briarmoss/.local/lib/python3.10/site-packages (from boston311==0.1.0) (1.2.2)\n",
            "Requirement already satisfied: numpy in /home/briarmoss/.local/lib/python3.10/site-packages (from boston311==0.1.0) (1.23.5)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas->boston311==0.1.0) (2022.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /home/briarmoss/.local/lib/python3.10/site-packages (from pandas->boston311==0.1.0) (2.8.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /home/briarmoss/.local/lib/python3.10/site-packages (from pandas->boston311==0.1.0) (2023.3)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/briarmoss/.local/lib/python3.10/site-packages (from scikit-learn->boston311==0.1.0) (3.1.0)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /home/briarmoss/.local/lib/python3.10/site-packages (from scikit-learn->boston311==0.1.0) (1.10.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /home/briarmoss/.local/lib/python3.10/site-packages (from scikit-learn->boston311==0.1.0) (1.2.0)\n",
            "Requirement already satisfied: tensorboard<2.14,>=2.13 in /home/briarmoss/.local/lib/python3.10/site-packages (from tensorflow->boston311==0.1.0) (2.13.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /home/briarmoss/.local/lib/python3.10/site-packages (from tensorflow->boston311==0.1.0) (1.6.3)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /home/briarmoss/.local/lib/python3.10/site-packages (from tensorflow->boston311==0.1.0) (16.0.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /home/briarmoss/.local/lib/python3.10/site-packages (from tensorflow->boston311==0.1.0) (0.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/lib/python3/dist-packages (from tensorflow->boston311==0.1.0) (1.16.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /home/briarmoss/.local/lib/python3.10/site-packages (from tensorflow->boston311==0.1.0) (1.4.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /home/briarmoss/.local/lib/python3.10/site-packages (from tensorflow->boston311==0.1.0) (3.8.0)\n",
            "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in /home/briarmoss/.local/lib/python3.10/site-packages (from tensorflow->boston311==0.1.0) (4.5.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /home/briarmoss/.local/lib/python3.10/site-packages (from tensorflow->boston311==0.1.0) (4.23.3)\n",
            "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from tensorflow->boston311==0.1.0) (59.6.0)\n",
            "Requirement already satisfied: keras<2.14,>=2.13.1 in /home/briarmoss/.local/lib/python3.10/site-packages (from tensorflow->boston311==0.1.0) (2.13.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/briarmoss/.local/lib/python3.10/site-packages (from tensorflow->boston311==0.1.0) (1.54.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in /home/briarmoss/.local/lib/python3.10/site-packages (from tensorflow->boston311==0.1.0) (2.13.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /home/briarmoss/.local/lib/python3.10/site-packages (from tensorflow->boston311==0.1.0) (3.3.0)\n",
            "Requirement already satisfied: flatbuffers>=23.1.21 in /home/briarmoss/.local/lib/python3.10/site-packages (from tensorflow->boston311==0.1.0) (23.5.26)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/briarmoss/.local/lib/python3.10/site-packages (from tensorflow->boston311==0.1.0) (0.32.0)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /home/briarmoss/.local/lib/python3.10/site-packages (from tensorflow->boston311==0.1.0) (0.4.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /home/briarmoss/.local/lib/python3.10/site-packages (from tensorflow->boston311==0.1.0) (2.3.0)\n",
            "Requirement already satisfied: packaging in /home/briarmoss/.local/lib/python3.10/site-packages (from tensorflow->boston311==0.1.0) (23.1)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /home/briarmoss/.local/lib/python3.10/site-packages (from tensorflow->boston311==0.1.0) (1.14.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/lib/python3/dist-packages (from astunparse>=1.6.0->tensorflow->boston311==0.1.0) (0.37.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/briarmoss/.local/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow->boston311==0.1.0) (0.7.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /home/briarmoss/.local/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow->boston311==0.1.0) (2.3.6)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/briarmoss/.local/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow->boston311==0.1.0) (2.20.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /home/briarmoss/.local/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow->boston311==0.1.0) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /home/briarmoss/.local/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow->boston311==0.1.0) (3.4.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/lib/python3/dist-packages (from tensorboard<2.14,>=2.13->tensorflow->boston311==0.1.0) (2.25.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/briarmoss/.local/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow->boston311==0.1.0) (0.3.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/briarmoss/.local/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow->boston311==0.1.0) (5.3.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /home/briarmoss/.local/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow->boston311==0.1.0) (4.9)\n",
            "Requirement already satisfied: urllib3<2.0 in /usr/lib/python3/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow->boston311==0.1.0) (1.26.5)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/briarmoss/.local/lib/python3.10/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow->boston311==0.1.0) (1.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/briarmoss/.local/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow->boston311==0.1.0) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /home/briarmoss/.local/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow->boston311==0.1.0) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/lib/python3/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow->boston311==0.1.0) (3.2.0)\n",
            "Building wheels for collected packages: boston311\n",
            "  Building wheel for boston311 (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for boston311: filename=boston311-0.1.0-py3-none-any.whl size=18743 sha256=018bcde45bd6ea07ef1db1ba24d80cba1329bc4e04485978df85a2a0d9787f00\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-uaryng98/wheels/3d/69/ee/0a6ac96b9c09c948fc0e74f2724a9703aa39749a41fa757c9e\n",
            "Successfully built boston311\n",
            "Installing collected packages: boston311\n",
            "  Attempting uninstall: boston311\n",
            "    Found existing installation: boston311 0.1.0\n",
            "    Uninstalling boston311-0.1.0:\n",
            "      Successfully uninstalled boston311-0.1.0\n",
            "Successfully installed boston311-0.1.0\n"
          ]
        }
      ],
      "source": [
        "! pip install ../"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XP7Hzen_iEAl"
      },
      "source": [
        "##Import the Boston311Model class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "LdhJESm7eWaY"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-24 14:31:44.967950: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2023-09-24 14:31:45.002001: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2023-09-24 14:31:45.002557: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-09-24 14:31:45.488129: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend\n"
          ]
        }
      ],
      "source": [
        "from boston311 import Boston311LogReg, Boston311EventDecTree, Boston311SurvDecTree, Boston311KerasNLP\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oq06XnVjPxvg"
      },
      "source": [
        "## Get latest file URLS and Current Date Ranges"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "_2FYkUb2P1LR"
      },
      "outputs": [],
      "source": [
        "latest_URLS = Boston311LogReg.get311URLs()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mpg9Czm3QDpu",
        "outputId": "5e2b399b-0999-45d4-f9f9-d80ec19941ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'2023': 'https://data.boston.gov/dataset/8048697b-ad64-4bfc-b090-ee00169f2323/resource/e6013a93-1321-4f2a-bf91-8d8a02f1e62f/download/tmph34r4avm.csv', '2022': 'https://data.boston.gov/dataset/8048697b-ad64-4bfc-b090-ee00169f2323/resource/81a7b022-f8fc-4da5-80e4-b160058ca207/download/tmpfm8veglw.csv', '2021': 'https://data.boston.gov/dataset/8048697b-ad64-4bfc-b090-ee00169f2323/resource/f53ebccd-bc61-49f9-83db-625f209c95f5/download/tmp88p9g82n.csv', '2020': 'https://data.boston.gov/dataset/8048697b-ad64-4bfc-b090-ee00169f2323/resource/6ff6a6fd-3141-4440-a880-6f60a37fe789/download/tmpcv_10m2s.csv', '2019': 'https://data.boston.gov/dataset/8048697b-ad64-4bfc-b090-ee00169f2323/resource/ea2e4696-4a2d-429c-9807-d02eb92e0222/download/tmpcje3ep_w.csv', '2018': 'https://data.boston.gov/dataset/8048697b-ad64-4bfc-b090-ee00169f2323/resource/2be28d90-3a90-4af1-a3f6-f28c1e25880a/download/tmp7602cia8.csv', '2017': 'https://data.boston.gov/dataset/8048697b-ad64-4bfc-b090-ee00169f2323/resource/30022137-709d-465e-baae-ca155b51927d/download/tmpzccn8u4q.csv', '2016': 'https://data.boston.gov/dataset/8048697b-ad64-4bfc-b090-ee00169f2323/resource/b7ea6b1b-3ca4-4c5b-9713-6dc1db52379a/download/tmpzxzxeqfb.csv', '2015': 'https://data.boston.gov/dataset/8048697b-ad64-4bfc-b090-ee00169f2323/resource/c9509ab4-6f6d-4b97-979a-0cf2a10c922b/download/tmphrybkxuh.csv', '2014': 'https://data.boston.gov/dataset/8048697b-ad64-4bfc-b090-ee00169f2323/resource/bdae89c8-d4ce-40e9-a6e1-a5203953a2e0/download/tmp8afxvko_.csv', '2013': 'https://data.boston.gov/dataset/8048697b-ad64-4bfc-b090-ee00169f2323/resource/407c5cd0-f764-4a41-adf8-054ff535049e/download/tmpyzk_wmya.csv', '2012': 'https://data.boston.gov/dataset/8048697b-ad64-4bfc-b090-ee00169f2323/resource/382e10d9-1864-40ba-bef6-4eea3c75463c/download/tmpeyvgdt5u.csv', '2011': 'https://data.boston.gov/dataset/8048697b-ad64-4bfc-b090-ee00169f2323/resource/94b499d9-712a-4d2a-b790-7ceec5c9c4b1/download/tmp_9ogynu0.csv'}\n"
          ]
        }
      ],
      "source": [
        "print(latest_URLS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uUMCPAELR9h7",
        "outputId": "05fcba64-1b74-4fb7-a52c-d3f8a499bcc6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-09-24 2023-08-25 2023-09-25\n"
          ]
        }
      ],
      "source": [
        "from datetime import datetime, timedelta\n",
        "now = datetime.now()\n",
        "thirty_days = timedelta(days=30)\n",
        "thirty_days_ago = now - thirty_days\n",
        "today_datestring = now.strftime(\"%Y-%m-%d\")\n",
        "thirty_days_ago_datestring = thirty_days_ago.strftime(\"%Y-%m-%d\")\n",
        "tomorrow_datestring = (datetime.today() + timedelta(days=1)).strftime('%Y-%m-%d')\n",
        "\n",
        "print(today_datestring, thirty_days_ago_datestring, tomorrow_datestring)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "#set model folder constant\n",
        "MODEL_FOLDER = './daily_models'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load extra features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "#set path to mydata\n",
        "EXTRA_mydata_FILE = './cls_and_pooled_embeddings_with_service_id.csv'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NN_UiAIvb9MT"
      },
      "source": [
        "##Define several models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "nmi4jJgDF4Fv"
      },
      "outputs": [],
      "source": [
        "linear_tree_model = Boston311SurvDecTree(train_date_range={'start':'2022-01-01','end':thirty_days_ago_datestring},\n",
        "                            predict_date_range={'start':thirty_days_ago_datestring,'end':today_datestring},\n",
        "                            feature_columns=['type','queue'],\n",
        "                            scenario={'dropColumnValues': {'source':['City Worker App', 'Employee Generated']},\n",
        "                                      'survivalTimeMin':0,\n",
        "                                      'survivalTimeFill':tomorrow_datestring},\n",
        "                            files_dict=latest_URLS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "GGSlYgH6s54c"
      },
      "outputs": [],
      "source": [
        "logistic_model = Boston311LogReg(train_date_range={'start':'2022-01-01','end':thirty_days_ago_datestring},\n",
        "                            predict_date_range={'start':thirty_days_ago_datestring,'end':today_datestring},\n",
        "                            feature_columns=['type', 'queue'],\n",
        "                            scenario={'dropColumnValues': {'source':['City Worker App', 'Employee Generated']},\n",
        "                                      'survivalTimeMin':0},\n",
        "                            files_dict=latest_URLS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "oldlogistic_model = Boston311LogReg(train_date_range={'start':'2022-01-01','end':thirty_days_ago_datestring},\n",
        "                            predict_date_range={'start':thirty_days_ago_datestring,'end':today_datestring},\n",
        "                            feature_columns=['type', 'queue'],\n",
        "                            scenario={'dropColumnValues': {'source':['City Worker App', 'Employee Generated']},\n",
        "                                      'survivalTimeMin':0},\n",
        "                            files_dict=latest_URLS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "_Ddtw6t8s5rj"
      },
      "outputs": [],
      "source": [
        "logistic_tree_model = Boston311EventDecTree(train_date_range={'start':'2022-01-01','end':thirty_days_ago_datestring},\n",
        "                            predict_date_range={'start':thirty_days_ago_datestring,'end':today_datestring},\n",
        "                            feature_columns=['type', 'queue'],\n",
        "                            scenario={'dropColumnValues': {'source':['City Worker App', 'Employee Generated']},\n",
        "                                      'survivalTimeMin':0},\n",
        "                            files_dict=latest_URLS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "kerasNLP_model = Boston311KerasNLP(train_date_range={'start':'2022-01-01','end':thirty_days_ago_datestring},\n",
        "                            predict_date_range={'start':thirty_days_ago_datestring,'end':today_datestring},\n",
        "                            feature_columns=['type', 'queue', 'source', 'subject', 'reason', 'department', 'ward_number'],\n",
        "                            scenario={'dropColumnValues': {'source':['City Worker App', 'Employee Generated']},\n",
        "                                      'survivalTimeMin':0,\n",
        "                                      'survivalTimeFill':tomorrow_datestring},\n",
        "                            files_dict=latest_URLS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "#get current datetime in Boston timezone as string\n",
        "from datetime import datetime\n",
        "from pytz import timezone\n",
        "import pytz\n",
        "boston = timezone('US/Eastern')\n",
        "now = datetime.now(boston)\n",
        "today_datestring = now.strftime(\"%Y-%m-%d\")\n",
        "#get time in Boston timezone as string for a filename\n",
        "now = datetime.now(boston)\n",
        "time_string = now.strftime(\"%H-%M-%S\")\n",
        "#define datetime string\n",
        "my_datetime = today_datestring + '_' + time_string "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/briarmoss/.local/lib/python3.10/site-packages/boston311/Boston311Model.py:259: DtypeWarning: Columns (13) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(file)\n",
            "/home/briarmoss/.local/lib/python3.10/site-packages/boston311/Boston311Model.py:259: DtypeWarning: Columns (13) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(file)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files with different number of columns from File 0:  []\n",
            "Files with same number of columns as File 0:  [0, 1]\n",
            "Files with different column order from File 0:  []\n",
            "Files with same column order as File 0:  [0, 1]\n"
          ]
        }
      ],
      "source": [
        "mydata = kerasNLP_model.load_data()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0         101004113346\n",
              "1         101004113347\n",
              "2         101004113348\n",
              "3         101004113349\n",
              "4         101004113351\n",
              "              ...     \n",
              "476127    101005012397\n",
              "476128    101005012398\n",
              "476129    101005012399\n",
              "476130    101005012400\n",
              "476131    101005012401\n",
              "Name: case_enquiry_id, Length: 476132, dtype: int64"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mydata['case_enquiry_id']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "mydata = kerasNLP_model.enhance_data(mydata)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "mydata = kerasNLP_model.apply_scenario(mydata)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "mydata = kerasNLP_model.clean_data(mydata)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0         101004113346\n",
            "1         101004113347\n",
            "2         101004113348\n",
            "3         101004113349\n",
            "4         101004113351\n",
            "              ...     \n",
            "476127    101005012397\n",
            "476128    101005012398\n",
            "476129    101005012399\n",
            "476130    101005012400\n",
            "476131    101005012401\n",
            "Name: case_enquiry_id, Length: 423410, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(mydata['case_enquiry_id'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from ast import literal_eval\n",
        "import pickle\n",
        "\n",
        "pickle_file = 'dataframe.pkl'\n",
        "\n",
        "X = None\n",
        "\n",
        "if os.path.exists(pickle_file):\n",
        "    X = pickle.load(open(pickle_file, \"rb\"))\n",
        "else:\n",
        "    X = pd.read_csv(EXTRA_mydata_FILE)\n",
        "\n",
        "    #rename service_request_id to case_enquiry_id\n",
        "    X.rename(columns={'service_request_id':'case_enquiry_id'}, inplace=True)\n",
        "    #remove all rows where case_enquiry_id is non-numeric\n",
        "    #X = X[X['case_enquiry_id'].str.isnumeric()]\n",
        "    #convert case_enquiry_id to int64\n",
        "    #X['case_enquiry_id'] = X['case_enquiry_id'].astype('int64')\n",
        "\n",
        "    # Convert stringified arrays back to NumPy arrays\n",
        "    X['cls_embedding'] = X['cls_embedding'].apply(literal_eval).apply(np.array)\n",
        "    X['pooled_embedding'] = X['pooled_embedding'].apply(literal_eval).apply(np.array)\n",
        "\n",
        "    pickle.dump(X, open(pickle_file, \"wb\"))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(275503, 3)"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = X\n",
        "# Assuming df is your DataFrame and it has columns 'cls_embedding' and 'pooled_embedding'\n",
        "cls_embedding_flattened = np.stack(df['cls_embedding'].to_numpy())\n",
        "pooled_embedding_flattened = np.stack(df['pooled_embedding'].to_numpy())\n",
        "\n",
        "# Remove the old columns\n",
        "df.drop(['cls_embedding', 'pooled_embedding'], axis=1, inplace=True)\n",
        "\n",
        "# Add the new flattened columns\n",
        "df_cls = pd.DataFrame(cls_embedding_flattened, columns=[f'cls_{i}' for i in range(cls_embedding_flattened.shape[1])])\n",
        "df_pooled = pd.DataFrame(pooled_embedding_flattened, columns=[f'pooled_{i}' for i in range(pooled_embedding_flattened.shape[1])])\n",
        "\n",
        "df = pd.concat([df, df_cls, df_pooled], axis=1)\n",
        "X = df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0               101004615710\n",
              "1               101004615710\n",
              "2         service_request_id\n",
              "3               101004616099\n",
              "4               101004616098\n",
              "                 ...        \n",
              "275498          101005063009\n",
              "275499          101005062363\n",
              "275500          101005061781\n",
              "275501          101005063039\n",
              "275502          101005062077\n",
              "Name: case_enquiry_id, Length: 275503, dtype: object"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X['case_enquiry_id']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "X['case_enquiry_id'] = X['case_enquiry_id'].astype(str)\n",
        "is_numeric = X['case_enquiry_id'].str.isnumeric()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "X = X[is_numeric]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_458459/2653176235.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X['case_enquiry_id'] = X['case_enquiry_id'].astype('int64')\n"
          ]
        }
      ],
      "source": [
        "X['case_enquiry_id'] = X['case_enquiry_id'].astype('int64')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(275502, 257)"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(423410, 443)"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mydata.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "#join them so we are left only with records that have mydata in both files\n",
        "new_mydata = mydata.merge(X, on='case_enquiry_id', how='inner')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(156025, 699)"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "new_mydata.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "X, y = kerasNLP_model.split_data(new_mydata)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "#cast all columns that are type bool to float\n",
        "for col in X.columns:\n",
        "    if X[col].dtype == 'bool':\n",
        "        X[col] = X[col].astype('float64')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(156025, 696)\n",
            "(156025,)\n"
          ]
        }
      ],
      "source": [
        "#list the number of rows in X and y\n",
        "print(X.shape)\n",
        "print(y.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial 26 Complete [00h 02m 06s]\n",
            "val_accuracy: 0.7302035093307495\n",
            "\n",
            "Best val_accuracy So Far: 0.735074520111084\n",
            "Total elapsed time: 01h 24m 25s\n",
            "\n",
            "Search: Running Trial #27\n",
            "\n",
            "Value             |Best Value So Far |Hyperparameter\n",
            "1024              |1024              |start_nodes\n",
            "64                |64                |end_nodes\n",
            "0.00013238        |1e-05             |l2_0\n",
            "1e-05             |0.00014927        |learning_rate\n",
            "\n",
            "Epoch 1/10\n",
            "1055/3901 [=======>......................] - ETA: 23s - loss: 2.0726 - accuracy: 0.3526 - top_k_categorical_accuracy: 0.5366"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3901/3901 [==============================] - 34s 9ms/step - loss: 1.7729 - accuracy: 0.4443 - top_k_categorical_accuracy: 0.6530 - val_loss: 1.5523 - val_accuracy: 0.5129 - val_top_k_categorical_accuracy: 0.7332\n",
            "Epoch 2/10\n",
            "2688/3901 [===================>..........] - ETA: 9s - loss: 1.4927 - accuracy: 0.5382 - top_k_categorical_accuracy: 0.7456"
          ]
        }
      ],
      "source": [
        "best_model, best_hyperparameters = kerasNLP_model.tune_model(X, y, '/home/briarmoss/Documents/Boston_311/models/tuning')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting Training at 2023-09-24 00:55:45.726527\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "3901/3901 [==============================] - 9s 2ms/step - loss: 1.5726 - accuracy: 0.5613 - top_k_categorical_accuracy: 0.7516 - val_loss: 1.3970 - val_accuracy: 0.5932 - val_top_k_categorical_accuracy: 0.7760\n",
            "Epoch 2/100\n",
            "3901/3901 [==============================] - 8s 2ms/step - loss: 1.2808 - accuracy: 0.6225 - top_k_categorical_accuracy: 0.7959 - val_loss: 1.2950 - val_accuracy: 0.6143 - val_top_k_categorical_accuracy: 0.7894\n",
            "Epoch 3/100\n",
            "3901/3901 [==============================] - 8s 2ms/step - loss: 1.1986 - accuracy: 0.6436 - top_k_categorical_accuracy: 0.8068 - val_loss: 1.2789 - val_accuracy: 0.6190 - val_top_k_categorical_accuracy: 0.7743\n",
            "Epoch 4/100\n",
            "3901/3901 [==============================] - 8s 2ms/step - loss: 1.1547 - accuracy: 0.6560 - top_k_categorical_accuracy: 0.8152 - val_loss: 1.1756 - val_accuracy: 0.6395 - val_top_k_categorical_accuracy: 0.8143\n",
            "Epoch 5/100\n",
            "3901/3901 [==============================] - 8s 2ms/step - loss: 1.1288 - accuracy: 0.6632 - top_k_categorical_accuracy: 0.8196 - val_loss: 1.1321 - val_accuracy: 0.6588 - val_top_k_categorical_accuracy: 0.8204\n",
            "Epoch 6/100\n",
            "3901/3901 [==============================] - 8s 2ms/step - loss: 1.1107 - accuracy: 0.6696 - top_k_categorical_accuracy: 0.8220 - val_loss: 1.1207 - val_accuracy: 0.6606 - val_top_k_categorical_accuracy: 0.8197\n",
            "Epoch 7/100\n",
            "3901/3901 [==============================] - 8s 2ms/step - loss: 1.1077 - accuracy: 0.6707 - top_k_categorical_accuracy: 0.8217 - val_loss: 1.0942 - val_accuracy: 0.6780 - val_top_k_categorical_accuracy: 0.8237\n",
            "Epoch 8/100\n",
            "3901/3901 [==============================] - 8s 2ms/step - loss: 1.0914 - accuracy: 0.6764 - top_k_categorical_accuracy: 0.8244 - val_loss: 1.1431 - val_accuracy: 0.6563 - val_top_k_categorical_accuracy: 0.8200\n",
            "Epoch 9/100\n",
            "3901/3901 [==============================] - 8s 2ms/step - loss: 1.0828 - accuracy: 0.6777 - top_k_categorical_accuracy: 0.8250 - val_loss: 1.0930 - val_accuracy: 0.6724 - val_top_k_categorical_accuracy: 0.8236\n",
            "Epoch 10/100\n",
            "3901/3901 [==============================] - 8s 2ms/step - loss: 1.0817 - accuracy: 0.6790 - top_k_categorical_accuracy: 0.8252 - val_loss: 1.0643 - val_accuracy: 0.6843 - val_top_k_categorical_accuracy: 0.8270\n",
            "Epoch 11/100\n",
            "3901/3901 [==============================] - 8s 2ms/step - loss: 1.0854 - accuracy: 0.6764 - top_k_categorical_accuracy: 0.8247 - val_loss: 1.1288 - val_accuracy: 0.6674 - val_top_k_categorical_accuracy: 0.8160\n",
            "Epoch 12/100\n",
            "3901/3901 [==============================] - 8s 2ms/step - loss: 1.0717 - accuracy: 0.6809 - top_k_categorical_accuracy: 0.8277 - val_loss: 1.0642 - val_accuracy: 0.6863 - val_top_k_categorical_accuracy: 0.8317\n",
            "Epoch 13/100\n",
            "3901/3901 [==============================] - 8s 2ms/step - loss: 1.0699 - accuracy: 0.6825 - top_k_categorical_accuracy: 0.8282 - val_loss: 1.0608 - val_accuracy: 0.6840 - val_top_k_categorical_accuracy: 0.8314\n",
            "Epoch 14/100\n",
            "3901/3901 [==============================] - 8s 2ms/step - loss: 1.0651 - accuracy: 0.6842 - top_k_categorical_accuracy: 0.8289 - val_loss: 1.0473 - val_accuracy: 0.6923 - val_top_k_categorical_accuracy: 0.8284\n",
            "Epoch 15/100\n",
            "3901/3901 [==============================] - 8s 2ms/step - loss: 1.0648 - accuracy: 0.6835 - top_k_categorical_accuracy: 0.8278 - val_loss: 1.0997 - val_accuracy: 0.6790 - val_top_k_categorical_accuracy: 0.8251\n",
            "Epoch 16/100\n",
            "3901/3901 [==============================] - 8s 2ms/step - loss: 1.0647 - accuracy: 0.6840 - top_k_categorical_accuracy: 0.8278 - val_loss: 1.0484 - val_accuracy: 0.6881 - val_top_k_categorical_accuracy: 0.8343\n",
            "Epoch 17/100\n",
            "3901/3901 [==============================] - 8s 2ms/step - loss: 1.0600 - accuracy: 0.6855 - top_k_categorical_accuracy: 0.8294 - val_loss: 1.0325 - val_accuracy: 0.6922 - val_top_k_categorical_accuracy: 0.8311\n",
            "Epoch 18/100\n",
            "3901/3901 [==============================] - 8s 2ms/step - loss: 1.0645 - accuracy: 0.6843 - top_k_categorical_accuracy: 0.8291 - val_loss: 1.0870 - val_accuracy: 0.6776 - val_top_k_categorical_accuracy: 0.8253\n",
            "Epoch 19/100\n",
            "3901/3901 [==============================] - 8s 2ms/step - loss: 1.0619 - accuracy: 0.6848 - top_k_categorical_accuracy: 0.8294 - val_loss: 1.1467 - val_accuracy: 0.6564 - val_top_k_categorical_accuracy: 0.8190\n",
            "Epoch 20/100\n",
            "3901/3901 [==============================] - 8s 2ms/step - loss: 1.0598 - accuracy: 0.6849 - top_k_categorical_accuracy: 0.8295 - val_loss: 1.2239 - val_accuracy: 0.6454 - val_top_k_categorical_accuracy: 0.7887\n",
            "Epoch 21/100\n",
            "3901/3901 [==============================] - 8s 2ms/step - loss: 1.0549 - accuracy: 0.6868 - top_k_categorical_accuracy: 0.8300 - val_loss: 1.0360 - val_accuracy: 0.6927 - val_top_k_categorical_accuracy: 0.8323\n",
            "Epoch 22/100\n",
            "3901/3901 [==============================] - 8s 2ms/step - loss: 1.0533 - accuracy: 0.6867 - top_k_categorical_accuracy: 0.8306 - val_loss: 1.1601 - val_accuracy: 0.6445 - val_top_k_categorical_accuracy: 0.8133\n",
            "Epoch 23/100\n",
            "3901/3901 [==============================] - 8s 2ms/step - loss: 1.0684 - accuracy: 0.6808 - top_k_categorical_accuracy: 0.8277 - val_loss: 1.1986 - val_accuracy: 0.6445 - val_top_k_categorical_accuracy: 0.8127\n",
            "Epoch 24/100\n",
            "3901/3901 [==============================] - 8s 2ms/step - loss: 1.0571 - accuracy: 0.6840 - top_k_categorical_accuracy: 0.8293 - val_loss: 1.0387 - val_accuracy: 0.6890 - val_top_k_categorical_accuracy: 0.8297\n",
            "Epoch 25/100\n",
            "3901/3901 [==============================] - 8s 2ms/step - loss: 1.0616 - accuracy: 0.6823 - top_k_categorical_accuracy: 0.8272 - val_loss: 1.0574 - val_accuracy: 0.6856 - val_top_k_categorical_accuracy: 0.8321\n",
            "Epoch 26/100\n",
            "3901/3901 [==============================] - 8s 2ms/step - loss: 1.0617 - accuracy: 0.6829 - top_k_categorical_accuracy: 0.8277 - val_loss: 1.0233 - val_accuracy: 0.7032 - val_top_k_categorical_accuracy: 0.8319\n",
            "Epoch 27/100\n",
            "3901/3901 [==============================] - 8s 2ms/step - loss: 1.0544 - accuracy: 0.6855 - top_k_categorical_accuracy: 0.8292 - val_loss: 1.1235 - val_accuracy: 0.6618 - val_top_k_categorical_accuracy: 0.8218\n",
            "Epoch 28/100\n",
            "3901/3901 [==============================] - 8s 2ms/step - loss: 1.0486 - accuracy: 0.6876 - top_k_categorical_accuracy: 0.8305 - val_loss: 1.0441 - val_accuracy: 0.6907 - val_top_k_categorical_accuracy: 0.8314\n",
            "Epoch 29/100\n",
            "3901/3901 [==============================] - 8s 2ms/step - loss: 1.0489 - accuracy: 0.6867 - top_k_categorical_accuracy: 0.8301 - val_loss: 1.1316 - val_accuracy: 0.6676 - val_top_k_categorical_accuracy: 0.8132\n",
            "Epoch 30/100\n",
            "3901/3901 [==============================] - 8s 2ms/step - loss: 1.0477 - accuracy: 0.6871 - top_k_categorical_accuracy: 0.8303 - val_loss: 1.0839 - val_accuracy: 0.6737 - val_top_k_categorical_accuracy: 0.8230\n",
            "Epoch 31/100\n",
            "3901/3901 [==============================] - 8s 2ms/step - loss: 1.0458 - accuracy: 0.6877 - top_k_categorical_accuracy: 0.8307 - val_loss: 1.0687 - val_accuracy: 0.6839 - val_top_k_categorical_accuracy: 0.8301\n",
            "Epoch 32/100\n",
            "3901/3901 [==============================] - 8s 2ms/step - loss: 1.0448 - accuracy: 0.6884 - top_k_categorical_accuracy: 0.8314 - val_loss: 1.1331 - val_accuracy: 0.6533 - val_top_k_categorical_accuracy: 0.8159\n",
            "Epoch 33/100\n",
            "3901/3901 [==============================] - 8s 2ms/step - loss: 1.0459 - accuracy: 0.6885 - top_k_categorical_accuracy: 0.8303 - val_loss: 1.0998 - val_accuracy: 0.6675 - val_top_k_categorical_accuracy: 0.8293\n",
            "Epoch 34/100\n",
            "3901/3901 [==============================] - 8s 2ms/step - loss: 1.0424 - accuracy: 0.6890 - top_k_categorical_accuracy: 0.8311 - val_loss: 1.0238 - val_accuracy: 0.6949 - val_top_k_categorical_accuracy: 0.8320\n",
            "Epoch 35/100\n",
            "3901/3901 [==============================] - 8s 2ms/step - loss: 1.0427 - accuracy: 0.6891 - top_k_categorical_accuracy: 0.8311 - val_loss: 1.0309 - val_accuracy: 0.6940 - val_top_k_categorical_accuracy: 0.8327\n",
            "Epoch 36/100\n",
            "3901/3901 [==============================] - 8s 2ms/step - loss: 1.0417 - accuracy: 0.6894 - top_k_categorical_accuracy: 0.8312 - val_loss: 1.0398 - val_accuracy: 0.6948 - val_top_k_categorical_accuracy: 0.8329\n",
            "976/976 [==============================] - 1s 769us/step - loss: 1.0233 - accuracy: 0.7032 - top_k_categorical_accuracy: 0.8319\n",
            "Testing accuracy: 0.7031565308570862 \n",
            "Top-2 accuracy: 0.8318538665771484 \n",
            "Test loss: 1.0232927799224854\n",
            "Ending Training at 2023-09-24 01:00:35.303744\n",
            "Training took 0:04:49.577217\n"
          ]
        }
      ],
      "source": [
        "\n",
        "#parse CLS embedding column as array\n",
        "test_acc = kerasNLP_model.train_model( X, y )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sSSkyth-2K3A"
      },
      "source": [
        "## Train several models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "learning is fun!\n"
          ]
        }
      ],
      "source": [
        "print(\"learning is fun!\") "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lv4ivBuvinss",
        "outputId": "814ef4fb-e100-4b22-ccbc-6b9d91e5a341"
      },
      "outputs": [],
      "source": [
        "#logistic_tree_model.run_pipeline()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_UIaks6jjPkU",
        "outputId": "0e365ed1-472e-4cb1-cdde-ae0a2d32722e"
      },
      "outputs": [],
      "source": [
        "#logistic_model.run_pipeline()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2412"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import gc\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#linear_tree_model.run_pipeline()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\nimport datetime\\n\\ndef save_model_to_dir(model, folder_name):\\n    dir_path = os.path.join(MODEL_FOLDER, folder_name)\\n    \\n    if not os.path.exists(dir_path):\\n        os.mkdir(dir_path)\\n    \\n    timestamp = datetime.datetime.now().strftime(\\'%Y%m%d_%H%M%S\\')\\n    model_name = timestamp + \"_\" + model.model_type\\n    properties_name = model_name\\n    \\n    model.save(dir_path, model_name, properties_name)\\n\\n# List of models\\nmodels = [linear_tree_model, logistic_tree_model, logistic_model]\\n\\n\\n# Iterate over models and save\\nfor model in models:\\n    save_model_to_dir(model, model.model_type)\\n'"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\"\"\"\n",
        "import datetime\n",
        "\n",
        "def save_model_to_dir(model, folder_name):\n",
        "    dir_path = os.path.join(MODEL_FOLDER, folder_name)\n",
        "    \n",
        "    if not os.path.exists(dir_path):\n",
        "        os.mkdir(dir_path)\n",
        "    \n",
        "    timestamp = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "    model_name = timestamp + \"_\" + model.model_type\n",
        "    properties_name = model_name\n",
        "    \n",
        "    model.save(dir_path, model_name, properties_name)\n",
        "\n",
        "# List of models\n",
        "models = [linear_tree_model, logistic_tree_model, logistic_model]\n",
        "\n",
        "\n",
        "# Iterate over models and save\n",
        "for model in models:\n",
        "    save_model_to_dir(model, model.model_type)\n",
        "\"\"\"\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
