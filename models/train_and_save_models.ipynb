{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P1BXqsllgueC"
      },
      "source": [
        "#Boston 311 Tutorial\n",
        "\n",
        "This notebook will run you through the basic usage of this package to train 3 models on the Boston 311 mydata and use them to predict the outcome of cases from the last 30 days"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# !pip install keras-tuner"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Processing /home/briarmoss/Documents/Boston_311\n",
            "  Installing build dependencies ... \u001b[?25l"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "done\n",
            "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
            "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25hBuilding wheels for collected packages: boston311\n",
            "  Building wheel for boston311 (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for boston311: filename=boston311-0.1.0-py3-none-any.whl size=19309 sha256=b53af5bd2ce22cbf3634fc5df07c334755269298d0528c6d300d8a787d6f488e\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-fp2ut5xo/wheels/3d/69/ee/0a6ac96b9c09c948fc0e74f2724a9703aa39749a41fa757c9e\n",
            "Successfully built boston311\n",
            "Installing collected packages: boston311\n",
            "  Attempting uninstall: boston311\n",
            "    Found existing installation: boston311 0.1.0\n",
            "    Uninstalling boston311-0.1.0:\n",
            "      Successfully uninstalled boston311-0.1.0\n",
            "Successfully installed boston311-0.1.0\n"
          ]
        }
      ],
      "source": [
        "! pip install  ../"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XP7Hzen_iEAl"
      },
      "source": [
        "##Import the Boston311Model class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "#os.environ['HSA_OVERRIDE_GFX_VERSION'] = '10.3.0'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "LdhJESm7eWaY"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-10-23 02:35:00.930248: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2023-10-23 02:35:00.972861: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2023-10-23 02:35:00.973569: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-10-23 02:35:01.487304: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend\n"
          ]
        }
      ],
      "source": [
        "from boston311 import Boston311LogReg, Boston311EventDecTree, Boston311SurvDecTree, Boston311KerasNLP\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oq06XnVjPxvg"
      },
      "source": [
        "## Get latest file URLS and Current Date Ranges"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "_2FYkUb2P1LR"
      },
      "outputs": [],
      "source": [
        "latest_URLS = Boston311LogReg.get311URLs()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mpg9Czm3QDpu",
        "outputId": "5e2b399b-0999-45d4-f9f9-d80ec19941ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'2023': 'https://data.boston.gov/dataset/8048697b-ad64-4bfc-b090-ee00169f2323/resource/e6013a93-1321-4f2a-bf91-8d8a02f1e62f/download/tmpt7t05mld.csv', '2022': 'https://data.boston.gov/dataset/8048697b-ad64-4bfc-b090-ee00169f2323/resource/81a7b022-f8fc-4da5-80e4-b160058ca207/download/tmpfm8veglw.csv', '2021': 'https://data.boston.gov/dataset/8048697b-ad64-4bfc-b090-ee00169f2323/resource/f53ebccd-bc61-49f9-83db-625f209c95f5/download/tmp88p9g82n.csv', '2020': 'https://data.boston.gov/dataset/8048697b-ad64-4bfc-b090-ee00169f2323/resource/6ff6a6fd-3141-4440-a880-6f60a37fe789/download/tmpcv_10m2s.csv', '2019': 'https://data.boston.gov/dataset/8048697b-ad64-4bfc-b090-ee00169f2323/resource/ea2e4696-4a2d-429c-9807-d02eb92e0222/download/tmpcje3ep_w.csv', '2018': 'https://data.boston.gov/dataset/8048697b-ad64-4bfc-b090-ee00169f2323/resource/2be28d90-3a90-4af1-a3f6-f28c1e25880a/download/tmp7602cia8.csv', '2017': 'https://data.boston.gov/dataset/8048697b-ad64-4bfc-b090-ee00169f2323/resource/30022137-709d-465e-baae-ca155b51927d/download/tmpzccn8u4q.csv', '2016': 'https://data.boston.gov/dataset/8048697b-ad64-4bfc-b090-ee00169f2323/resource/b7ea6b1b-3ca4-4c5b-9713-6dc1db52379a/download/tmpzxzxeqfb.csv', '2015': 'https://data.boston.gov/dataset/8048697b-ad64-4bfc-b090-ee00169f2323/resource/c9509ab4-6f6d-4b97-979a-0cf2a10c922b/download/tmphrybkxuh.csv', '2014': 'https://data.boston.gov/dataset/8048697b-ad64-4bfc-b090-ee00169f2323/resource/bdae89c8-d4ce-40e9-a6e1-a5203953a2e0/download/tmp8afxvko_.csv', '2013': 'https://data.boston.gov/dataset/8048697b-ad64-4bfc-b090-ee00169f2323/resource/407c5cd0-f764-4a41-adf8-054ff535049e/download/tmpyzk_wmya.csv', '2012': 'https://data.boston.gov/dataset/8048697b-ad64-4bfc-b090-ee00169f2323/resource/382e10d9-1864-40ba-bef6-4eea3c75463c/download/tmpeyvgdt5u.csv', '2011': 'https://data.boston.gov/dataset/8048697b-ad64-4bfc-b090-ee00169f2323/resource/94b499d9-712a-4d2a-b790-7ceec5c9c4b1/download/tmp_9ogynu0.csv'}\n"
          ]
        }
      ],
      "source": [
        "print(latest_URLS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uUMCPAELR9h7",
        "outputId": "05fcba64-1b74-4fb7-a52c-d3f8a499bcc6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-10-23 2023-09-23 2023-10-24\n"
          ]
        }
      ],
      "source": [
        "from datetime import datetime, timedelta\n",
        "now = datetime.now()\n",
        "thirty_days = timedelta(days=30)\n",
        "thirty_days_ago = now - thirty_days\n",
        "today_datestring = now.strftime(\"%Y-%m-%d\")\n",
        "thirty_days_ago_datestring = thirty_days_ago.strftime(\"%Y-%m-%d\")\n",
        "tomorrow_datestring = (datetime.today() + timedelta(days=1)).strftime('%Y-%m-%d')\n",
        "\n",
        "print(today_datestring, thirty_days_ago_datestring, tomorrow_datestring)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "#set model folder constant\n",
        "MODEL_FOLDER = './daily_models'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load extra features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "#set path to mydata\n",
        "EXTRA_mydata_FILE = './cls_and_pooled_embeddings_with_three_cols.csv'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "#define a function that takes a path to a csv file and a pkl file and checks if the csv file is newer than the pkl file, and if so, loads the csv file into a dataframe and saves it as a pkl file, else loads the pkl file into a dataframe\n",
        "def pkl_load_data(csv_path, pkl_path):\n",
        "    if os.path.exists(pkl_path):\n",
        "        pkl_time = os.path.getmtime(pkl_path)\n",
        "        csv_time = os.path.getmtime(csv_path)\n",
        "        if csv_time > pkl_time:\n",
        "            df = pd.read_csv(csv_path)\n",
        "            df.to_pickle(pkl_path)\n",
        "        else:\n",
        "            df = pd.read_pickle(pkl_path)\n",
        "    else:\n",
        "        df = pd.read_csv(csv_path)\n",
        "        df.to_pickle(pkl_path)\n",
        "    return df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NN_UiAIvb9MT"
      },
      "source": [
        "##Define several models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "nmi4jJgDF4Fv"
      },
      "outputs": [],
      "source": [
        "linear_tree_model = Boston311SurvDecTree(train_date_range={'start':'2022-01-01','end':thirty_days_ago_datestring},\n",
        "                            predict_date_range={'start':thirty_days_ago_datestring,'end':today_datestring},\n",
        "                            feature_columns=['type','queue'],\n",
        "                            scenario={'dropColumnValues': {'source':['City Worker App', 'Employee Generated']},\n",
        "                                      'survivalTimeMin':0,\n",
        "                                      'survivalTimeFill':tomorrow_datestring},\n",
        "                            files_dict=latest_URLS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "GGSlYgH6s54c"
      },
      "outputs": [],
      "source": [
        "logistic_model = Boston311LogReg(train_date_range={'start':'2022-01-01','end':thirty_days_ago_datestring},\n",
        "                            predict_date_range={'start':thirty_days_ago_datestring,'end':today_datestring},\n",
        "                            feature_columns=['type', 'queue'],\n",
        "                            scenario={'dropColumnValues': {'source':['City Worker App', 'Employee Generated']},\n",
        "                                      'survivalTimeMin':0},\n",
        "                            files_dict=latest_URLS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "oldlogistic_model = Boston311LogReg(train_date_range={'start':'2022-01-01','end':thirty_days_ago_datestring},\n",
        "                            predict_date_range={'start':thirty_days_ago_datestring,'end':today_datestring},\n",
        "                            feature_columns=['type', 'queue'],\n",
        "                            scenario={'dropColumnValues': {'source':['City Worker App', 'Employee Generated']},\n",
        "                                      'survivalTimeMin':0},\n",
        "                            files_dict=latest_URLS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "_Ddtw6t8s5rj"
      },
      "outputs": [],
      "source": [
        "logistic_tree_model = Boston311EventDecTree(train_date_range={'start':'2022-01-01','end':thirty_days_ago_datestring},\n",
        "                            predict_date_range={'start':thirty_days_ago_datestring,'end':today_datestring},\n",
        "                            feature_columns=['type', 'queue'],\n",
        "                            scenario={'dropColumnValues': {'source':['City Worker App', 'Employee Generated']},\n",
        "                                      'survivalTimeMin':0},\n",
        "                            files_dict=latest_URLS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "kerasNLP_model = Boston311KerasNLP(train_date_range={'start':'2010-01-01','end':thirty_days_ago_datestring},\n",
        "                            predict_date_range={'start':thirty_days_ago_datestring,'end':today_datestring},\n",
        "                            feature_columns=['queue', 'subject', 'reason', 'department'],\n",
        "                            scenario={'dropColumnValues': {'source':['City Worker App', 'Employee Generated']},\n",
        "                                      'survivalTimeMin':0,\n",
        "                                      'survivalTimeFill':tomorrow_datestring},\n",
        "                            files_dict=latest_URLS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "#get current datetime in Boston timezone as string\n",
        "from datetime import datetime\n",
        "from pytz import timezone\n",
        "import pytz\n",
        "boston = timezone('US/Eastern')\n",
        "now = datetime.now(boston)\n",
        "today_datestring = now.strftime(\"%Y-%m-%d\")\n",
        "#get time in Boston timezone as string for a filename\n",
        "now = datetime.now(boston)\n",
        "time_string = now.strftime(\"%H-%M-%S\")\n",
        "#define datetime string\n",
        "my_datetime = today_datestring + '_' + time_string "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "mydata = None\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "\n",
        "case_data_file = 'case_data.pkl'\n",
        "case_data_csv = 'all_311_cases.csv'\n",
        "mydata = None\n",
        "\n",
        "X = None\n",
        "\n",
        "\n",
        "data = pkl_load_data(case_data_csv, case_data_file)\n",
        "mydata = kerasNLP_model.load_data(data)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0          101000295613\n",
              "1          101000295614\n",
              "2          101000295615\n",
              "3          101000295616\n",
              "4          101000295617\n",
              "               ...     \n",
              "2703205    101005077762\n",
              "2703206    101005077764\n",
              "2703207    101005077765\n",
              "2703208    101005077767\n",
              "2703209    101005077768\n",
              "Name: case_enquiry_id, Length: 2703210, dtype: int64"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mydata['case_enquiry_id']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/briarmoss/.local/lib/python3.10/site-packages/boston311/Boston311Model.py:92: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['closed_dt'] = pd.to_datetime(data['closed_dt'])\n",
            "/home/briarmoss/.local/lib/python3.10/site-packages/boston311/Boston311Model.py:93: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['open_dt'] = pd.to_datetime(data['open_dt'])\n",
            "/home/briarmoss/.local/lib/python3.10/site-packages/boston311/Boston311Model.py:94: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['survival_time'] = data['closed_dt'] - data['open_dt']\n",
            "/home/briarmoss/.local/lib/python3.10/site-packages/boston311/Boston311Model.py:95: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['event'] = data['closed_dt'].notnull().astype(int)\n",
            "/home/briarmoss/.local/lib/python3.10/site-packages/boston311/Boston311Model.py:96: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['ward_number'] = data['ward'].str.extract(r'0*(\\d+)')\n",
            "/home/briarmoss/.local/lib/python3.10/site-packages/boston311/Boston311Model.py:100: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['season_cos'] = day_of_year.apply(lambda x: cos((x - 1) * (2. * pi / 365.25)))\n",
            "/home/briarmoss/.local/lib/python3.10/site-packages/boston311/Boston311Model.py:104: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['weekday_cos'] = weekday.apply(lambda x: cos(x * (2. * pi / 7)))\n",
            "/home/briarmoss/.local/lib/python3.10/site-packages/boston311/Boston311Model.py:107: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['survival_time_hours'] = np.nan\n"
          ]
        }
      ],
      "source": [
        "mydata = kerasNLP_model.enhance_data(mydata)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "cyclical_df = mydata[['case_enquiry_id', 'season_cos', 'weekday_cos']].copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "mydata = kerasNLP_model.apply_scenario(mydata)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "mydata = kerasNLP_model.clean_data(mydata)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1          101000295614\n",
            "2          101000295615\n",
            "3          101000295616\n",
            "4          101000295617\n",
            "5          101000295618\n",
            "               ...     \n",
            "2703204    101005077760\n",
            "2703205    101005077762\n",
            "2703206    101005077764\n",
            "2703207    101005077765\n",
            "2703208    101005077767\n",
            "Name: case_enquiry_id, Length: 2269940, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(mydata['case_enquiry_id'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from ast import literal_eval\n",
        "import pickle\n",
        "\n",
        "pickle_file = 'dataframe.pkl'\n",
        "\n",
        "X = None\n",
        "\n",
        "X = pkl_load_data(EXTRA_mydata_FILE, pickle_file)\n",
        "\n",
        "# if X has a column service_request_id, do the following\n",
        "if 'service_request_id' in X.columns:\n",
        "    X.rename(columns={'service_request_id':'case_enquiry_id'}, inplace=True)\n",
        "    #X['cls_embedding'] = X['cls_embedding'].apply(literal_eval).apply(np.array)\n",
        "    #X['pooled_embedding'] = X['pooled_embedding'].apply(literal_eval).apply(np.array)\n",
        "    #new code similar two above two lines but using the six columns of embeddings: desc_cls_embedding, desc_pooled_embedding, name_cls_embedding, name_pooled_embedding, code_cls_embedding, code_pooled_embedding\n",
        "    for col in ['desc_cls_embedding', 'desc_pooled_embedding', 'name_cls_embedding', 'name_pooled_embedding', 'code_cls_embedding', 'code_pooled_embedding']:\n",
        "        X[col] = X[col].apply(literal_eval).apply(np.array)\n",
        "\n",
        "    pickle.dump(X, open(pickle_file, \"wb\"))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 286639 entries, 0 to 286638\n",
            "Data columns (total 7 columns):\n",
            " #   Column                 Non-Null Count   Dtype \n",
            "---  ------                 --------------   ----- \n",
            " 0   case_enquiry_id        286639 non-null  int64 \n",
            " 1   desc_cls_embedding     286639 non-null  object\n",
            " 2   desc_pooled_embedding  286639 non-null  object\n",
            " 3   name_cls_embedding     286639 non-null  object\n",
            " 4   name_pooled_embedding  286639 non-null  object\n",
            " 5   code_cls_embedding     286639 non-null  object\n",
            " 6   code_pooled_embedding  286639 non-null  object\n",
            "dtypes: int64(1), object(6)\n",
            "memory usage: 15.3+ MB\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "#print information about X2022\n",
        "print(X.info())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "#concatenate the two dataframes and reindex\n",
        "df = X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(286639, 7)"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Assuming df is your DataFrame and it has columns 'desc_cls_embedding', 'desc_pooled_embedding', 'name_cls_embedding', 'name_pooled_embedding', 'code_cls_embedding', 'code_pooled_embedding'\n",
        "desc_cls_embedding_flattened = np.stack(df['desc_cls_embedding'].to_numpy())\n",
        "desc_pooled_embedding_flattened = np.stack(df['desc_pooled_embedding'].to_numpy())\n",
        "#do the same for the rest\n",
        "name_cls_embedding_flattened = np.stack(df['name_cls_embedding'].to_numpy())\n",
        "name_pooled_embedding_flattened = np.stack(df['name_pooled_embedding'].to_numpy())\n",
        "code_cls_embedding_flattened = np.stack(df['code_cls_embedding'].to_numpy())\n",
        "code_pooled_embedding_flattened = np.stack(df['code_pooled_embedding'].to_numpy())\n",
        "\n",
        "\n",
        "# Remove the old columns\n",
        "df.drop(['desc_cls_embedding', 'desc_pooled_embedding'], axis=1, inplace=True)\n",
        "#do the same for the rest\n",
        "df.drop(['name_cls_embedding', 'name_pooled_embedding'], axis=1, inplace=True)\n",
        "df.drop(['code_cls_embedding', 'code_pooled_embedding'], axis=1, inplace=True)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Add the new flattened columns\n",
        "df_desc_cls = pd.DataFrame(desc_cls_embedding_flattened, columns=[f'desc_cls_{i}' for i in range(desc_cls_embedding_flattened.shape[1])])\n",
        "\n",
        "df_desc_pooled = pd.DataFrame(desc_pooled_embedding_flattened, columns=[f'desc_pooled_{i}' for i in range(desc_pooled_embedding_flattened.shape[1])])\n",
        "#do the same for the rest\n",
        "df_name_cls = pd.DataFrame(name_cls_embedding_flattened, columns=[f'name_cls_{i}' for i in range(name_cls_embedding_flattened.shape[1])])\n",
        "df_name_pooled = pd.DataFrame(name_pooled_embedding_flattened, columns=[f'name_pooled_{i}' for i in range(name_pooled_embedding_flattened.shape[1])])\n",
        "df_code_cls = pd.DataFrame(code_cls_embedding_flattened, columns=[f'code_cls_{i}' for i in range(code_cls_embedding_flattened.shape[1])])\n",
        "df_code_pooled = pd.DataFrame(code_pooled_embedding_flattened, columns=[f'code_pooled_{i}' for i in range(code_pooled_embedding_flattened.shape[1])])\n",
        "\n",
        "\n",
        "\n",
        "df = pd.concat([df, df_desc_cls, df_desc_pooled, df_name_cls, df_name_pooled, df_code_cls, df_code_pooled], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "df['case_enquiry_id'] = df['case_enquiry_id'].astype(str)\n",
        "is_numeric = df['case_enquiry_id'].str.isnumeric()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = df[is_numeric]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "df['case_enquiry_id'] = df['case_enquiry_id'].astype('int64')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(286639, 769)"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = df.drop_duplicates(subset=['case_enquiry_id']) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(286639, 769)"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>case_enquiry_id</th>\n",
              "      <th>desc_cls_0</th>\n",
              "      <th>desc_cls_1</th>\n",
              "      <th>desc_cls_2</th>\n",
              "      <th>desc_cls_3</th>\n",
              "      <th>desc_cls_4</th>\n",
              "      <th>desc_cls_5</th>\n",
              "      <th>desc_cls_6</th>\n",
              "      <th>desc_cls_7</th>\n",
              "      <th>desc_cls_8</th>\n",
              "      <th>...</th>\n",
              "      <th>code_pooled_118</th>\n",
              "      <th>code_pooled_119</th>\n",
              "      <th>code_pooled_120</th>\n",
              "      <th>code_pooled_121</th>\n",
              "      <th>code_pooled_122</th>\n",
              "      <th>code_pooled_123</th>\n",
              "      <th>code_pooled_124</th>\n",
              "      <th>code_pooled_125</th>\n",
              "      <th>code_pooled_126</th>\n",
              "      <th>code_pooled_127</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>101004113559</td>\n",
              "      <td>-1.100319</td>\n",
              "      <td>0.180848</td>\n",
              "      <td>-3.067521</td>\n",
              "      <td>-2.449431</td>\n",
              "      <td>0.048062</td>\n",
              "      <td>0.750774</td>\n",
              "      <td>-1.156688</td>\n",
              "      <td>1.701071</td>\n",
              "      <td>-1.121157</td>\n",
              "      <td>...</td>\n",
              "      <td>0.121683</td>\n",
              "      <td>-0.998929</td>\n",
              "      <td>0.036228</td>\n",
              "      <td>-0.999963</td>\n",
              "      <td>-0.742293</td>\n",
              "      <td>0.969737</td>\n",
              "      <td>-0.998525</td>\n",
              "      <td>0.986848</td>\n",
              "      <td>0.982758</td>\n",
              "      <td>0.931549</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>101004113295</td>\n",
              "      <td>-0.136960</td>\n",
              "      <td>0.691521</td>\n",
              "      <td>-3.540846</td>\n",
              "      <td>-1.352687</td>\n",
              "      <td>1.299200</td>\n",
              "      <td>-0.141181</td>\n",
              "      <td>0.158119</td>\n",
              "      <td>2.410162</td>\n",
              "      <td>0.071449</td>\n",
              "      <td>...</td>\n",
              "      <td>0.086003</td>\n",
              "      <td>-0.998614</td>\n",
              "      <td>0.014076</td>\n",
              "      <td>-0.999995</td>\n",
              "      <td>-0.893147</td>\n",
              "      <td>0.982163</td>\n",
              "      <td>-0.999566</td>\n",
              "      <td>0.996798</td>\n",
              "      <td>0.977021</td>\n",
              "      <td>0.915342</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>101004113630</td>\n",
              "      <td>0.175361</td>\n",
              "      <td>0.668518</td>\n",
              "      <td>-3.556810</td>\n",
              "      <td>-1.355421</td>\n",
              "      <td>1.444425</td>\n",
              "      <td>0.603148</td>\n",
              "      <td>-1.361185</td>\n",
              "      <td>1.510217</td>\n",
              "      <td>-0.073560</td>\n",
              "      <td>...</td>\n",
              "      <td>0.120324</td>\n",
              "      <td>-0.999417</td>\n",
              "      <td>0.059866</td>\n",
              "      <td>-0.999934</td>\n",
              "      <td>-0.765923</td>\n",
              "      <td>0.960436</td>\n",
              "      <td>-0.998330</td>\n",
              "      <td>0.985888</td>\n",
              "      <td>0.973252</td>\n",
              "      <td>0.943457</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>101004113228</td>\n",
              "      <td>-0.649289</td>\n",
              "      <td>0.929046</td>\n",
              "      <td>-2.988562</td>\n",
              "      <td>-1.767200</td>\n",
              "      <td>-0.438132</td>\n",
              "      <td>-0.361119</td>\n",
              "      <td>0.010478</td>\n",
              "      <td>1.114518</td>\n",
              "      <td>-0.448996</td>\n",
              "      <td>...</td>\n",
              "      <td>0.183652</td>\n",
              "      <td>-0.997964</td>\n",
              "      <td>0.057766</td>\n",
              "      <td>-0.999915</td>\n",
              "      <td>-0.724165</td>\n",
              "      <td>0.798789</td>\n",
              "      <td>-0.999548</td>\n",
              "      <td>0.995305</td>\n",
              "      <td>0.995679</td>\n",
              "      <td>0.948751</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>101004113229</td>\n",
              "      <td>-0.649289</td>\n",
              "      <td>0.929046</td>\n",
              "      <td>-2.988562</td>\n",
              "      <td>-1.767200</td>\n",
              "      <td>-0.438132</td>\n",
              "      <td>-0.361119</td>\n",
              "      <td>0.010478</td>\n",
              "      <td>1.114518</td>\n",
              "      <td>-0.448996</td>\n",
              "      <td>...</td>\n",
              "      <td>0.183652</td>\n",
              "      <td>-0.997964</td>\n",
              "      <td>0.057766</td>\n",
              "      <td>-0.999915</td>\n",
              "      <td>-0.724165</td>\n",
              "      <td>0.798789</td>\n",
              "      <td>-0.999548</td>\n",
              "      <td>0.995305</td>\n",
              "      <td>0.995679</td>\n",
              "      <td>0.948751</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 769 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   case_enquiry_id  desc_cls_0  desc_cls_1  desc_cls_2  desc_cls_3  \\\n",
              "0     101004113559   -1.100319    0.180848   -3.067521   -2.449431   \n",
              "1     101004113295   -0.136960    0.691521   -3.540846   -1.352687   \n",
              "2     101004113630    0.175361    0.668518   -3.556810   -1.355421   \n",
              "3     101004113228   -0.649289    0.929046   -2.988562   -1.767200   \n",
              "4     101004113229   -0.649289    0.929046   -2.988562   -1.767200   \n",
              "\n",
              "   desc_cls_4  desc_cls_5  desc_cls_6  desc_cls_7  desc_cls_8  ...  \\\n",
              "0    0.048062    0.750774   -1.156688    1.701071   -1.121157  ...   \n",
              "1    1.299200   -0.141181    0.158119    2.410162    0.071449  ...   \n",
              "2    1.444425    0.603148   -1.361185    1.510217   -0.073560  ...   \n",
              "3   -0.438132   -0.361119    0.010478    1.114518   -0.448996  ...   \n",
              "4   -0.438132   -0.361119    0.010478    1.114518   -0.448996  ...   \n",
              "\n",
              "   code_pooled_118  code_pooled_119  code_pooled_120  code_pooled_121  \\\n",
              "0         0.121683        -0.998929         0.036228        -0.999963   \n",
              "1         0.086003        -0.998614         0.014076        -0.999995   \n",
              "2         0.120324        -0.999417         0.059866        -0.999934   \n",
              "3         0.183652        -0.997964         0.057766        -0.999915   \n",
              "4         0.183652        -0.997964         0.057766        -0.999915   \n",
              "\n",
              "   code_pooled_122  code_pooled_123  code_pooled_124  code_pooled_125  \\\n",
              "0        -0.742293         0.969737        -0.998525         0.986848   \n",
              "1        -0.893147         0.982163        -0.999566         0.996798   \n",
              "2        -0.765923         0.960436        -0.998330         0.985888   \n",
              "3        -0.724165         0.798789        -0.999548         0.995305   \n",
              "4        -0.724165         0.798789        -0.999548         0.995305   \n",
              "\n",
              "   code_pooled_126  code_pooled_127  \n",
              "0         0.982758         0.931549  \n",
              "1         0.977021         0.915342  \n",
              "2         0.973252         0.943457  \n",
              "3         0.995679         0.948751  \n",
              "4         0.995679         0.948751  \n",
              "\n",
              "[5 rows x 769 columns]"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2269940, 269)"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mydata.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "mydata = mydata.drop_duplicates(subset=['case_enquiry_id'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2269940, 269)"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mydata.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [],
      "source": [
        "#join them so we are left only with records that have mydata in both files\n",
        "new_mydata = mydata.merge(df, on='case_enquiry_id', how='inner')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [],
      "source": [
        "new_mydata = new_mydata.merge(cyclical_df, on='case_enquiry_id', how='inner')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(207064, 1039)"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "new_mydata = new_mydata.sort_values(by='case_enquiry_id')\n",
        "new_mydata.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [],
      "source": [
        "old_bin_edges = [0, 12, 24, 72, 168, 336, 672, 1344, 2688, 9999999]\n",
        "old_bin_labels = [\n",
        "                \"0-12 hours\",      # Less than half a day\n",
        "                \"12-24 hours\",     # Half to one day\n",
        "                \"1-3 days\",        # One to three days\n",
        "                \"4-7 days\",        # Four to seven days\n",
        "                \"1-2 weeks\",       # One to two weeks\n",
        "                \"2-4 weeks\",       # Two to four weeks\n",
        "                \"1-2 months\",      # One to two months\n",
        "                \"2-4 months\",      # Two to four months\n",
        "                \"4+ months\"        # More than four months\n",
        "            ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_time_bins(hour_interval, max_days, overflow_label=None):\n",
        "    # Calculate the number of hours for max_days\n",
        "    max_hours = max_days * 24\n",
        "    \n",
        "    # Generate bin edges\n",
        "    bin_edges = [i for i in range(0, max_hours + 1, hour_interval)]\n",
        "    bin_edges.append(1000000)  # for the overflow category\n",
        "    \n",
        "    # Generate bin labels\n",
        "    bin_labels = []\n",
        "    for i in range(len(bin_edges) - 1):\n",
        "        start_day = bin_edges[i] // 24\n",
        "        end_day = (bin_edges[i + 1] // 24) - 1  # -1 because it's inclusive\n",
        "        if end_day > start_day:\n",
        "            bin_labels.append(f\"{start_day}-{end_day} days\")\n",
        "        else:\n",
        "            bin_labels.append(f\"{start_day} days\")\n",
        "    \n",
        "    if overflow_label is not None:\n",
        "        bin_labels[-1] = overflow_label  # update the last label to the overflow label if specified\n",
        "\n",
        "    return bin_edges, bin_labels\n",
        "\n",
        "# Example usage\n",
        "hour_interval = 72\n",
        "max_days = 180\n",
        "bin_edges, bin_labels = generate_time_bins(hour_interval, max_days, \"180+ days\")\n",
        "bin_number = len(bin_labels)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "$prediction_timespans = [\n",
            "    \"0-2 days\" => [0, 72],\n",
            "    \"3-5 days\" => [72, 144],\n",
            "    \"6-8 days\" => [144, 216],\n",
            "    \"9-11 days\" => [216, 288],\n",
            "    \"12-14 days\" => [288, 360],\n",
            "    \"15-17 days\" => [360, 432],\n",
            "    \"18-20 days\" => [432, 504],\n",
            "    \"21-23 days\" => [504, 576],\n",
            "    \"24-26 days\" => [576, 648],\n",
            "    \"27-29 days\" => [648, 720],\n",
            "    \"30-32 days\" => [720, 792],\n",
            "    \"33-35 days\" => [792, 864],\n",
            "    \"36-38 days\" => [864, 936],\n",
            "    \"39-41 days\" => [936, 1008],\n",
            "    \"42-44 days\" => [1008, 1080],\n",
            "    \"45-47 days\" => [1080, 1152],\n",
            "    \"48-50 days\" => [1152, 1224],\n",
            "    \"51-53 days\" => [1224, 1296],\n",
            "    \"54-56 days\" => [1296, 1368],\n",
            "    \"57-59 days\" => [1368, 1440],\n",
            "    \"60-62 days\" => [1440, 1512],\n",
            "    \"63-65 days\" => [1512, 1584],\n",
            "    \"66-68 days\" => [1584, 1656],\n",
            "    \"69-71 days\" => [1656, 1728],\n",
            "    \"72-74 days\" => [1728, 1800],\n",
            "    \"75-77 days\" => [1800, 1872],\n",
            "    \"78-80 days\" => [1872, 1944],\n",
            "    \"81-83 days\" => [1944, 2016],\n",
            "    \"84-86 days\" => [2016, 2088],\n",
            "    \"87-89 days\" => [2088, 2160],\n",
            "    \"90-92 days\" => [2160, 2232],\n",
            "    \"93-95 days\" => [2232, 2304],\n",
            "    \"96-98 days\" => [2304, 2376],\n",
            "    \"99-101 days\" => [2376, 2448],\n",
            "    \"102-104 days\" => [2448, 2520],\n",
            "    \"105-107 days\" => [2520, 2592],\n",
            "    \"108-110 days\" => [2592, 2664],\n",
            "    \"111-113 days\" => [2664, 2736],\n",
            "    \"114-116 days\" => [2736, 2808],\n",
            "    \"117-119 days\" => [2808, 2880],\n",
            "    \"120-122 days\" => [2880, 2952],\n",
            "    \"123-125 days\" => [2952, 3024],\n",
            "    \"126-128 days\" => [3024, 3096],\n",
            "    \"129-131 days\" => [3096, 3168],\n",
            "    \"132-134 days\" => [3168, 3240],\n",
            "    \"135-137 days\" => [3240, 3312],\n",
            "    \"138-140 days\" => [3312, 3384],\n",
            "    \"141-143 days\" => [3384, 3456],\n",
            "    \"144-146 days\" => [3456, 3528],\n",
            "    \"147-149 days\" => [3528, 3600],\n",
            "    \"150-152 days\" => [3600, 3672],\n",
            "    \"153-155 days\" => [3672, 3744],\n",
            "    \"156-158 days\" => [3744, 3816],\n",
            "    \"159-161 days\" => [3816, 3888],\n",
            "    \"162-164 days\" => [3888, 3960],\n",
            "    \"165-167 days\" => [3960, 4032],\n",
            "    \"168-170 days\" => [4032, 4104],\n",
            "    \"171-173 days\" => [4104, 4176],\n",
            "    \"174-176 days\" => [4176, 4248],\n",
            "    \"177-179 days\" => [4248, 4320],\n",
            "    \"180+ days\" => [4320, 1000000],\n",
            "];\n"
          ]
        }
      ],
      "source": [
        "php_array = \"$prediction_timespans = [\\n\"\n",
        "for i, label in enumerate(bin_labels):\n",
        "    try:\n",
        "        new_line = f'    \"{label}\" => [{bin_edges[i]}, {bin_edges[i+1]}],\\n'\n",
        "        php_array += new_line\n",
        "    except IndexError:\n",
        "        continue\n",
        "php_array += \"];\"\n",
        "\n",
        "print(php_array)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "df, y = kerasNLP_model.split_data(new_mydata, bin_edges=bin_edges, bin_labels=bin_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [],
      "source": [
        "#cast all columns that are type bool to float\n",
        "for col in df.columns:\n",
        "    if df[col].dtype == 'bool':\n",
        "        df[col] = df[col].astype('float64')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(207064, 1036)\n",
            "(207064,)\n"
          ]
        }
      ],
      "source": [
        "#list the number of rows in X and y\n",
        "print(df.shape)\n",
        "print(y.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [],
      "source": [
        "#best_model, best_hyperparameters = kerasNLP_model.tune_model(df, y, '/home/briarmoss/Documents/Boston_311/models/tuning')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [],
      "source": [
        "#define hyperparameters\n",
        "from kerastuner import HyperParameters\n",
        "\n",
        "#set constants\n",
        "start_nodes = 2048  \n",
        "end_nodes = 128\n",
        "#l2_0 = 0.00001\n",
        "#learning_rate = 7.5842e-05\n",
        "l2_0 = 0.001\n",
        "learning_rate = 0.0001\n",
        "\n",
        "\n",
        "hp = HyperParameters()\n",
        "hp.Fixed('start_nodes', start_nodes)\n",
        "hp.Fixed('end_nodes', end_nodes)\n",
        "hp.Fixed('l2_0', l2_0)\n",
        "hp.Fixed('learning_rate', learning_rate)\n",
        "hp.Fixed('final_layer', bin_number)\n",
        "hp.Fixed('final_activation', 'softmax')\n",
        "kerasNLP_model.best_hyperparameters = hp\n",
        "\n",
        "\n",
        "#parameters for linear regression\n",
        "linear='''\n",
        "hp = HyperParameters()\n",
        "hp.Fixed('start_nodes', start_nodes)\n",
        "hp.Fixed('end_nodes', end_nodes)\n",
        "hp.Fixed('l2_0', l2_0)\n",
        "hp.Fixed('learning_rate', learning_rate)\n",
        "hp.Fixed('final_layer', 1)\n",
        "hp.Fixed('final_activation', 'linear')\n",
        "kerasNLP_model.best_hyperparameters = hp\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [],
      "source": [
        "#free all unused dataframes\n",
        "try :\n",
        "    df_to_delete = [X, new_mydata, is_numeric, mydata, merged_data]\n",
        "    df_to_delete.extend([df_desc_cls, df_desc_pooled, df_name_cls, df_name_pooled, df_code_cls, df_code_pooled])\n",
        "except NameError:\n",
        "    pass\n",
        "try :\n",
        "    for data_frame in df_to_delete:\n",
        "        try:\n",
        "            del data_frame\n",
        "        #if the dataframe doesn't exist, pass\n",
        "        except NameError:\n",
        "            pass\n",
        "except NameError:\n",
        "    pass\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "47"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import gc\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [],
      "source": [
        "import logging\n",
        "\n",
        "# Suppress specific TensorFlow log messages\n",
        "logging.getLogger('tensorflow').addFilter(\n",
        "    lambda record: \"ROCm Fusion is enabled\" not in record.msg\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting Training at 2023-10-23 02:35:45.425216\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 2048)              2123776   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1024)              2098176   \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 512)               524800    \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 256)               131328    \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 128)               32896     \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 61)                7869      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4918845 (18.76 MB)\n",
            "Trainable params: 4918845 (18.76 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n",
            "<class 'pandas.core.frame.DataFrame'> (165651, 61)\n",
            "<class 'pandas.core.frame.DataFrame'> (41413, 61)\n",
            "run fit\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-10-23 02:35:51.638334: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 1372915488 exceeds 10% of free system memory.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "1295/1295 [==============================] - ETA: 0s - loss: 1.0732 - accuracy: 0.7652 - top_k_categorical_accuracy: 0.8381"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-10-23 02:36:39.865840: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 343230944 exceeds 10% of free system memory.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1295/1295 [==============================] - 48s 37ms/step - loss: 1.0732 - accuracy: 0.7652 - top_k_categorical_accuracy: 0.8381 - val_loss: 0.9666 - val_accuracy: 0.7788 - val_top_k_categorical_accuracy: 0.8477\n",
            "Epoch 2/300\n",
            "1295/1295 [==============================] - 46s 36ms/step - loss: 0.9461 - accuracy: 0.7817 - top_k_categorical_accuracy: 0.8507 - val_loss: 0.9281 - val_accuracy: 0.7823 - val_top_k_categorical_accuracy: 0.8512\n",
            "Epoch 3/300\n",
            "1295/1295 [==============================] - 46s 36ms/step - loss: 0.9199 - accuracy: 0.7842 - top_k_categorical_accuracy: 0.8525 - val_loss: 0.9224 - val_accuracy: 0.7814 - val_top_k_categorical_accuracy: 0.8521\n",
            "Epoch 4/300\n",
            "1295/1295 [==============================] - 46s 36ms/step - loss: 0.9046 - accuracy: 0.7854 - top_k_categorical_accuracy: 0.8537 - val_loss: 0.9095 - val_accuracy: 0.7840 - val_top_k_categorical_accuracy: 0.8534\n",
            "Epoch 5/300\n",
            "1295/1295 [==============================] - 46s 36ms/step - loss: 0.8934 - accuracy: 0.7865 - top_k_categorical_accuracy: 0.8544 - val_loss: 0.8916 - val_accuracy: 0.7864 - val_top_k_categorical_accuracy: 0.8544\n",
            "Epoch 6/300\n",
            "1295/1295 [==============================] - 46s 36ms/step - loss: 0.8855 - accuracy: 0.7867 - top_k_categorical_accuracy: 0.8550 - val_loss: 0.8964 - val_accuracy: 0.7835 - val_top_k_categorical_accuracy: 0.8511\n",
            "Epoch 7/300\n",
            "1295/1295 [==============================] - 46s 36ms/step - loss: 0.8774 - accuracy: 0.7874 - top_k_categorical_accuracy: 0.8556 - val_loss: 0.8709 - val_accuracy: 0.7867 - val_top_k_categorical_accuracy: 0.8560\n",
            "Epoch 8/300\n",
            "1295/1295 [==============================] - 46s 36ms/step - loss: 0.8696 - accuracy: 0.7881 - top_k_categorical_accuracy: 0.8561 - val_loss: 0.8654 - val_accuracy: 0.7870 - val_top_k_categorical_accuracy: 0.8563\n",
            "Epoch 9/300\n",
            "1295/1295 [==============================] - 46s 36ms/step - loss: 0.8635 - accuracy: 0.7887 - top_k_categorical_accuracy: 0.8564 - val_loss: 0.8682 - val_accuracy: 0.7838 - val_top_k_categorical_accuracy: 0.8552\n",
            "Epoch 10/300\n",
            "1295/1295 [==============================] - 46s 36ms/step - loss: 0.8549 - accuracy: 0.7888 - top_k_categorical_accuracy: 0.8573 - val_loss: 0.8511 - val_accuracy: 0.7880 - val_top_k_categorical_accuracy: 0.8570\n",
            "Epoch 11/300\n",
            "1295/1295 [==============================] - 46s 36ms/step - loss: 0.8474 - accuracy: 0.7895 - top_k_categorical_accuracy: 0.8579 - val_loss: 0.8462 - val_accuracy: 0.7879 - val_top_k_categorical_accuracy: 0.8584\n",
            "Epoch 12/300\n",
            "1295/1295 [==============================] - 46s 36ms/step - loss: 0.8411 - accuracy: 0.7900 - top_k_categorical_accuracy: 0.8584 - val_loss: 0.8334 - val_accuracy: 0.7880 - val_top_k_categorical_accuracy: 0.8599\n",
            "Epoch 13/300\n",
            "1295/1295 [==============================] - 46s 36ms/step - loss: 0.8319 - accuracy: 0.7903 - top_k_categorical_accuracy: 0.8597 - val_loss: 0.8275 - val_accuracy: 0.7888 - val_top_k_categorical_accuracy: 0.8603\n",
            "Epoch 14/300\n",
            "1295/1295 [==============================] - 46s 36ms/step - loss: 0.8258 - accuracy: 0.7904 - top_k_categorical_accuracy: 0.8601 - val_loss: 0.8217 - val_accuracy: 0.7890 - val_top_k_categorical_accuracy: 0.8607\n",
            "Epoch 15/300\n",
            "1295/1295 [==============================] - 46s 36ms/step - loss: 0.8179 - accuracy: 0.7915 - top_k_categorical_accuracy: 0.8605 - val_loss: 0.8086 - val_accuracy: 0.7903 - val_top_k_categorical_accuracy: 0.8627\n",
            "Epoch 16/300\n",
            "1295/1295 [==============================] - 46s 36ms/step - loss: 0.8125 - accuracy: 0.7918 - top_k_categorical_accuracy: 0.8620 - val_loss: 0.8070 - val_accuracy: 0.7903 - val_top_k_categorical_accuracy: 0.8635\n",
            "Epoch 17/300\n",
            "1295/1295 [==============================] - 46s 36ms/step - loss: 0.8047 - accuracy: 0.7924 - top_k_categorical_accuracy: 0.8629 - val_loss: 0.7956 - val_accuracy: 0.7920 - val_top_k_categorical_accuracy: 0.8647\n",
            "Epoch 18/300\n",
            "1295/1295 [==============================] - 46s 36ms/step - loss: 0.8001 - accuracy: 0.7932 - top_k_categorical_accuracy: 0.8637 - val_loss: 0.7956 - val_accuracy: 0.7910 - val_top_k_categorical_accuracy: 0.8652\n",
            "Epoch 19/300\n",
            "1295/1295 [==============================] - 47s 36ms/step - loss: 0.7927 - accuracy: 0.7939 - top_k_categorical_accuracy: 0.8653 - val_loss: 0.7851 - val_accuracy: 0.7932 - val_top_k_categorical_accuracy: 0.8666\n",
            "Epoch 20/300\n",
            "1295/1295 [==============================] - 47s 36ms/step - loss: 0.7869 - accuracy: 0.7940 - top_k_categorical_accuracy: 0.8662 - val_loss: 0.7784 - val_accuracy: 0.7929 - val_top_k_categorical_accuracy: 0.8679\n",
            "Epoch 21/300\n",
            "1295/1295 [==============================] - 46s 36ms/step - loss: 0.7812 - accuracy: 0.7951 - top_k_categorical_accuracy: 0.8668 - val_loss: 0.7683 - val_accuracy: 0.7952 - val_top_k_categorical_accuracy: 0.8686\n",
            "Epoch 22/300\n",
            "1295/1295 [==============================] - 46s 36ms/step - loss: 0.7755 - accuracy: 0.7960 - top_k_categorical_accuracy: 0.8676 - val_loss: 0.7693 - val_accuracy: 0.7937 - val_top_k_categorical_accuracy: 0.8703\n",
            "Epoch 23/300\n",
            "1295/1295 [==============================] - 46s 36ms/step - loss: 0.7693 - accuracy: 0.7969 - top_k_categorical_accuracy: 0.8685 - val_loss: 0.7614 - val_accuracy: 0.7958 - val_top_k_categorical_accuracy: 0.8701\n",
            "Epoch 24/300\n",
            "1295/1295 [==============================] - 46s 36ms/step - loss: 0.7634 - accuracy: 0.7978 - top_k_categorical_accuracy: 0.8698 - val_loss: 0.7517 - val_accuracy: 0.7982 - val_top_k_categorical_accuracy: 0.8745\n",
            "Epoch 25/300\n",
            "1295/1295 [==============================] - 46s 36ms/step - loss: 0.7561 - accuracy: 0.7991 - top_k_categorical_accuracy: 0.8721 - val_loss: 0.7579 - val_accuracy: 0.7979 - val_top_k_categorical_accuracy: 0.8758\n",
            "Epoch 26/300\n",
            "1295/1295 [==============================] - 46s 36ms/step - loss: 0.7511 - accuracy: 0.7995 - top_k_categorical_accuracy: 0.8728 - val_loss: 0.7442 - val_accuracy: 0.7980 - val_top_k_categorical_accuracy: 0.8740\n",
            "Epoch 27/300\n",
            "1295/1295 [==============================] - 46s 36ms/step - loss: 0.7451 - accuracy: 0.8005 - top_k_categorical_accuracy: 0.8737 - val_loss: 0.7307 - val_accuracy: 0.8006 - val_top_k_categorical_accuracy: 0.8776\n",
            "Epoch 28/300\n",
            "1295/1295 [==============================] - 46s 36ms/step - loss: 0.7383 - accuracy: 0.8014 - top_k_categorical_accuracy: 0.8749 - val_loss: 0.7349 - val_accuracy: 0.8015 - val_top_k_categorical_accuracy: 0.8763\n",
            "Epoch 29/300\n",
            "1295/1295 [==============================] - 46s 36ms/step - loss: 0.7309 - accuracy: 0.8032 - top_k_categorical_accuracy: 0.8768 - val_loss: 0.7121 - val_accuracy: 0.8068 - val_top_k_categorical_accuracy: 0.8823\n",
            "Epoch 30/300\n",
            "1295/1295 [==============================] - 46s 36ms/step - loss: 0.7238 - accuracy: 0.8047 - top_k_categorical_accuracy: 0.8777 - val_loss: 0.7064 - val_accuracy: 0.8077 - val_top_k_categorical_accuracy: 0.8840\n",
            "Epoch 31/300\n",
            "1295/1295 [==============================] - 46s 36ms/step - loss: 0.7181 - accuracy: 0.8051 - top_k_categorical_accuracy: 0.8792 - val_loss: 0.6998 - val_accuracy: 0.8085 - val_top_k_categorical_accuracy: 0.8839\n",
            "Epoch 32/300\n",
            "1295/1295 [==============================] - 46s 36ms/step - loss: 0.7107 - accuracy: 0.8073 - top_k_categorical_accuracy: 0.8808 - val_loss: 0.7119 - val_accuracy: 0.8093 - val_top_k_categorical_accuracy: 0.8844\n",
            "Epoch 33/300\n",
            "1295/1295 [==============================] - 46s 36ms/step - loss: 0.7025 - accuracy: 0.8089 - top_k_categorical_accuracy: 0.8828 - val_loss: 0.6872 - val_accuracy: 0.8093 - val_top_k_categorical_accuracy: 0.8852\n",
            "Epoch 34/300\n",
            "1295/1295 [==============================] - 46s 36ms/step - loss: 0.6972 - accuracy: 0.8092 - top_k_categorical_accuracy: 0.8836 - val_loss: 0.6894 - val_accuracy: 0.8131 - val_top_k_categorical_accuracy: 0.8886\n",
            "Epoch 35/300\n",
            "1295/1295 [==============================] - 46s 36ms/step - loss: 0.6891 - accuracy: 0.8121 - top_k_categorical_accuracy: 0.8856 - val_loss: 0.6708 - val_accuracy: 0.8148 - val_top_k_categorical_accuracy: 0.8924\n",
            "Epoch 36/300\n",
            "1295/1295 [==============================] - 46s 36ms/step - loss: 0.6802 - accuracy: 0.8137 - top_k_categorical_accuracy: 0.8875 - val_loss: 0.6648 - val_accuracy: 0.8157 - val_top_k_categorical_accuracy: 0.8905\n",
            "Epoch 37/300\n",
            "1295/1295 [==============================] - 46s 36ms/step - loss: 0.6761 - accuracy: 0.8149 - top_k_categorical_accuracy: 0.8884 - val_loss: 0.6516 - val_accuracy: 0.8213 - val_top_k_categorical_accuracy: 0.8964\n",
            "Epoch 38/300\n",
            "1295/1295 [==============================] - 46s 36ms/step - loss: 0.6664 - accuracy: 0.8169 - top_k_categorical_accuracy: 0.8907 - val_loss: 0.6617 - val_accuracy: 0.8191 - val_top_k_categorical_accuracy: 0.8921\n",
            "Epoch 39/300\n",
            "1295/1295 [==============================] - 46s 36ms/step - loss: 0.6595 - accuracy: 0.8184 - top_k_categorical_accuracy: 0.8918 - val_loss: 0.6464 - val_accuracy: 0.8190 - val_top_k_categorical_accuracy: 0.8964\n",
            "Epoch 40/300\n",
            "1295/1295 [==============================] - 46s 36ms/step - loss: 0.6494 - accuracy: 0.8204 - top_k_categorical_accuracy: 0.8939 - val_loss: 0.6581 - val_accuracy: 0.8164 - val_top_k_categorical_accuracy: 0.8939\n",
            "Epoch 41/300\n",
            "1295/1295 [==============================] - 46s 36ms/step - loss: 0.6415 - accuracy: 0.8233 - top_k_categorical_accuracy: 0.8964 - val_loss: 0.6278 - val_accuracy: 0.8237 - val_top_k_categorical_accuracy: 0.9007\n",
            "Epoch 42/300\n",
            "1295/1295 [==============================] - 46s 36ms/step - loss: 0.6323 - accuracy: 0.8249 - top_k_categorical_accuracy: 0.8982 - val_loss: 0.6103 - val_accuracy: 0.8279 - val_top_k_categorical_accuracy: 0.9041\n",
            "Epoch 43/300\n",
            "1295/1295 [==============================] - 46s 36ms/step - loss: 0.6258 - accuracy: 0.8266 - top_k_categorical_accuracy: 0.8995 - val_loss: 0.6027 - val_accuracy: 0.8316 - val_top_k_categorical_accuracy: 0.9059\n",
            "Epoch 44/300\n",
            "1295/1295 [==============================] - 46s 36ms/step - loss: 0.6136 - accuracy: 0.8305 - top_k_categorical_accuracy: 0.9024 - val_loss: 0.5908 - val_accuracy: 0.8337 - val_top_k_categorical_accuracy: 0.9080\n",
            "Epoch 45/300\n",
            "1295/1295 [==============================] - 46s 36ms/step - loss: 0.6060 - accuracy: 0.8320 - top_k_categorical_accuracy: 0.9045 - val_loss: 0.5961 - val_accuracy: 0.8364 - val_top_k_categorical_accuracy: 0.9119\n",
            "Epoch 46/300\n",
            "1295/1295 [==============================] - 46s 36ms/step - loss: 0.5989 - accuracy: 0.8341 - top_k_categorical_accuracy: 0.9058 - val_loss: 0.5904 - val_accuracy: 0.8347 - val_top_k_categorical_accuracy: 0.9065\n",
            "Epoch 47/300\n",
            "1295/1295 [==============================] - 47s 36ms/step - loss: 0.5886 - accuracy: 0.8365 - top_k_categorical_accuracy: 0.9081 - val_loss: 0.5660 - val_accuracy: 0.8446 - val_top_k_categorical_accuracy: 0.9136\n",
            "Epoch 48/300\n",
            "1295/1295 [==============================] - 46s 36ms/step - loss: 0.5779 - accuracy: 0.8392 - top_k_categorical_accuracy: 0.9103 - val_loss: 0.5469 - val_accuracy: 0.8445 - val_top_k_categorical_accuracy: 0.9178\n",
            "Epoch 49/300\n",
            "1295/1295 [==============================] - 46s 36ms/step - loss: 0.5706 - accuracy: 0.8415 - top_k_categorical_accuracy: 0.9119 - val_loss: 0.5518 - val_accuracy: 0.8467 - val_top_k_categorical_accuracy: 0.9189\n",
            "Epoch 50/300\n",
            "1295/1295 [==============================] - 46s 36ms/step - loss: 0.5606 - accuracy: 0.8436 - top_k_categorical_accuracy: 0.9139 - val_loss: 0.5457 - val_accuracy: 0.8456 - val_top_k_categorical_accuracy: 0.9171\n",
            "Epoch 51/300\n",
            "1295/1295 [==============================] - 46s 36ms/step - loss: 0.5512 - accuracy: 0.8469 - top_k_categorical_accuracy: 0.9159 - val_loss: 0.5413 - val_accuracy: 0.8482 - val_top_k_categorical_accuracy: 0.9194\n",
            "Epoch 52/300\n",
            "1295/1295 [==============================] - 46s 36ms/step - loss: 0.5437 - accuracy: 0.8490 - top_k_categorical_accuracy: 0.9179 - val_loss: 0.5243 - val_accuracy: 0.8567 - val_top_k_categorical_accuracy: 0.9218\n",
            "Epoch 53/300\n",
            "1295/1295 [==============================] - 46s 36ms/step - loss: 0.5340 - accuracy: 0.8514 - top_k_categorical_accuracy: 0.9200 - val_loss: 0.5065 - val_accuracy: 0.8580 - val_top_k_categorical_accuracy: 0.9276\n",
            "Epoch 54/300\n",
            "1295/1295 [==============================] - 46s 36ms/step - loss: 0.5238 - accuracy: 0.8550 - top_k_categorical_accuracy: 0.9222 - val_loss: 0.5082 - val_accuracy: 0.8600 - val_top_k_categorical_accuracy: 0.9276\n",
            "Epoch 55/300\n",
            "1295/1295 [==============================] - 46s 36ms/step - loss: 0.5167 - accuracy: 0.8566 - top_k_categorical_accuracy: 0.9231 - val_loss: 0.4890 - val_accuracy: 0.8653 - val_top_k_categorical_accuracy: 0.9298\n",
            "Epoch 56/300\n",
            "1295/1295 [==============================] - 46s 36ms/step - loss: 0.5056 - accuracy: 0.8597 - top_k_categorical_accuracy: 0.9255 - val_loss: 0.4863 - val_accuracy: 0.8656 - val_top_k_categorical_accuracy: 0.9315\n",
            "Epoch 57/300\n",
            "1295/1295 [==============================] - 46s 36ms/step - loss: 0.4992 - accuracy: 0.8617 - top_k_categorical_accuracy: 0.9273 - val_loss: 0.4779 - val_accuracy: 0.8691 - val_top_k_categorical_accuracy: 0.9334\n",
            "Epoch 58/300\n",
            "1295/1295 [==============================] - 46s 36ms/step - loss: 0.4909 - accuracy: 0.8645 - top_k_categorical_accuracy: 0.9288 - val_loss: 0.4688 - val_accuracy: 0.8702 - val_top_k_categorical_accuracy: 0.9358\n",
            "Epoch 59/300\n",
            "1295/1295 [==============================] - 46s 36ms/step - loss: 0.4800 - accuracy: 0.8670 - top_k_categorical_accuracy: 0.9310 - val_loss: 0.4681 - val_accuracy: 0.8688 - val_top_k_categorical_accuracy: 0.9332\n",
            "Epoch 60/300\n",
            "1295/1295 [==============================] - 46s 36ms/step - loss: 0.4748 - accuracy: 0.8690 - top_k_categorical_accuracy: 0.9322 - val_loss: 0.4867 - val_accuracy: 0.8664 - val_top_k_categorical_accuracy: 0.9310\n",
            "Epoch 61/300\n",
            "1295/1295 [==============================] - 46s 36ms/step - loss: 0.4669 - accuracy: 0.8709 - top_k_categorical_accuracy: 0.9337 - val_loss: 0.4487 - val_accuracy: 0.8750 - val_top_k_categorical_accuracy: 0.9383\n",
            "Epoch 62/300\n",
            "1295/1295 [==============================] - 46s 36ms/step - loss: 0.4581 - accuracy: 0.8739 - top_k_categorical_accuracy: 0.9362 - val_loss: 0.4596 - val_accuracy: 0.8702 - val_top_k_categorical_accuracy: 0.9381\n",
            "Epoch 63/300\n",
            "1295/1295 [==============================] - 46s 36ms/step - loss: 0.4497 - accuracy: 0.8764 - top_k_categorical_accuracy: 0.9372 - val_loss: 0.4311 - val_accuracy: 0.8819 - val_top_k_categorical_accuracy: 0.9421\n",
            "Epoch 64/300\n",
            "1295/1295 [==============================] - 46s 36ms/step - loss: 0.4434 - accuracy: 0.8783 - top_k_categorical_accuracy: 0.9383 - val_loss: 0.4256 - val_accuracy: 0.8836 - val_top_k_categorical_accuracy: 0.9446\n",
            "Epoch 65/300\n",
            "1295/1295 [==============================] - 46s 36ms/step - loss: 0.4327 - accuracy: 0.8820 - top_k_categorical_accuracy: 0.9408 - val_loss: 0.4273 - val_accuracy: 0.8850 - val_top_k_categorical_accuracy: 0.9437\n",
            "Epoch 66/300\n",
            "1295/1295 [==============================] - 46s 36ms/step - loss: 0.4276 - accuracy: 0.8832 - top_k_categorical_accuracy: 0.9413 - val_loss: 0.3958 - val_accuracy: 0.8937 - val_top_k_categorical_accuracy: 0.9478\n",
            "Epoch 67/300\n",
            "1295/1295 [==============================] - 46s 36ms/step - loss: 0.4192 - accuracy: 0.8852 - top_k_categorical_accuracy: 0.9433 - val_loss: 0.3953 - val_accuracy: 0.8917 - val_top_k_categorical_accuracy: 0.9486\n",
            "Epoch 68/300\n",
            "1295/1295 [==============================] - 46s 36ms/step - loss: 0.4125 - accuracy: 0.8873 - top_k_categorical_accuracy: 0.9443 - val_loss: 0.3814 - val_accuracy: 0.8970 - val_top_k_categorical_accuracy: 0.9502\n",
            "Epoch 69/300\n",
            "1295/1295 [==============================] - 46s 36ms/step - loss: 0.4062 - accuracy: 0.8896 - top_k_categorical_accuracy: 0.9458 - val_loss: 0.3862 - val_accuracy: 0.8961 - val_top_k_categorical_accuracy: 0.9495\n",
            "Epoch 70/300\n",
            "1295/1295 [==============================] - 46s 36ms/step - loss: 0.4009 - accuracy: 0.8904 - top_k_categorical_accuracy: 0.9466 - val_loss: 0.4027 - val_accuracy: 0.8874 - val_top_k_categorical_accuracy: 0.9480\n",
            "Epoch 71/300\n",
            "1295/1295 [==============================] - 46s 36ms/step - loss: 0.3911 - accuracy: 0.8943 - top_k_categorical_accuracy: 0.9487 - val_loss: 0.3776 - val_accuracy: 0.8965 - val_top_k_categorical_accuracy: 0.9522\n",
            "Epoch 72/300\n",
            "1295/1295 [==============================] - 46s 36ms/step - loss: 0.3894 - accuracy: 0.8946 - top_k_categorical_accuracy: 0.9493 - val_loss: 0.3695 - val_accuracy: 0.9018 - val_top_k_categorical_accuracy: 0.9533\n",
            "Epoch 73/300\n",
            "1295/1295 [==============================] - 46s 36ms/step - loss: 0.3811 - accuracy: 0.8972 - top_k_categorical_accuracy: 0.9500 - val_loss: 0.3599 - val_accuracy: 0.9087 - val_top_k_categorical_accuracy: 0.9559\n",
            "Epoch 74/300\n",
            "1295/1295 [==============================] - 46s 36ms/step - loss: 0.3743 - accuracy: 0.8989 - top_k_categorical_accuracy: 0.9511 - val_loss: 0.3545 - val_accuracy: 0.9067 - val_top_k_categorical_accuracy: 0.9561\n",
            "Epoch 75/300\n",
            "1295/1295 [==============================] - 46s 36ms/step - loss: 0.3689 - accuracy: 0.9012 - top_k_categorical_accuracy: 0.9525 - val_loss: 0.3710 - val_accuracy: 0.8992 - val_top_k_categorical_accuracy: 0.9548\n",
            "Epoch 76/300\n",
            "1295/1295 [==============================] - 46s 36ms/step - loss: 0.3640 - accuracy: 0.9029 - top_k_categorical_accuracy: 0.9538 - val_loss: 0.3428 - val_accuracy: 0.9094 - val_top_k_categorical_accuracy: 0.9587\n",
            "Epoch 77/300\n",
            "1295/1295 [==============================] - 46s 36ms/step - loss: 0.3574 - accuracy: 0.9048 - top_k_categorical_accuracy: 0.9547 - val_loss: 0.3448 - val_accuracy: 0.9107 - val_top_k_categorical_accuracy: 0.9577\n",
            "Epoch 78/300\n",
            "1295/1295 [==============================] - 46s 36ms/step - loss: 0.3539 - accuracy: 0.9053 - top_k_categorical_accuracy: 0.9555 - val_loss: 0.3236 - val_accuracy: 0.9195 - val_top_k_categorical_accuracy: 0.9604\n",
            "Epoch 79/300\n",
            "1295/1295 [==============================] - 46s 36ms/step - loss: 0.3475 - accuracy: 0.9073 - top_k_categorical_accuracy: 0.9561 - val_loss: 0.3454 - val_accuracy: 0.9073 - val_top_k_categorical_accuracy: 0.9571\n",
            "Epoch 80/300\n",
            "1295/1295 [==============================] - 46s 36ms/step - loss: 0.3445 - accuracy: 0.9086 - top_k_categorical_accuracy: 0.9574 - val_loss: 0.3405 - val_accuracy: 0.9074 - val_top_k_categorical_accuracy: 0.9598\n",
            "Epoch 81/300\n",
            "1295/1295 [==============================] - 46s 36ms/step - loss: 0.3378 - accuracy: 0.9105 - top_k_categorical_accuracy: 0.9578 - val_loss: 0.3135 - val_accuracy: 0.9181 - val_top_k_categorical_accuracy: 0.9621\n",
            "Epoch 82/300\n",
            "1295/1295 [==============================] - 46s 36ms/step - loss: 0.3341 - accuracy: 0.9119 - top_k_categorical_accuracy: 0.9588 - val_loss: 0.3180 - val_accuracy: 0.9172 - val_top_k_categorical_accuracy: 0.9619\n",
            "Epoch 83/300\n",
            "1295/1295 [==============================] - 46s 36ms/step - loss: 0.3276 - accuracy: 0.9144 - top_k_categorical_accuracy: 0.9599 - val_loss: 0.3277 - val_accuracy: 0.9115 - val_top_k_categorical_accuracy: 0.9617\n",
            "Epoch 84/300\n",
            "1295/1295 [==============================] - 46s 36ms/step - loss: 0.3249 - accuracy: 0.9146 - top_k_categorical_accuracy: 0.9609 - val_loss: 0.3128 - val_accuracy: 0.9201 - val_top_k_categorical_accuracy: 0.9630\n",
            "Epoch 85/300\n",
            "1295/1295 [==============================] - 46s 36ms/step - loss: 0.3215 - accuracy: 0.9164 - top_k_categorical_accuracy: 0.9609 - val_loss: 0.3166 - val_accuracy: 0.9158 - val_top_k_categorical_accuracy: 0.9623\n",
            "Epoch 86/300\n",
            "1295/1295 [==============================] - 46s 36ms/step - loss: 0.3170 - accuracy: 0.9171 - top_k_categorical_accuracy: 0.9622 - val_loss: 0.2887 - val_accuracy: 0.9277 - val_top_k_categorical_accuracy: 0.9673\n",
            "Epoch 87/300\n",
            "1295/1295 [==============================] - 46s 36ms/step - loss: 0.3118 - accuracy: 0.9187 - top_k_categorical_accuracy: 0.9630 - val_loss: 0.2969 - val_accuracy: 0.9253 - val_top_k_categorical_accuracy: 0.9659\n",
            "Epoch 88/300\n",
            "1295/1295 [==============================] - 46s 36ms/step - loss: 0.3085 - accuracy: 0.9198 - top_k_categorical_accuracy: 0.9636 - val_loss: 0.2945 - val_accuracy: 0.9247 - val_top_k_categorical_accuracy: 0.9663\n",
            "Epoch 89/300\n",
            "1295/1295 [==============================] - 46s 36ms/step - loss: 0.3072 - accuracy: 0.9199 - top_k_categorical_accuracy: 0.9634 - val_loss: 0.3062 - val_accuracy: 0.9208 - val_top_k_categorical_accuracy: 0.9648\n",
            "Epoch 90/300\n",
            "1295/1295 [==============================] - 46s 36ms/step - loss: 0.3019 - accuracy: 0.9220 - top_k_categorical_accuracy: 0.9644 - val_loss: 0.2778 - val_accuracy: 0.9316 - val_top_k_categorical_accuracy: 0.9699\n",
            "Epoch 91/300\n",
            "1295/1295 [==============================] - 46s 36ms/step - loss: 0.2999 - accuracy: 0.9226 - top_k_categorical_accuracy: 0.9651 - val_loss: 0.2864 - val_accuracy: 0.9271 - val_top_k_categorical_accuracy: 0.9667\n",
            "Epoch 92/300\n",
            "1295/1295 [==============================] - 46s 36ms/step - loss: 0.2976 - accuracy: 0.9235 - top_k_categorical_accuracy: 0.9653 - val_loss: 0.2866 - val_accuracy: 0.9257 - val_top_k_categorical_accuracy: 0.9671\n",
            "Epoch 93/300\n",
            "1295/1295 [==============================] - 46s 36ms/step - loss: 0.2911 - accuracy: 0.9259 - top_k_categorical_accuracy: 0.9665 - val_loss: 0.3013 - val_accuracy: 0.9231 - val_top_k_categorical_accuracy: 0.9668\n",
            "Epoch 94/300\n",
            "1295/1295 [==============================] - 46s 36ms/step - loss: 0.2863 - accuracy: 0.9272 - top_k_categorical_accuracy: 0.9671 - val_loss: 0.2734 - val_accuracy: 0.9308 - val_top_k_categorical_accuracy: 0.9688\n",
            "Epoch 95/300\n",
            "1295/1295 [==============================] - 46s 36ms/step - loss: 0.2835 - accuracy: 0.9278 - top_k_categorical_accuracy: 0.9676 - val_loss: 0.2655 - val_accuracy: 0.9337 - val_top_k_categorical_accuracy: 0.9696\n",
            "Epoch 96/300\n",
            "1295/1295 [==============================] - 46s 36ms/step - loss: 0.2837 - accuracy: 0.9281 - top_k_categorical_accuracy: 0.9676 - val_loss: 0.2653 - val_accuracy: 0.9347 - val_top_k_categorical_accuracy: 0.9703\n",
            "Epoch 97/300\n",
            "1295/1295 [==============================] - 46s 36ms/step - loss: 0.2791 - accuracy: 0.9293 - top_k_categorical_accuracy: 0.9679 - val_loss: 0.2927 - val_accuracy: 0.9258 - val_top_k_categorical_accuracy: 0.9669\n",
            "Epoch 98/300\n",
            "1295/1295 [==============================] - 46s 36ms/step - loss: 0.2796 - accuracy: 0.9291 - top_k_categorical_accuracy: 0.9683 - val_loss: 0.2549 - val_accuracy: 0.9392 - val_top_k_categorical_accuracy: 0.9723\n",
            "Epoch 99/300\n",
            "1295/1295 [==============================] - 46s 36ms/step - loss: 0.2735 - accuracy: 0.9317 - top_k_categorical_accuracy: 0.9697 - val_loss: 0.2470 - val_accuracy: 0.9425 - val_top_k_categorical_accuracy: 0.9729\n",
            "Epoch 100/300\n",
            "1295/1295 [==============================] - 46s 36ms/step - loss: 0.2711 - accuracy: 0.9317 - top_k_categorical_accuracy: 0.9699 - val_loss: 0.2657 - val_accuracy: 0.9346 - val_top_k_categorical_accuracy: 0.9714\n",
            "Epoch 101/300\n",
            "1295/1295 [==============================] - 46s 36ms/step - loss: 0.2701 - accuracy: 0.9326 - top_k_categorical_accuracy: 0.9702 - val_loss: 0.2489 - val_accuracy: 0.9391 - val_top_k_categorical_accuracy: 0.9716\n",
            "Epoch 102/300\n",
            "1295/1295 [==============================] - 46s 36ms/step - loss: 0.2626 - accuracy: 0.9351 - top_k_categorical_accuracy: 0.9712 - val_loss: 0.2645 - val_accuracy: 0.9367 - val_top_k_categorical_accuracy: 0.9707\n",
            "Epoch 103/300\n",
            "1295/1295 [==============================] - 46s 36ms/step - loss: 0.2637 - accuracy: 0.9344 - top_k_categorical_accuracy: 0.9711 - val_loss: 0.2502 - val_accuracy: 0.9385 - val_top_k_categorical_accuracy: 0.9737\n",
            "Epoch 104/300\n",
            "1295/1295 [==============================] - 46s 36ms/step - loss: 0.2621 - accuracy: 0.9354 - top_k_categorical_accuracy: 0.9715 - val_loss: 0.2655 - val_accuracy: 0.9325 - val_top_k_categorical_accuracy: 0.9715\n",
            "Epoch 105/300\n",
            "1295/1295 [==============================] - 46s 36ms/step - loss: 0.2606 - accuracy: 0.9357 - top_k_categorical_accuracy: 0.9717 - val_loss: 0.2593 - val_accuracy: 0.9344 - val_top_k_categorical_accuracy: 0.9729\n",
            "Epoch 106/300\n",
            "1295/1295 [==============================] - 46s 36ms/step - loss: 0.2570 - accuracy: 0.9370 - top_k_categorical_accuracy: 0.9720 - val_loss: 0.2466 - val_accuracy: 0.9401 - val_top_k_categorical_accuracy: 0.9741\n",
            "Epoch 107/300\n",
            "1295/1295 [==============================] - 46s 36ms/step - loss: 0.2540 - accuracy: 0.9387 - top_k_categorical_accuracy: 0.9729 - val_loss: 0.2402 - val_accuracy: 0.9426 - val_top_k_categorical_accuracy: 0.9752\n",
            "Epoch 108/300\n",
            "1295/1295 [==============================] - 46s 36ms/step - loss: 0.2531 - accuracy: 0.9382 - top_k_categorical_accuracy: 0.9728 - val_loss: 0.2399 - val_accuracy: 0.9423 - val_top_k_categorical_accuracy: 0.9753\n",
            "Epoch 109/300\n",
            "1295/1295 [==============================] - 46s 36ms/step - loss: 0.2496 - accuracy: 0.9393 - top_k_categorical_accuracy: 0.9735 - val_loss: 0.2259 - val_accuracy: 0.9475 - val_top_k_categorical_accuracy: 0.9758\n",
            "Epoch 110/300\n",
            "1295/1295 [==============================] - 46s 36ms/step - loss: 0.2515 - accuracy: 0.9390 - top_k_categorical_accuracy: 0.9733 - val_loss: 0.2514 - val_accuracy: 0.9368 - val_top_k_categorical_accuracy: 0.9732\n",
            "Epoch 111/300\n",
            "1295/1295 [==============================] - 46s 36ms/step - loss: 0.2458 - accuracy: 0.9404 - top_k_categorical_accuracy: 0.9742 - val_loss: 0.2328 - val_accuracy: 0.9445 - val_top_k_categorical_accuracy: 0.9754\n",
            "Epoch 112/300\n",
            "1295/1295 [==============================] - 46s 36ms/step - loss: 0.2439 - accuracy: 0.9413 - top_k_categorical_accuracy: 0.9746 - val_loss: 0.2582 - val_accuracy: 0.9359 - val_top_k_categorical_accuracy: 0.9745\n",
            "Epoch 113/300\n",
            "1295/1295 [==============================] - 46s 36ms/step - loss: 0.2431 - accuracy: 0.9417 - top_k_categorical_accuracy: 0.9745 - val_loss: 0.2640 - val_accuracy: 0.9345 - val_top_k_categorical_accuracy: 0.9730\n",
            "Epoch 114/300\n",
            "1295/1295 [==============================] - 46s 36ms/step - loss: 0.2403 - accuracy: 0.9418 - top_k_categorical_accuracy: 0.9753 - val_loss: 0.2390 - val_accuracy: 0.9434 - val_top_k_categorical_accuracy: 0.9743\n",
            "Epoch 115/300\n",
            "1295/1295 [==============================] - 46s 36ms/step - loss: 0.2412 - accuracy: 0.9417 - top_k_categorical_accuracy: 0.9749 - val_loss: 0.2305 - val_accuracy: 0.9456 - val_top_k_categorical_accuracy: 0.9775\n",
            "Epoch 116/300\n",
            "1295/1295 [==============================] - 46s 36ms/step - loss: 0.2350 - accuracy: 0.9445 - top_k_categorical_accuracy: 0.9757 - val_loss: 0.2248 - val_accuracy: 0.9476 - val_top_k_categorical_accuracy: 0.9774\n",
            "Epoch 117/300\n",
            "1295/1295 [==============================] - 46s 36ms/step - loss: 0.2358 - accuracy: 0.9437 - top_k_categorical_accuracy: 0.9758 - val_loss: 0.2621 - val_accuracy: 0.9342 - val_top_k_categorical_accuracy: 0.9732\n",
            "Epoch 118/300\n",
            "1295/1295 [==============================] - 46s 36ms/step - loss: 0.2354 - accuracy: 0.9440 - top_k_categorical_accuracy: 0.9761 - val_loss: 0.2452 - val_accuracy: 0.9398 - val_top_k_categorical_accuracy: 0.9741\n",
            "Epoch 119/300\n",
            "1295/1295 [==============================] - 46s 36ms/step - loss: 0.2317 - accuracy: 0.9455 - top_k_categorical_accuracy: 0.9767 - val_loss: 0.2273 - val_accuracy: 0.9479 - val_top_k_categorical_accuracy: 0.9772\n",
            "Epoch 120/300\n",
            "1295/1295 [==============================] - 46s 36ms/step - loss: 0.2303 - accuracy: 0.9460 - top_k_categorical_accuracy: 0.9767 - val_loss: 0.2579 - val_accuracy: 0.9384 - val_top_k_categorical_accuracy: 0.9717\n",
            "Epoch 121/300\n",
            "1295/1295 [==============================] - 46s 36ms/step - loss: 0.2287 - accuracy: 0.9462 - top_k_categorical_accuracy: 0.9767 - val_loss: 0.2215 - val_accuracy: 0.9474 - val_top_k_categorical_accuracy: 0.9785\n",
            "Epoch 122/300\n",
            "1295/1295 [==============================] - 46s 36ms/step - loss: 0.2322 - accuracy: 0.9456 - top_k_categorical_accuracy: 0.9766 - val_loss: 0.2203 - val_accuracy: 0.9494 - val_top_k_categorical_accuracy: 0.9782\n",
            "Epoch 123/300\n",
            "1295/1295 [==============================] - 46s 36ms/step - loss: 0.2257 - accuracy: 0.9467 - top_k_categorical_accuracy: 0.9773 - val_loss: 0.2140 - val_accuracy: 0.9507 - val_top_k_categorical_accuracy: 0.9780\n",
            "Epoch 124/300\n",
            "1295/1295 [==============================] - 46s 36ms/step - loss: 0.2227 - accuracy: 0.9487 - top_k_categorical_accuracy: 0.9781 - val_loss: 0.2195 - val_accuracy: 0.9487 - val_top_k_categorical_accuracy: 0.9783\n",
            "Epoch 125/300\n",
            "1295/1295 [==============================] - 46s 36ms/step - loss: 0.2238 - accuracy: 0.9482 - top_k_categorical_accuracy: 0.9779 - val_loss: 0.2155 - val_accuracy: 0.9509 - val_top_k_categorical_accuracy: 0.9795\n",
            "Epoch 126/300\n",
            "1295/1295 [==============================] - 46s 36ms/step - loss: 0.2233 - accuracy: 0.9482 - top_k_categorical_accuracy: 0.9778 - val_loss: 0.2366 - val_accuracy: 0.9427 - val_top_k_categorical_accuracy: 0.9786\n",
            "Epoch 127/300\n",
            "1295/1295 [==============================] - 46s 36ms/step - loss: 0.2250 - accuracy: 0.9474 - top_k_categorical_accuracy: 0.9780 - val_loss: 0.2119 - val_accuracy: 0.9519 - val_top_k_categorical_accuracy: 0.9799\n",
            "Epoch 128/300\n",
            "1295/1295 [==============================] - 46s 36ms/step - loss: 0.2197 - accuracy: 0.9496 - top_k_categorical_accuracy: 0.9784 - val_loss: 0.2107 - val_accuracy: 0.9509 - val_top_k_categorical_accuracy: 0.9796\n",
            "Epoch 129/300\n",
            "1295/1295 [==============================] - 46s 36ms/step - loss: 0.2159 - accuracy: 0.9506 - top_k_categorical_accuracy: 0.9790 - val_loss: 0.2098 - val_accuracy: 0.9531 - val_top_k_categorical_accuracy: 0.9802\n",
            "Epoch 130/300\n",
            "1295/1295 [==============================] - 46s 36ms/step - loss: 0.2195 - accuracy: 0.9493 - top_k_categorical_accuracy: 0.9789 - val_loss: 0.2098 - val_accuracy: 0.9527 - val_top_k_categorical_accuracy: 0.9796\n",
            "Epoch 131/300\n",
            "1295/1295 [==============================] - 46s 36ms/step - loss: 0.2164 - accuracy: 0.9500 - top_k_categorical_accuracy: 0.9791 - val_loss: 0.2195 - val_accuracy: 0.9494 - val_top_k_categorical_accuracy: 0.9785\n",
            "Epoch 132/300\n",
            "1295/1295 [==============================] - 46s 36ms/step - loss: 0.2164 - accuracy: 0.9504 - top_k_categorical_accuracy: 0.9790 - val_loss: 0.2038 - val_accuracy: 0.9555 - val_top_k_categorical_accuracy: 0.9805\n",
            "Epoch 133/300\n",
            "1295/1295 [==============================] - 46s 36ms/step - loss: 0.2141 - accuracy: 0.9512 - top_k_categorical_accuracy: 0.9796 - val_loss: 0.2147 - val_accuracy: 0.9502 - val_top_k_categorical_accuracy: 0.9800\n",
            "Epoch 134/300\n",
            "1295/1295 [==============================] - 46s 36ms/step - loss: 0.2140 - accuracy: 0.9511 - top_k_categorical_accuracy: 0.9792 - val_loss: 0.1914 - val_accuracy: 0.9590 - val_top_k_categorical_accuracy: 0.9820\n",
            "Epoch 135/300\n",
            "1295/1295 [==============================] - 46s 36ms/step - loss: 0.2146 - accuracy: 0.9512 - top_k_categorical_accuracy: 0.9799 - val_loss: 0.2314 - val_accuracy: 0.9466 - val_top_k_categorical_accuracy: 0.9788\n",
            "Epoch 136/300\n",
            "1295/1295 [==============================] - 46s 36ms/step - loss: 0.2134 - accuracy: 0.9512 - top_k_categorical_accuracy: 0.9795 - val_loss: 0.1928 - val_accuracy: 0.9579 - val_top_k_categorical_accuracy: 0.9818\n",
            "Epoch 137/300\n",
            "1295/1295 [==============================] - 46s 36ms/step - loss: 0.2072 - accuracy: 0.9535 - top_k_categorical_accuracy: 0.9802 - val_loss: 0.2134 - val_accuracy: 0.9508 - val_top_k_categorical_accuracy: 0.9819\n",
            "Epoch 138/300\n",
            "1295/1295 [==============================] - 46s 36ms/step - loss: 0.2100 - accuracy: 0.9524 - top_k_categorical_accuracy: 0.9802 - val_loss: 0.2092 - val_accuracy: 0.9529 - val_top_k_categorical_accuracy: 0.9808\n",
            "Epoch 139/300\n",
            "1295/1295 [==============================] - 46s 36ms/step - loss: 0.2077 - accuracy: 0.9536 - top_k_categorical_accuracy: 0.9803 - val_loss: 0.2022 - val_accuracy: 0.9537 - val_top_k_categorical_accuracy: 0.9823\n",
            "Epoch 140/300\n",
            "1295/1295 [==============================] - 46s 36ms/step - loss: 0.2084 - accuracy: 0.9530 - top_k_categorical_accuracy: 0.9804 - val_loss: 0.2116 - val_accuracy: 0.9515 - val_top_k_categorical_accuracy: 0.9801\n",
            "Epoch 141/300\n",
            "1295/1295 [==============================] - 46s 36ms/step - loss: 0.2086 - accuracy: 0.9529 - top_k_categorical_accuracy: 0.9804 - val_loss: 0.1944 - val_accuracy: 0.9582 - val_top_k_categorical_accuracy: 0.9828\n",
            "Epoch 142/300\n",
            "1295/1295 [==============================] - 46s 36ms/step - loss: 0.2061 - accuracy: 0.9534 - top_k_categorical_accuracy: 0.9809 - val_loss: 0.2025 - val_accuracy: 0.9543 - val_top_k_categorical_accuracy: 0.9819\n",
            "Epoch 143/300\n",
            "1295/1295 [==============================] - 46s 36ms/step - loss: 0.2047 - accuracy: 0.9547 - top_k_categorical_accuracy: 0.9810 - val_loss: 0.1972 - val_accuracy: 0.9571 - val_top_k_categorical_accuracy: 0.9820\n",
            "Epoch 144/300\n",
            "1295/1295 [==============================] - 46s 36ms/step - loss: 0.2037 - accuracy: 0.9550 - top_k_categorical_accuracy: 0.9810 - val_loss: 0.2422 - val_accuracy: 0.9409 - val_top_k_categorical_accuracy: 0.9763\n",
            "  45/1295 [>.............................] - ETA: 4s - loss: 1.4510 - accuracy: 0.8396 - top_k_categorical_accuracy: 0.8785"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-10-23 04:27:10.800102: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 343230944 exceeds 10% of free system memory.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1295/1295 [==============================] - 5s 4ms/step - loss: 2.1751 - accuracy: 0.7613 - top_k_categorical_accuracy: 0.8331\n",
            "Testing accuracy: 0.7612585425376892 \n",
            "Top-2 accuracy: 0.8331441879272461 \n",
            "Test loss: 2.175051212310791\n",
            "Ending Training at 2023-10-23 04:27:15.663918\n",
            "Training took 1:51:30.238702\n"
          ]
        }
      ],
      "source": [
        "\n",
        "#parse CLS embedding column as array\n",
        "test_acc = kerasNLP_model.train_model( df, y , epochs=3xfghnm00)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sSSkyth-2K3A"
      },
      "source": [
        "## Train several models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "learning is fun!\n"
          ]
        }
      ],
      "source": [
        "print(\"learning is fun!\") "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lv4ivBuvinss",
        "outputId": "814ef4fb-e100-4b22-ccbc-6b9d91e5a341"
      },
      "outputs": [],
      "source": [
        "#logistic_tree_model.run_pipeline()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_UIaks6jjPkU",
        "outputId": "0e365ed1-472e-4cb1-cdde-ae0a2d32722e"
      },
      "outputs": [],
      "source": [
        "#logistic_model.run_pipeline()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2290"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import gc\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [],
      "source": [
        "kerasNLP_model.best_hyperparameters = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/briarmoss/.local/lib/python3.10/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ],
      "source": [
        "import datetime\n",
        "\n",
        "def save_model_to_dir(model, folder_name):\n",
        "    dir_path = os.path.join(MODEL_FOLDER, folder_name)\n",
        "    \n",
        "    if not os.path.exists(dir_path):\n",
        "        os.mkdir(dir_path)\n",
        "    \n",
        "    timestamp = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "    model_name = timestamp + \"_\" + model.model_type\n",
        "    properties_name = model_name\n",
        "    \n",
        "    model.save(dir_path, model_name, properties_name)\n",
        "\n",
        "# List of models\n",
        "models = [kerasNLP_model]\n",
        "\n",
        "\n",
        "# Iterate over models and save\n",
        "for model in models:\n",
        "    save_model_to_dir(model, model.model_type)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"\\ndata = kerasNLP_model.load_data( 'predict' )\\ndata = kerasNLP_model.enhance_data( data, 'predict')\\nclean_data = kerasNLP_model.clean_data_for_prediction( data )\\n\\nX_predict, y_predict = kerasNLP_model.split_data( clean_data )\\ny_predict = kerasNLP_model.model.predict(X_predict)\\ndata['survival_prediction'] = y_predict\\nreturn data\\n\""
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\"\"\"\n",
        "data = kerasNLP_model.load_data( 'predict' )\n",
        "data = kerasNLP_model.enhance_data( data, 'predict')\n",
        "clean_data = kerasNLP_model.clean_data_for_prediction( data )\n",
        "\n",
        "X_predict, y_predict = kerasNLP_model.split_data( clean_data )\n",
        "y_predict = kerasNLP_model.model.predict(X_predict)\n",
        "data['survival_prediction'] = y_predict\n",
        "return data\n",
        "\"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
