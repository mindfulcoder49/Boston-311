{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOQ1HlgdYIX15vKKvxbmqwO"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#Boston 311 v4 - List all to-dos and questions, and finally train our models on all the data\n","\n","The last three notebooks provided interesting insights into our problem here, but the fun of Machine Learning is running models on big data right? So let's list all of our to dos, and then put them aside for a moment to see how our data cleaning functions and models do on the combined 311 data from 2011-2023\n","\n","##Questions and To-Dos from v1:\n","\n","1. Train the models on all the historical 311 data\n","2. Add more features\n","3. clean up the data by removing outliers\n","4. deal with the missing feature columns between 2022 and 2023 data because some categorical feature values are missing from one or the other, resulting in one hot encoded column mismatches.\n","5. Develop some heuristics to see if our Machine Learning model can actually do better than some obvious correlations.\n","\n","Questions to answer:\n","1. Can we find some basic commonality between open cases?\n","2. When and how is the target date set? How about the overdue flag?\n","3. Do cases autoclose after a certain time?\n","4. Do cases carry over from year to year? If so, do they keep the same case_enquiry_id? (probably they do, but it would be good to confirm)\n","\n","##Questions and To-Dos from v3:\n","\n","To-Dos:\n","\n","1. look at the currently available android app and see what values are available to the user to select, and which categories might be assigned by the 311 agents after receiving a new case.\n","2. compare a basic model which only uses the department value as a feature to our more complex models as a heuristic for whether additional features actually improve predictions.\n","\n","We have done a bit of work on some of these. v1.TD3 was addressed a bit in v3. v1.TD4 will be dealt with by combining all our data together. v1.TD5 is addressed partially with v3.TD2 where we hypothesize that a simple department value feature model might be a good heuristic to see if other features add noise or good predictive data.\n","\n","For now we are going to address v1.TD1 and combine all the data."],"metadata":{"id":"R7xdGwOZrlTM"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import re\n","import tensorflow as tf\n","import glob\n","from tensorflow import keras\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, f1_score\n","from sklearn.preprocessing import StandardScaler\n","from datetime import datetime\n","\n","from IPython.display import display\n","\n","%matplotlib inline\n","\n","#first of course we must import the necessary modules"],"metadata":{"id":"1ex4nrsttjQW","executionInfo":{"status":"ok","timestamp":1683223442106,"user_tz":240,"elapsed":129,"user":{"displayName":"Alex Alcivar","userId":"16433380480796576336"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["def clean_and_split_for_logistic(data) :\n","  data['survival_time'] = data['closed_dt'] - data['open_dt']\n","  data['event'] = data['closed_dt'].notnull().astype(int)\n","  data['ward_number'] = data['ward'].str.extract(r'0*(\\d+)')\n","\n","  cols_to_keep = ['case_enquiry_id', 'survival_time', 'event', 'subject', 'reason', 'department', 'source', 'ward_number']\n","  clean_data = data[cols_to_keep].copy()\n","\n","  clean_data = pd.get_dummies(clean_data, columns=['subject', 'reason', 'department', 'source', 'ward_number'])\n","\n","  #fix this line to also drop the case_enquiry_id\n","  X = clean_data.drop(['case_enquiry_id','event', 'survival_time'], axis=1)\n","  y = clean_data['event']\n","\n","  return X, y\n","\n","def clean_and_split_for_linear(data) :\n","  data['survival_time'] = data['closed_dt'] - data['open_dt']\n","  data['event'] = data['closed_dt'].notnull().astype(int)\n","  data['ward_number'] = data['ward'].str.extract(r'0*(\\d+)')\n","\n","  cols_to_keep = ['case_enquiry_id', 'survival_time', 'event', 'subject', 'reason', 'department', 'source', 'ward_number']\n","  clean_data = data[cols_to_keep].copy()\n","\n","  clean_data = pd.get_dummies(clean_data, columns=['subject', 'reason', 'department', 'source', 'ward_number'])\n","  clean_data_survival_mask = clean_data[\"survival_time\"].notnull()\n","  clean_data_survival = clean_data[clean_data_survival_mask].copy()\n","  clean_data_survival['survival_time_hours'] = clean_data_survival['survival_time'].apply(lambda x: x.total_seconds()/3600)\n","\n","  #fix this line to also drop the case_enquiry_id\n","  X = clean_data_survival.drop(['case_enquiry_id','survival_time_hours', 'survival_time', 'event'], axis=1) \n","  y = clean_data_survival['survival_time_hours']\n","  \n","  return X, y"],"metadata":{"id":"ePrLP4YztnyM","executionInfo":{"status":"ok","timestamp":1683222383635,"user_tz":240,"elapsed":209,"user":{"displayName":"Alex Alcivar","userId":"16433380480796576336"}}},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":["We imported our libraries and defined our clean data functions. Now let's load all the data and see if we have duplicated case_enquiry_id value and how we will deal with those. Probably we would want to drop the earlier records and keep the later ones. It will be interesting to see if any cases remained open long enough to be included in more than two of the year-based datasets. I loaded these files into google colaboratory by downloading them from data.boston.gov and uploading them manually. Here is the link to all the data sets:\n","\n","https://data.boston.gov/dataset/311-service-requests"],"metadata":{"id":"MjXS7vdMuAAu"}},{"cell_type":"code","source":["\n","# Get a list of all CSV files in the directory\n","all_files = glob.glob(\"*.csv\")\n","\n","# Create an empty list to store the dataframes\n","dfs = []\n","\n","# Loop through the files and load them into dataframes\n","for file in all_files:\n","  df = pd.read_csv(file)\n","  dfs.append(df)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CvalfNwatweO","executionInfo":{"status":"ok","timestamp":1683221048737,"user_tz":240,"elapsed":22500,"user":{"displayName":"Alex Alcivar","userId":"16433380480796576336"}},"outputId":"a56640dc-70fc-4282-96ee-ff44dc6c4f94"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-7-f0d266f2bb0a>:9: DtypeWarning: Columns (14) have mixed types. Specify dtype option on import or set low_memory=False.\n","  df = pd.read_csv(file)\n","<ipython-input-7-f0d266f2bb0a>:9: DtypeWarning: Columns (13) have mixed types. Specify dtype option on import or set low_memory=False.\n","  df = pd.read_csv(file)\n"]}]},{"cell_type":"code","source":["#check that the files all have the same number of columns, and the same names\n","for i in range(len(dfs)):\n","  if dfs[i].shape[1] != dfs[0].shape[1]:\n","    print('Error: File', i, 'does not have the same number of columns as File 0')\n","  else:\n","    print('File', i, 'has same number of columns as File 0')\n","  if not dfs[i].columns.equals(dfs[0].columns):\n","    print('Error: File', i, 'does not have the same column names and order as File 0')\n","  else:\n","    print('File', i, 'has the same column name and order as File 0')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VUD2X_0ezO90","executionInfo":{"status":"ok","timestamp":1683221185940,"user_tz":240,"elapsed":442,"user":{"displayName":"Alex Alcivar","userId":"16433380480796576336"}},"outputId":"bb4c1ad0-7d11-4e52-da1a-58718b557070"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["File 0 has same number of columns as File 0\n","File 0 has the same column name and order as File 0\n","File 1 has same number of columns as File 0\n","File 1 has the same column name and order as File 0\n","File 2 has same number of columns as File 0\n","File 2 has the same column name and order as File 0\n","File 3 has same number of columns as File 0\n","File 3 has the same column name and order as File 0\n","File 4 has same number of columns as File 0\n","File 4 has the same column name and order as File 0\n","File 5 has same number of columns as File 0\n","File 5 has the same column name and order as File 0\n","File 6 has same number of columns as File 0\n","File 6 has the same column name and order as File 0\n","File 7 has same number of columns as File 0\n","File 7 has the same column name and order as File 0\n","File 8 has same number of columns as File 0\n","File 8 has the same column name and order as File 0\n","File 9 has same number of columns as File 0\n","File 9 has the same column name and order as File 0\n","File 10 has same number of columns as File 0\n","File 10 has the same column name and order as File 0\n","File 11 has same number of columns as File 0\n","File 11 has the same column name and order as File 0\n","File 12 has same number of columns as File 0\n","File 12 has the same column name and order as File 0\n"]}]},{"cell_type":"code","source":["# Concatenate the dataframes into a single dataframe\n","df_all = pd.concat(dfs, ignore_index=True)"],"metadata":{"id":"kYHw_gitwmHW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["id_counts = df_all['case_enquiry_id'].value_counts()\n","id_filter = df_all['reason'].isin(id_counts[id_counts > 1].index)\n","display(df_all[id_filter])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":143},"id":"EUdtPOuGzqk1","executionInfo":{"status":"ok","timestamp":1683221540943,"user_tz":240,"elapsed":2071,"user":{"displayName":"Alex Alcivar","userId":"16433380480796576336"}},"outputId":"42b450cb-7055-4bf3-c8ae-0d1a3da701ac"},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":["Empty DataFrame\n","Columns: [case_enquiry_id, open_dt, target_dt, closed_dt, ontime, case_status, closure_reason, case_title, subject, reason, type, queue, department, submittedphoto, closedphoto, location, fire_district, pwd_district, city_council_district, police_district, neighborhood, neighborhood_services_district, ward, precinct, location_street_name, location_zipcode, latitude, longitude, source]\n","Index: []\n","\n","[0 rows x 29 columns]"],"text/html":["\n","  <div id=\"df-8fb2dced-1d23-4224-a643-9099b751873e\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>case_enquiry_id</th>\n","      <th>open_dt</th>\n","      <th>target_dt</th>\n","      <th>closed_dt</th>\n","      <th>ontime</th>\n","      <th>case_status</th>\n","      <th>closure_reason</th>\n","      <th>case_title</th>\n","      <th>subject</th>\n","      <th>reason</th>\n","      <th>...</th>\n","      <th>police_district</th>\n","      <th>neighborhood</th>\n","      <th>neighborhood_services_district</th>\n","      <th>ward</th>\n","      <th>precinct</th>\n","      <th>location_street_name</th>\n","      <th>location_zipcode</th>\n","      <th>latitude</th>\n","      <th>longitude</th>\n","      <th>source</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table>\n","<p>0 rows × 29 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8fb2dced-1d23-4224-a643-9099b751873e')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-8fb2dced-1d23-4224-a643-9099b751873e button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-8fb2dced-1d23-4224-a643-9099b751873e');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{}}]},{"cell_type":"markdown","source":["Interestingly, even though we expected the data might have duplicate 'case_enquiry_id' values because of cases that spanned multiple years, it looks like maybe the data from past years was generated from a central database. Is it continually updated? We could answer that question by checking if any cases have an open and closed date in different years."],"metadata":{"id":"qMW-_d9j0vHj"}},{"cell_type":"code","source":["# Convert the 'open_dt' and 'close_dt' columns to datetime\n","df_all['open_dt'] = pd.to_datetime(df_all['open_dt'])\n","df_all['closed_dt'] = pd.to_datetime(df_all['closed_dt'])\n","\n","# Create a new column to hold the year of each open date\n","df_all['open_year'] = df_all['open_dt'].dt.year\n","\n","# Filter the DataFrame to only include cases where the close_dt year is greater than the open_dt year\n","df_across_years = df_all[(df_all['closed_dt'].dt.year > df_all['open_dt'].dt.year)]\n"],"metadata":{"id":"Mnxeps4k17bJ","executionInfo":{"status":"ok","timestamp":1683221934497,"user_tz":240,"elapsed":2255,"user":{"displayName":"Alex Alcivar","userId":"16433380480796576336"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["df_across_years.describe()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":344},"id":"SWrGprNp2IUf","executionInfo":{"status":"ok","timestamp":1683222036187,"user_tz":240,"elapsed":7,"user":{"displayName":"Alex Alcivar","userId":"16433380480796576336"}},"outputId":"f4059d94-2afc-4954-acaf-fe3fcf818816"},"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["       case_enquiry_id  location_zipcode      latitude     longitude  \\\n","count     4.024500e+04      32455.000000  40244.000000  40244.000000   \n","mean      1.010010e+11       2126.978678     42.328398    -71.082523   \n","std       6.414967e+05         17.592728      0.034287      0.035802   \n","min       1.010003e+11       2108.000000     42.232700    -71.181000   \n","25%       1.010005e+11       2119.000000     42.298600    -71.102700   \n","50%       1.010009e+11       2126.000000     42.336400    -71.073400   \n","75%       1.010012e+11       2130.000000     42.357900    -71.058700   \n","max       1.010046e+11       2467.000000     42.393300    -70.996300   \n","\n","          open_year  \n","count  40245.000000  \n","mean    2013.281153  \n","std        2.010371  \n","min     2011.000000  \n","25%     2012.000000  \n","50%     2013.000000  \n","75%     2014.000000  \n","max     2022.000000  "],"text/html":["\n","  <div id=\"df-3fcee17f-d661-4ba1-a4d1-c13dee9a5c79\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>case_enquiry_id</th>\n","      <th>location_zipcode</th>\n","      <th>latitude</th>\n","      <th>longitude</th>\n","      <th>open_year</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>4.024500e+04</td>\n","      <td>32455.000000</td>\n","      <td>40244.000000</td>\n","      <td>40244.000000</td>\n","      <td>40245.000000</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>1.010010e+11</td>\n","      <td>2126.978678</td>\n","      <td>42.328398</td>\n","      <td>-71.082523</td>\n","      <td>2013.281153</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>6.414967e+05</td>\n","      <td>17.592728</td>\n","      <td>0.034287</td>\n","      <td>0.035802</td>\n","      <td>2.010371</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>1.010003e+11</td>\n","      <td>2108.000000</td>\n","      <td>42.232700</td>\n","      <td>-71.181000</td>\n","      <td>2011.000000</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>1.010005e+11</td>\n","      <td>2119.000000</td>\n","      <td>42.298600</td>\n","      <td>-71.102700</td>\n","      <td>2012.000000</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>1.010009e+11</td>\n","      <td>2126.000000</td>\n","      <td>42.336400</td>\n","      <td>-71.073400</td>\n","      <td>2013.000000</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>1.010012e+11</td>\n","      <td>2130.000000</td>\n","      <td>42.357900</td>\n","      <td>-71.058700</td>\n","      <td>2014.000000</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>1.010046e+11</td>\n","      <td>2467.000000</td>\n","      <td>42.393300</td>\n","      <td>-70.996300</td>\n","      <td>2022.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3fcee17f-d661-4ba1-a4d1-c13dee9a5c79')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-3fcee17f-d661-4ba1-a4d1-c13dee9a5c79 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-3fcee17f-d661-4ba1-a4d1-c13dee9a5c79');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":16}]},{"cell_type":"markdown","source":["We indeed have many records that were opened in one year and closed in another. Looking at the individual data sets, we can see that each data set contains cases opened in that year, but the closed date might be in the following year. This is a helpful aspect of our data. That means we are ready to clean our data and train our models."],"metadata":{"id":"yiY6lKUy2g1o"}},{"cell_type":"code","source":["logistic_X, logistic_y = clean_and_split_for_logistic(df_all)"],"metadata":{"id":"i2UHDoMtSjt1","executionInfo":{"status":"ok","timestamp":1683222399302,"user_tz":240,"elapsed":9125,"user":{"displayName":"Alex Alcivar","userId":"16433380480796576336"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["linear_X, linear_y = clean_and_split_for_linear(df_all)"],"metadata":{"id":"ocYKCB9US5YB","executionInfo":{"status":"ok","timestamp":1683224072251,"user_tz":240,"elapsed":17991,"user":{"displayName":"Alex Alcivar","userId":"16433380480796576336"}}},"execution_count":29,"outputs":[]},{"cell_type":"code","source":["#Train a logistic regression model\n","\n","# Split into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(logistic_X, logistic_y, test_size=0.2, random_state=42)\n","\n","# Build model\n","model_logistic = keras.Sequential([\n","    keras.layers.Dense(units=1, input_shape=(X_train.shape[1],), activation='sigmoid')\n","])\n","\n","# Compile model\n","model_logistic.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n","\n","# Train model\n","model_logistic.fit(X_train, y_train, epochs=10, batch_size=32)\n","\n","# Evaluate model\n","test_loss, test_acc = model_logistic.evaluate(X_test, y_test)\n","\n","print('Test accuracy:', test_acc)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uxIvZzVQ3OsO","executionInfo":{"status":"ok","timestamp":1683223298417,"user_tz":240,"elapsed":876192,"user":{"displayName":"Alex Alcivar","userId":"16433380480796576336"}},"outputId":"656f2cb7-46e1-4679-b652-ed47748a1691"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","36498/36498 [==============================] - 85s 2ms/step - loss: 0.1707 - accuracy: 0.9363\n","Epoch 2/10\n","36498/36498 [==============================] - 86s 2ms/step - loss: 0.1628 - accuracy: 0.9392\n","Epoch 3/10\n","36498/36498 [==============================] - 89s 2ms/step - loss: 0.1626 - accuracy: 0.9393\n","Epoch 4/10\n","36498/36498 [==============================] - 90s 2ms/step - loss: 0.1626 - accuracy: 0.9392\n","Epoch 5/10\n","36498/36498 [==============================] - 83s 2ms/step - loss: 0.1626 - accuracy: 0.9392\n","Epoch 6/10\n","36498/36498 [==============================] - 83s 2ms/step - loss: 0.1626 - accuracy: 0.9392\n","Epoch 7/10\n","36498/36498 [==============================] - 86s 2ms/step - loss: 0.1626 - accuracy: 0.9392\n","Epoch 8/10\n","36498/36498 [==============================] - 85s 2ms/step - loss: 0.1626 - accuracy: 0.9392\n","Epoch 9/10\n","36498/36498 [==============================] - 82s 2ms/step - loss: 0.1626 - accuracy: 0.9392\n","Epoch 10/10\n","36498/36498 [==============================] - 81s 2ms/step - loss: 0.1626 - accuracy: 0.9392\n","9125/9125 [==============================] - 20s 2ms/step - loss: 0.1623 - accuracy: 0.9402\n","Test accuracy: 0.9402193427085876\n"]}]},{"cell_type":"markdown","source":["Our model has better accuracy than when we only used the 2022 data. Unfortunately, now we have no validation data set. So we can't tell if we just overfitted our model or if it's actually better. We should add a validation set in our next notebook.\n","\n","For now, let's just add a validation set to our linear regression model, since that will take more time to train, and is a more important model. \n","\n","Let's also add code to record the start and end times of our training and tell us how long the training took."],"metadata":{"id":"wETOgWET75Nr"}},{"cell_type":"code","source":["#Train a linear regression model\n","\n","start_time = datetime.now()\n","print(\"Starting Training at {}\".format(start_time))\n","\n","scaler = StandardScaler()\n","X_scaled = scaler.fit_transform(linear_X) # scale the data\n","X_train, X_test, y_train, y_test = train_test_split(X_scaled, linear_y, test_size=0.2, random_state=42)\n","\n","# split the data again to create a validation set\n","X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n","\n","# define the model architecture\n","model_linear = keras.Sequential([\n","    keras.layers.Dense(units=1, input_dim=X_train.shape[1])\n","])\n","\n","# compile the model\n","model_linear.compile(optimizer='adam', loss='mean_squared_error')\n","\n","# train the model\n","model_linear.fit(X_train, y_train, epochs=50, batch_size=32, verbose=1, validation_data=(X_val, y_val))\n","\n","end_time = datetime.now()\n","total_time = (end_time - start_time)\n","print(\"Ending Training at {}\".format(end_time))\n","print(\"Training took {}\".format(total_time))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h4ByGJ6u3SH0","executionInfo":{"status":"ok","timestamp":1683227303053,"user_tz":240,"elapsed":3094215,"user":{"displayName":"Alex Alcivar","userId":"16433380480796576336"}},"outputId":"c251906d-447d-4684-83bd-dcb80334dea8"},"execution_count":34,"outputs":[{"output_type":"stream","name":"stdout","text":["Starting Training at 2023-05-04 18:16:48.813984\n","Epoch 1/50\n","26748/26748 [==============================] - 66s 2ms/step - loss: 4407586.0000 - val_loss: 4355220.0000\n","Epoch 2/50\n","26748/26748 [==============================] - 58s 2ms/step - loss: 4318564.5000 - val_loss: 4278623.5000\n","Epoch 3/50\n","26748/26748 [==============================] - 62s 2ms/step - loss: 4247426.0000 - val_loss: 4215415.0000\n","Epoch 4/50\n","26748/26748 [==============================] - 60s 2ms/step - loss: 4192095.5000 - val_loss: 4165817.0000\n","Epoch 5/50\n","26748/26748 [==============================] - 64s 2ms/step - loss: 4148078.2500 - val_loss: 4124982.0000\n","Epoch 6/50\n","26748/26748 [==============================] - 61s 2ms/step - loss: 4112482.0000 - val_loss: 4094784.5000\n","Epoch 7/50\n","26748/26748 [==============================] - 58s 2ms/step - loss: 4083910.5000 - val_loss: 4066947.0000\n","Epoch 8/50\n","26748/26748 [==============================] - 60s 2ms/step - loss: 4060905.5000 - val_loss: 4046237.2500\n","Epoch 9/50\n","26748/26748 [==============================] - 62s 2ms/step - loss: 4043087.0000 - val_loss: 4030477.5000\n","Epoch 10/50\n","26748/26748 [==============================] - 64s 2ms/step - loss: 4026957.7500 - val_loss: 4015428.0000\n","Epoch 11/50\n","26748/26748 [==============================] - 58s 2ms/step - loss: 4014131.0000 - val_loss: 4000659.7500\n","Epoch 12/50\n","26748/26748 [==============================] - 59s 2ms/step - loss: 4002727.0000 - val_loss: 3988147.2500\n","Epoch 13/50\n","26748/26748 [==============================] - 57s 2ms/step - loss: 3992122.7500 - val_loss: 3976858.0000\n","Epoch 14/50\n","26748/26748 [==============================] - 64s 2ms/step - loss: 3983363.0000 - val_loss: 3967424.0000\n","Epoch 15/50\n","26748/26748 [==============================] - 62s 2ms/step - loss: 3976746.7500 - val_loss: 3958746.0000\n","Epoch 16/50\n","26748/26748 [==============================] - 58s 2ms/step - loss: 3969636.7500 - val_loss: 3953208.0000\n","Epoch 17/50\n","26748/26748 [==============================] - 61s 2ms/step - loss: 3964555.7500 - val_loss: 3946394.0000\n","Epoch 18/50\n","26748/26748 [==============================] - 62s 2ms/step - loss: 3959355.2500 - val_loss: 3940835.2500\n","Epoch 19/50\n","26748/26748 [==============================] - 62s 2ms/step - loss: 3955077.7500 - val_loss: 3935793.0000\n","Epoch 20/50\n","26748/26748 [==============================] - 62s 2ms/step - loss: 3952329.0000 - val_loss: 3932931.7500\n","Epoch 21/50\n","26748/26748 [==============================] - 72s 3ms/step - loss: 3950011.5000 - val_loss: 3929115.7500\n","Epoch 22/50\n","26748/26748 [==============================] - 60s 2ms/step - loss: 3948323.0000 - val_loss: 3925547.5000\n","Epoch 23/50\n","26748/26748 [==============================] - 65s 2ms/step - loss: 3945771.5000 - val_loss: 3922912.5000\n","Epoch 24/50\n","26748/26748 [==============================] - 63s 2ms/step - loss: 3945082.7500 - val_loss: 3920088.2500\n","Epoch 25/50\n","26748/26748 [==============================] - 65s 2ms/step - loss: 3942353.2500 - val_loss: 3917540.5000\n","Epoch 26/50\n","26748/26748 [==============================] - 59s 2ms/step - loss: 3940871.5000 - val_loss: 3915524.2500\n","Epoch 27/50\n","26748/26748 [==============================] - 61s 2ms/step - loss: 3941788.5000 - val_loss: 3914234.5000\n","Epoch 28/50\n","26748/26748 [==============================] - 62s 2ms/step - loss: 3940332.2500 - val_loss: 3912805.5000\n","Epoch 29/50\n","26748/26748 [==============================] - 65s 2ms/step - loss: 3939788.2500 - val_loss: 3912210.5000\n","Epoch 30/50\n","26748/26748 [==============================] - 64s 2ms/step - loss: 3939484.5000 - val_loss: 3911330.7500\n","Epoch 31/50\n","26748/26748 [==============================] - 62s 2ms/step - loss: 3938583.2500 - val_loss: 3910684.7500\n","Epoch 32/50\n","26748/26748 [==============================] - 61s 2ms/step - loss: 3937747.5000 - val_loss: 3909657.7500\n","Epoch 33/50\n","26748/26748 [==============================] - 60s 2ms/step - loss: 3938417.7500 - val_loss: 3909040.0000\n","Epoch 34/50\n","26748/26748 [==============================] - 59s 2ms/step - loss: 3937846.5000 - val_loss: 3908345.0000\n","Epoch 35/50\n","26748/26748 [==============================] - 61s 2ms/step - loss: 3937434.2500 - val_loss: 3908413.0000\n","Epoch 36/50\n","26748/26748 [==============================] - 61s 2ms/step - loss: 3938071.5000 - val_loss: 3907975.7500\n","Epoch 37/50\n","26748/26748 [==============================] - 63s 2ms/step - loss: 3937983.2500 - val_loss: 3907292.7500\n","Epoch 38/50\n","26748/26748 [==============================] - 63s 2ms/step - loss: 3938277.5000 - val_loss: 3906761.2500\n","Epoch 39/50\n","26748/26748 [==============================] - 59s 2ms/step - loss: 3937816.5000 - val_loss: 3906264.2500\n","Epoch 40/50\n","26748/26748 [==============================] - 57s 2ms/step - loss: 3937488.7500 - val_loss: 3905776.0000\n","Epoch 41/50\n","26748/26748 [==============================] - 58s 2ms/step - loss: 3937517.7500 - val_loss: 3905683.2500\n","Epoch 42/50\n","26748/26748 [==============================] - 57s 2ms/step - loss: 3937167.5000 - val_loss: 3905467.5000\n","Epoch 43/50\n","26748/26748 [==============================] - 64s 2ms/step - loss: 3937262.5000 - val_loss: 3905176.2500\n","Epoch 44/50\n","26748/26748 [==============================] - 65s 2ms/step - loss: 3937055.0000 - val_loss: 3905024.5000\n","Epoch 45/50\n","26748/26748 [==============================] - 66s 2ms/step - loss: 3937381.5000 - val_loss: 3904707.0000\n","Epoch 46/50\n","26748/26748 [==============================] - 62s 2ms/step - loss: 3937287.0000 - val_loss: 3904445.0000\n","Epoch 47/50\n","26748/26748 [==============================] - 60s 2ms/step - loss: 3937084.5000 - val_loss: 3904240.0000\n","Epoch 48/50\n","26748/26748 [==============================] - 62s 2ms/step - loss: 3936813.7500 - val_loss: 3903975.0000\n","Epoch 49/50\n","26748/26748 [==============================] - 60s 2ms/step - loss: 3936618.0000 - val_loss: 3903723.0000\n","Epoch 50/50\n","26748/26748 [==============================] - 61s 2ms/step - loss: 3936748.7500 - val_loss: 3903819.5000\n","Ending Training at 2023-05-04 19:08:22.215391\n","Training took 0:51:33.401407\n"]}]},{"cell_type":"code","source":["model_linear.save(\"model_linear.h5\")"],"metadata":{"id":"lBXiNZEgRSzN","executionInfo":{"status":"ok","timestamp":1683229154102,"user_tz":240,"elapsed":123,"user":{"displayName":"Alex Alcivar","userId":"16433380480796576336"}}},"execution_count":36,"outputs":[]},{"cell_type":"code","source":["model_logistic.save(\"model_logistic.h5\")"],"metadata":{"id":"BQUCnVrMRpnF","executionInfo":{"status":"ok","timestamp":1683229171556,"user_tz":240,"elapsed":195,"user":{"displayName":"Alex Alcivar","userId":"16433380480796576336"}}},"execution_count":37,"outputs":[]},{"cell_type":"markdown","source":["We save these models so that we can start building a website and API to make these models available to the public"],"metadata":{"id":"0KRoUzvLSD09"}}]}